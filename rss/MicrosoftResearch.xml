<?xml version="1.0" encoding="UTF-8"?><rss version="2.0"
	xmlns:content="http://purl.org/rss/1.0/modules/content/"
	xmlns:wfw="http://wellformedweb.org/CommentAPI/"
	xmlns:dc="http://purl.org/dc/elements/1.1/"
	xmlns:atom="http://www.w3.org/2005/Atom"
	xmlns:sy="http://purl.org/rss/1.0/modules/syndication/"
	xmlns:slash="http://purl.org/rss/1.0/modules/slash/"
	>

<channel>
	<title>Microsoft Research</title>
	<atom:link href="https://www.microsoft.com/en-us/research/feed/" rel="self" type="application/rss+xml" />
	<link>https://www.microsoft.com/en-us/research/</link>
	<description></description>
	<lastBuildDate>Thu, 13 Feb 2025 14:50:52 +0000</lastBuildDate>
	<language>en-US</language>
	<sy:updatePeriod>
	hourly	</sy:updatePeriod>
	<sy:updateFrequency>
	1	</sy:updateFrequency>
	<generator>https://wordpress.org/?v=6.7.1</generator>
	<item>
		<title>Microsoft Research and Physics Wallah team up to enhance AI-based tutoring</title>
		<link>https://www.microsoft.com/en-us/research/blog/microsoft-research-and-physics-wallah-team-up-to-enhance-ai-based-tutoring/</link>
		
		<dc:creator><![CDATA[Brenda Potts]]></dc:creator>
		<pubDate>Wed, 12 Feb 2025 21:01:07 +0000</pubDate>
				<category><![CDATA[Research Blog]]></category>
		<guid isPermaLink="false">https://www.microsoft.com/en-us/research/?p=1128279</guid>

					<description><![CDATA[<p>Limited resources, geography, and economic factors present barriers to quality education for many students in India. Learn how Microsoft Research is collaborating with Physics Wallah to make AI-based tutoring more accurate, reliable, and affordable.</p>
<p>The post <a href="https://www.microsoft.com/en-us/research/blog/microsoft-research-and-physics-wallah-team-up-to-enhance-ai-based-tutoring/">Microsoft Research and Physics Wallah team up to enhance AI-based tutoring</a> appeared first on <a href="https://www.microsoft.com/en-us/research">Microsoft Research</a>.</p>
]]></description>
										<content:encoded><![CDATA[
<figure class="wp-block-image size-full"><img fetchpriority="high" decoding="async" width="1400" height="788" src="https://www.microsoft.com/en-us/research/uploads/prod/2025/02/Physics-Wallah-BlogHeroFeature-1400x788-1.jpg" alt="Physics Wallah blog | education icons" class="wp-image-1128240" srcset="https://www.microsoft.com/en-us/research/uploads/prod/2025/02/Physics-Wallah-BlogHeroFeature-1400x788-1.jpg 1400w, https://www.microsoft.com/en-us/research/uploads/prod/2025/02/Physics-Wallah-BlogHeroFeature-1400x788-1-300x169.jpg 300w, https://www.microsoft.com/en-us/research/uploads/prod/2025/02/Physics-Wallah-BlogHeroFeature-1400x788-1-1024x576.jpg 1024w, https://www.microsoft.com/en-us/research/uploads/prod/2025/02/Physics-Wallah-BlogHeroFeature-1400x788-1-768x432.jpg 768w, https://www.microsoft.com/en-us/research/uploads/prod/2025/02/Physics-Wallah-BlogHeroFeature-1400x788-1-1066x600.jpg 1066w, https://www.microsoft.com/en-us/research/uploads/prod/2025/02/Physics-Wallah-BlogHeroFeature-1400x788-1-655x368.jpg 655w, https://www.microsoft.com/en-us/research/uploads/prod/2025/02/Physics-Wallah-BlogHeroFeature-1400x788-1-240x135.jpg 240w, https://www.microsoft.com/en-us/research/uploads/prod/2025/02/Physics-Wallah-BlogHeroFeature-1400x788-1-640x360.jpg 640w, https://www.microsoft.com/en-us/research/uploads/prod/2025/02/Physics-Wallah-BlogHeroFeature-1400x788-1-960x540.jpg 960w, https://www.microsoft.com/en-us/research/uploads/prod/2025/02/Physics-Wallah-BlogHeroFeature-1400x788-1-1280x720.jpg 1280w" sizes="(max-width: 1400px) 100vw, 1400px" /></figure>



<p>In India, limited resources, geographical constraints, and economic factors present barriers to quality education for some students.</p>



<p>A shortage of teachers, particularly in remote or low-income areas, makes it harder for students to receive the guidance they need to prepare for highly competitive professional and academic programs.&nbsp;Microsoft Research is developing new algorithms and techniques that are enabling <a class="msr-external-link glyph-append glyph-append-open-in-new-tab glyph-append-xsmall" href="https://www.pw.live/" target="_blank" rel="noreferrer noopener">Physics Wallah<span class="sr-only"> (opens in new tab)</span></a>, a growing educational company, to make its AI-based tutoring services more accurate and reliable, to better support students on their education journey.</p>



<p>As in other countries, many Indian students purchase coaching and tutoring services to prepare for entrance exams at top institutions. This includes <em>offline</em> coaching, where hundreds of students meet in a classroom staffed by teachers covering a structured curriculum. <em>Online</em> coaching enables students to learn remotely in a virtual classroom. <em>Hybrid</em> coaching delivers virtual lessons in a physical classroom.</p>



<p class="has-text-align-left">Offline courses can cost as much as 100,000 Indian rupees a year—equivalent to hundreds of U.S. dollars. This puts them out of reach for many lower income students living in smaller and mid-sized Indian cities, as well as rural villages. Online courses are much more affordable. They allow students to work at their own pace by providing high-quality web-based content supported by teachers who work remotely.</p>



<figure class="wp-block-image alignright size-medium"><img decoding="async" width="200" height="300" src="https://www.microsoft.com/en-us/research/uploads/prod/2025/02/Vineet_Headshot-200x300.jpeg" alt="Vineet Govil" class="wp-image-1127256" srcset="https://www.microsoft.com/en-us/research/uploads/prod/2025/02/Vineet_Headshot-200x300.jpeg 200w, https://www.microsoft.com/en-us/research/uploads/prod/2025/02/Vineet_Headshot-683x1024.jpeg 683w, https://www.microsoft.com/en-us/research/uploads/prod/2025/02/Vineet_Headshot-768x1152.jpeg 768w, https://www.microsoft.com/en-us/research/uploads/prod/2025/02/Vineet_Headshot-1024x1536.jpeg 1024w, https://www.microsoft.com/en-us/research/uploads/prod/2025/02/Vineet_Headshot-1365x2048.jpeg 1365w, https://www.microsoft.com/en-us/research/uploads/prod/2025/02/Vineet_Headshot-120x180.jpeg 120w, https://www.microsoft.com/en-us/research/uploads/prod/2025/02/Vineet_Headshot-scaled.jpeg 1707w" sizes="(max-width: 200px) 100vw, 200px" /><figcaption class="wp-element-caption">Vineet Govil</figcaption></figure>



<p>Meeting this need is the mission of Physics Wallah. The company uses AI to offer on-demand tutoring at scale, curating volumes of standard science- and math-related content to provide the best answers. Some 2 million students use the Physics Wallah platform every day, at a fraction of the cost of offline tutoring. For example, its prep courses for the Joint Entrance Examination (JEE), which is required for admission to engineering and technology programs, and the National Eligibility cum Entrance Test (NEET), a required entrance exam for medical and dental school candidates, cost between 4,200 and 4,500 rupees per year. That’s roughly 50 U.S. dollars.</p>



<blockquote class="wp-block-quote is-style-spectrum is-layout-flow wp-block-quote-is-layout-flow">
<p>“The mantra here really is how do we provide quality education in an affordable manner and accessible to every student, regardless of who they are or where they come from.”</p>
<cite>—Vineet Govil, Chief Technology and Product Officer, Physics Wallah</cite></blockquote>



<div class="annotations " data-bi-aN="margin-callout">
	<ul class="annotations__list card depth-16 bg-body p-4 annotations__list--left">
		<li class="annotations__list-item">
							<a href="https://www.microsoft.com/en-us/research/articles/microsoft-research-india-celebrating-20-years-of-innovation/" target="_self" aria-label="Celebrating 20 Years at Microsoft Research India" data-bi-type="annotated-link" data-bi-cN="Celebrating 20 Years at Microsoft Research India" class="annotations__list-thumbnail" >
					<img decoding="async" width="172" height="96" src="https://www.microsoft.com/en-us/research/uploads/prod/2023/03/MSR-India-Bangalore-720x405-1-240x135.jpg" class="mb-2" alt="Microsoft Research India, Bangalore" srcset="https://www.microsoft.com/en-us/research/uploads/prod/2023/03/MSR-India-Bangalore-720x405-1-240x135.jpg 240w, https://www.microsoft.com/en-us/research/uploads/prod/2023/03/MSR-India-Bangalore-720x405-1-300x169.jpg 300w, https://www.microsoft.com/en-us/research/uploads/prod/2023/03/MSR-India-Bangalore-720x405-1-655x368.jpg 655w, https://www.microsoft.com/en-us/research/uploads/prod/2023/03/MSR-India-Bangalore-720x405-1-343x193.jpg 343w, https://www.microsoft.com/en-us/research/uploads/prod/2023/03/MSR-India-Bangalore-720x405-1-640x360.jpg 640w, https://www.microsoft.com/en-us/research/uploads/prod/2023/03/MSR-India-Bangalore-720x405-1.jpg 720w" sizes="(max-width: 172px) 100vw, 172px" />				</a>
							<span class="annotations__type d-block text-uppercase font-weight-semibold text-neutral-300 small">TIMELINE</span>
			<a href="https://www.microsoft.com/en-us/research/articles/microsoft-research-india-celebrating-20-years-of-innovation/" target="_self" class="annotations__link font-weight-semibold text-decoration-none" data-bi-type="annotated-link" aria-label="Celebrating 20 Years at Microsoft Research India" data-bi-aN="margin-callout" data-bi-cN="Celebrating 20 Years at Microsoft Research India">
				Celebrating 20 Years at Microsoft Research India&nbsp;<span class="glyph-append glyph-append-chevron-right glyph-append-xsmall"></span>
			</a>
					</li>
	</ul>
</div>



<p>Microsoft Research India’s collaboration with Physics Wallah is part of a 20-year legacy of supporting emerging Indian companies, underscored by the January 2025 announcement that <a class="msr-external-link glyph-append glyph-append-open-in-new-tab glyph-append-xsmall" href="https://news.microsoft.com/en-in/microsoft-announces-us-3bn-investment-over-two-years-in-india-cloud-and-ai-infrastructure-to-accelerate-adoption-of-ai-skilling-and-innovation/" target="_blank" rel="noreferrer noopener">Microsoft will invest $3 billion<span class="sr-only"> (opens in new tab)</span></a> in cloud and AI infrastructure to accelerate the adoption of AI, skilling, and innovation. &nbsp;</p>



<p>Physics Wallah has developed an AI-driven educational suite, <strong>Alakh AI</strong>, leveraging OpenAI’s GPT-4o model through Microsoft Azure OpenAI Service. Alakh AI’s flagship offerings include <strong>AI Guru</strong> and the <strong>Smart Doubt Engine</strong>, both designed to transform the learning experience in and beyond the classroom.</p>



<ul class="wp-block-list">
<li><strong>AI Guru</strong> acts as a personal academic tutor, delivering adaptive guidance based on a student’s progress, real-time question-solving, and customized content that evolves with their learning journey.</li>



<li><strong>Smart Doubt Engine</strong> is an AI tool through which students can ask questions (also known as “doubts” in Indian English) during live classes and receive instant responses.</li>
</ul>



<p>Additionally, the Alakh AI suite includes:</p>



<ul class="wp-block-list">
<li><strong>AI Grader</strong> for subjective answer evaluation without human intervention</li>



<li><strong>Sahayak</strong> for crafting hyper-personalized learning paths tailored to individual students’ needs</li>
</ul>



<p>This innovative ecosystem elevates learning efficiency and accessibility for students.</p>



<figure class="wp-block-image aligncenter size-full"><a data-bi-bhvr="14"  data-bi-cn="Screenshot of AI Guru interface showing a student’s query about Newton’s First Law. The AI tutor responds with a detailed explanation and includes two video resources for additional learning." href="https://www.microsoft.com/en-us/research/uploads/prod/2025/02/AI-Guru-2-scaled.jpg"><img loading="lazy" decoding="async" width="2560" height="2560" src="https://www.microsoft.com/en-us/research/uploads/prod/2025/02/AI-Guru-2-scaled.jpg" alt="Screenshot of AI Guru interface showing a student’s query about Newton’s First Law. The AI tutor responds with a detailed explanation and includes two video resources for additional learning." class="wp-image-1126782" srcset="https://www.microsoft.com/en-us/research/uploads/prod/2025/02/AI-Guru-2-scaled.jpg 2560w, https://www.microsoft.com/en-us/research/uploads/prod/2025/02/AI-Guru-2-300x300.jpg 300w, https://www.microsoft.com/en-us/research/uploads/prod/2025/02/AI-Guru-2-1024x1024.jpg 1024w, https://www.microsoft.com/en-us/research/uploads/prod/2025/02/AI-Guru-2-150x150.jpg 150w, https://www.microsoft.com/en-us/research/uploads/prod/2025/02/AI-Guru-2-768x768.jpg 768w, https://www.microsoft.com/en-us/research/uploads/prod/2025/02/AI-Guru-2-1536x1536.jpg 1536w, https://www.microsoft.com/en-us/research/uploads/prod/2025/02/AI-Guru-2-2048x2048.jpg 2048w, https://www.microsoft.com/en-us/research/uploads/prod/2025/02/AI-Guru-2-180x180.jpg 180w, https://www.microsoft.com/en-us/research/uploads/prod/2025/02/AI-Guru-2-360x360.jpg 360w" sizes="auto, (max-width: 2560px) 100vw, 2560px" /></a><figcaption class="wp-element-caption">AI Guru in action – A student asks, <em>&#8220;Explain Newton’s First Law,&#8221;</em> and the AI tutor provides a detailed explanation along with two videos for further learning.</figcaption></figure>



<div style="height:10px" aria-hidden="true" class="wp-block-spacer"></div>



<figure class="wp-block-image aligncenter size-full"><a data-bi-bhvr="14"  data-bi-cn="Screenshot of the Smart Doubt Engine interface showing a student asking a question about the directrix during a live classroom session. The AI responds with a detailed explanation to clarify the concept." href="https://www.microsoft.com/en-us/research/uploads/prod/2025/02/Smartdoubt.jpg"><img loading="lazy" decoding="async" width="1160" height="478" src="https://www.microsoft.com/en-us/research/uploads/prod/2025/02/Smartdoubt.jpg" alt="Screenshot of the Smart Doubt Engine interface showing a student asking a question about the directrix during a live classroom session. The AI responds with a detailed explanation to clarify the concept." class="wp-image-1126410" srcset="https://www.microsoft.com/en-us/research/uploads/prod/2025/02/Smartdoubt.jpg 1160w, https://www.microsoft.com/en-us/research/uploads/prod/2025/02/Smartdoubt-300x124.jpg 300w, https://www.microsoft.com/en-us/research/uploads/prod/2025/02/Smartdoubt-1024x422.jpg 1024w, https://www.microsoft.com/en-us/research/uploads/prod/2025/02/Smartdoubt-768x316.jpg 768w, https://www.microsoft.com/en-us/research/uploads/prod/2025/02/Smartdoubt-240x99.jpg 240w" sizes="auto, (max-width: 1160px) 100vw, 1160px" /></a><figcaption class="wp-element-caption">Smart Doubt Engine in action – A student asks a clarifying question during a live class, and the AI provides a detailed explanation in real time.</figcaption></figure>



<h2 class="wp-block-heading" id="how-does-ai-guru-work-1">How does AI Guru work?</h2>



<p>Let’s say a student had a question about Newton’s laws of motion, a core concept in physics. She would type her query into the AI Guru chat window (she could also just talk to it or upload an image from a textbook) and receive a text answer plus images derived from standard textbooks and curated content, typically in just a few seconds. AI Guru also provides a short video where a teacher offers additional context.</p>



<div style="height:30px" aria-hidden="true" class="wp-block-spacer"></div>



<h2 class="wp-block-heading" id="getting-the-technology-right-1">Getting the technology right</h2>



<p>The Alakh AI suite is powered by OpenAI&#8217;s foundational models GPT-4 and GPT-4o, integrated with a retrieval-augmented generation (RAG) architecture. It leverages Physics Wallah&#8217;s rich repository of high-quality curated content—developed and refined over several years—along with continuous updates from subject matter experts to ensure new materials, textbooks, tutorials, and question banks are seamlessly incorporated. Despite considerable progress, the existing AI sometimes falters when navigating complex academic problems.</p>



<p>“The accuracy level of today&#8217;s large language models (LLMs) is not up to the mark where we can provide reliable and satisfactory answers to the students all the time—specifically, if it&#8217;s a hard mathematical problem involving complex equations,” Govil said.</p>



<p>That’s one important focus of the collaboration. Researchers from Microsoft Research are developing new algorithms and techniques to enhance the accuracy and reasoning capabilities of AI models. They are now collaborating with Physics Wallah to apply these advancements to the Alakh AI suite, improving its ability to solve complex problems and provide more reliable, step-by-step guidance to students. A key challenge is the nature of student queries, which are often ambiguous and involve multimodal inputs—text, images, videos, or audio—requiring unified capabilities to address the problem. Many STEM problems require breaking down complex queries into logical sub-problems and applying high-order, step-by-step reasoning for consistency. Additionally, integrating domain-specific knowledge in advanced math, physics, chemistry, and biology requires contextualization and seamless retrieval of specialized, grade-appropriate information.&nbsp;</p>



<p>Microsoft Research is working with Physics Wallah to move beyond traditional next-token prediction and develop AI systems that approach reliable, systematic, step-by-step problem-solving.</p>



<p>That includes <a href="https://www.microsoft.com/en-us/research/publication/exposing-the-achilles-heel-evaluating-llms-ability-to-handle-mistakes-in-mathematical-reasoning/">ongoing work</a> to enhance the model’s reasoning capabilities and deliver more accurate query answers on complex JEE math problems. Instead of just providing the final answer, the underlying models now break problems into step-by-step solutions. That helps students learn how to solve the actual problems. The AI can also review student answers, detect mistakes, and give detailed feedback, acting as a personal tutor to guide students, improve their understanding, and enhance their learning experience.</p>



	<div class="border-bottom border-top border-gray-300 mt-5 mb-5 msr-promo text-center text-md-left alignwide" data-bi-aN="promo" data-bi-id="1116360">
		

		<p class="msr-promo__label text-gray-800 text-center text-uppercase">
		<span class="px-4 bg-white display-inline-block font-weight-semibold small">Microsoft Research Blog</span>
	</p>
	
	<div class="row pt-3 pb-4 align-items-center">
						<div class="msr-promo__media col-12 col-md-5">
				<a class="bg-gray-300" href="https://www.microsoft.com/en-us/research/story/microsoft-research-2024-a-year-in-review/" aria-label="Research at Microsoft 2024: Meeting the challenge of a changing world" data-bi-cN="Research at Microsoft 2024: Meeting the challenge of a changing world" target="_blank">
					<img decoding="async" class="w-100 display-block" src="https://www.microsoft.com/en-us/research/uploads/prod/2024/12/Year-in-review-2024_Stories_Hero_Feature-1400x788-1.jpg" alt="Research at Microsoft 2024 - Year in Review" />
				</a>
			</div>
			
			<div class="msr-promo__content p-3 px-5 col-12 col-md">

									<h2 class="h4">Research at Microsoft 2024: Meeting the challenge of a changing world</h2>
				
								<p class="large">In this new AI era, technology is changing even faster than before, and the transition from research to reality, from concept to solution, now takes days or weeks rather than months or years.</p>
				
								<div class="wp-block-buttons justify-content-center justify-content-md-start">
					<div class="wp-block-button">
						<a href="https://www.microsoft.com/en-us/research/story/microsoft-research-2024-a-year-in-review/" class="btn btn-brand glyph-append glyph-append-chevron-right" aria-label="Read more" data-bi-cN="Research at Microsoft 2024: Meeting the challenge of a changing world" target="_blank">
							Read more						</a>
					</div>
				</div>
							</div><!--/.msr-promo__content-->
	</div><!--/.msr-promo__inner-wrap-->
<span id="label-external-link" class="sr-only" aria-hidden="true">Opens in a new tab</span>	</div><!--/.msr-promo-->
	


<p>Solving complex problems requires enhancing the reasoning capabilities of both large and small language models by training them to not just generate answers, but to systematically think through and reason about complex problems. This requires high-quality reasoning traces—detailed, step-by-step breakdowns of logical problem-solving processes.</p>



<p>To enable this, researchers collaborated with Physics Wallah to curate a dataset of 150,000 high-quality math reasoning traces. These traces serve as the foundation for training specialized small language models (SLMs) using supervised fine-tuning (SFT). Model performance is further refined through training on carefully curated on-policy preference data, ensuring alignment with high-quality reasoning standards. The team’s current Phi-based models have already outperformed leading LLMs and other baselines on complex math problems.</p>



<blockquote class="wp-block-quote is-style-spectrum is-layout-flow wp-block-quote-is-layout-flow">
<p>&#8220;Building AI systems capable of human-like thinking and reasoning represents a significant challenge.&#8221;</p>
<cite>—Akshay Nambi, Principal Researcher at Microsoft Research India</cite></blockquote>



<p>The next step is to develop a self-evolving learning pipeline using online reinforcement learning techniques, allowing the model to continuously generate high-quality synthetic data that further enhances its capabilities. Additionally, researchers are building a reward model and integrating it with Monte Carlo Tree Search (MCTS) to optimize reasoning and improve inference-time decision-making.</p>



<p>“The goal is to develop tools that complement education. To do this, we are enhancing the model’s capabilities to process, break down, and solve problems step-by-step. We do this by incorporating high-quality data into training to teach the model how to approach such tasks, alongside algorithmic innovations that enable the model to think and reason more effectively.&#8221;</p>



<hr class="wp-block-separator has-alpha-channel-opacity"/>



<div style="padding-bottom:0; padding-top:0" class="wp-block-msr-immersive-section alignfull row wp-block-msr-immersive-section">
	
	<div class="container">
		<div class="wp-block-msr-immersive-section__inner wp-block-msr-immersive-section__inner--narrow">
			<div class="wp-block-media-text has-vertical-margin-none  has-vertical-padding-none  has-media-on-the-right is-stacked-on-mobile" data-bi-an="media-text"><div class="wp-block-media-text__content" data-bi-an="media-text">
<h3 class="wp-block-heading has-text-align-right" id="insert-fmt-video-in-this-episode-of-the-microsoft-research-podcast-martin-and-daniela">Listen or read along as <a href="https://www.microsoft.com/en-us/research/podcast/ideas-building-ai-for-population-scale-systems-with-akshay-nambi/" target="_blank" rel="noreferrer noopener">Microsoft Research Podcast</a> guest Akshay Nambi shares how his passion for tackling real-world challenges across various domains fuels his work in building reliable and robust AI systems.</h3>
</div><figure class="wp-block-media-text__media"><a href="https://www.microsoft.com/en-us/research/podcast/abstracts-september-30-2024/" target="_blank" rel="noreferrer noopener"><img loading="lazy" decoding="async" width="1024" height="576" src="https://www.microsoft.com/en-us/research/uploads/prod/2025/02/Akshay_Ideas_Hero_Feature_No_Text_1400x788-1024x576.jpg" alt="Outline illustration of Akshay Nambi | Ideas podcast" class="wp-image-1127463 size-full" srcset="https://www.microsoft.com/en-us/research/uploads/prod/2025/02/Akshay_Ideas_Hero_Feature_No_Text_1400x788-1024x576.jpg 1024w, https://www.microsoft.com/en-us/research/uploads/prod/2025/02/Akshay_Ideas_Hero_Feature_No_Text_1400x788-300x169.jpg 300w, https://www.microsoft.com/en-us/research/uploads/prod/2025/02/Akshay_Ideas_Hero_Feature_No_Text_1400x788-768x432.jpg 768w, https://www.microsoft.com/en-us/research/uploads/prod/2025/02/Akshay_Ideas_Hero_Feature_No_Text_1400x788-1066x600.jpg 1066w, https://www.microsoft.com/en-us/research/uploads/prod/2025/02/Akshay_Ideas_Hero_Feature_No_Text_1400x788-655x368.jpg 655w, https://www.microsoft.com/en-us/research/uploads/prod/2025/02/Akshay_Ideas_Hero_Feature_No_Text_1400x788-240x135.jpg 240w, https://www.microsoft.com/en-us/research/uploads/prod/2025/02/Akshay_Ideas_Hero_Feature_No_Text_1400x788-640x360.jpg 640w, https://www.microsoft.com/en-us/research/uploads/prod/2025/02/Akshay_Ideas_Hero_Feature_No_Text_1400x788-960x540.jpg 960w, https://www.microsoft.com/en-us/research/uploads/prod/2025/02/Akshay_Ideas_Hero_Feature_No_Text_1400x788-1280x720.jpg 1280w, https://www.microsoft.com/en-us/research/uploads/prod/2025/02/Akshay_Ideas_Hero_Feature_No_Text_1400x788.jpg 1401w" sizes="auto, (max-width: 1024px) 100vw, 1024px" /></a></figure></div>		</div>
	</div>

	</div>



<hr class="wp-block-separator has-alpha-channel-opacity"/>



<h2 class="wp-block-heading" id="opening-new-doors-for-students-1">Opening new doors for students</h2>



<figure class="wp-block-image alignright size-full is-resized"><img loading="lazy" decoding="async" width="360" height="360" src="https://www.microsoft.com/en-us/research/uploads/prod/2025/02/Chandramouleswar-Parida_360x360.jpg" alt="Chandramouleswar Parida" class="wp-image-1126932" style="width:176px" srcset="https://www.microsoft.com/en-us/research/uploads/prod/2025/02/Chandramouleswar-Parida_360x360.jpg 360w, https://www.microsoft.com/en-us/research/uploads/prod/2025/02/Chandramouleswar-Parida_360x360-300x300.jpg 300w, https://www.microsoft.com/en-us/research/uploads/prod/2025/02/Chandramouleswar-Parida_360x360-150x150.jpg 150w, https://www.microsoft.com/en-us/research/uploads/prod/2025/02/Chandramouleswar-Parida_360x360-180x180.jpg 180w" sizes="auto, (max-width: 360px) 100vw, 360px" /><figcaption class="wp-element-caption">Chandramouleswar Parida</figcaption></figure>



<p>Getting an education at a top university can be life changing for anyone. For Chandramouleswar Parida, it could change the lives of everyone in his home village in Baniatangi, Khordha, Odisha State, India. Chandra decided to become a doctor after watching his grandfather die from a heart attack. The nearest doctor who could have treated him was at a regional hospital 65 kilometers away.</p>



<p>“He could have been saved if certain procedures had been followed,” Chandra said. He wants to study medicine, perhaps receiving advanced training overseas, and then return home. “I want to be a doctor here in our village and serve our people, because there is a lack of treatment. Being a doctor is a very noble kind of job in this society.”</p>



<p>Chandra is the only student in Baniatangi Village, Khordha, Odisha, currently preparing for the NEET. Without Physics Wallah, students like Chandra would likely have no access to the support and resources that can’t be found locally.</p>



<figure class="wp-block-image alignright size-large is-resized"><img loading="lazy" decoding="async" width="606" height="1024" src="https://www.microsoft.com/en-us/research/uploads/prod/2025/02/Student_Headshot_PW-606x1024.jpeg" alt="Anushka Sunil Dhanwade" class="wp-image-1126068" style="width:176px" srcset="https://www.microsoft.com/en-us/research/uploads/prod/2025/02/Student_Headshot_PW-606x1024.jpeg 606w, https://www.microsoft.com/en-us/research/uploads/prod/2025/02/Student_Headshot_PW-178x300.jpeg 178w, https://www.microsoft.com/en-us/research/uploads/prod/2025/02/Student_Headshot_PW-107x180.jpeg 107w, https://www.microsoft.com/en-us/research/uploads/prod/2025/02/Student_Headshot_PW.jpeg 691w" sizes="auto, (max-width: 606px) 100vw, 606px" /><figcaption class="wp-element-caption">Anushka Sunil Dhanwade</figcaption></figure>



<p>Another student, Anushka Sunil Dhanwade, is optimistic that Physics Wallah will help her dramatically improve her initial score on the NEET exam. While in 11th class, or grade, she joined an online NEET prep class with 800 students. But she struggled to follow the coursework, as the teachers tailored the content to the strongest students. After posting a low score on the NEET exam, her hopes of becoming a doctor were fading.</p>



<p>But after a serious stomach illness reminded her of the value of having a doctor in her family, she tried again, this time with Physics Wallah and AI Guru. After finishing 12th class, she began preparing for NEET and plans to take the exams again in May, confident that she will increase her score.</p>



<blockquote class="wp-block-quote is-style-spectrum--blue-green is-layout-flow wp-block-quote-is-layout-flow">
<p>“AI Guru has made my learning so smooth and easy because it provides me answers related to my study and study-related doubt just within a click.”</p>
<cite>—Anushka Sunil Dhanwade, Student</cite></blockquote>



<h2 class="wp-block-heading" id="next-steps-in-the-collaboration-1">Next steps in the collaboration</h2>



<p>The collaboration between Microsoft Research and Physics Wallah aims to apply the advancements in solving math problems across additional subjects, ultimately creating a unified <em>education LLM</em> with enhanced reasoning capabilities and improved accuracy to support student learning.</p>



<p>“We’re working on an education-specific LLM that will be fine-tuned using the extensive data we’ve gathered and enriched by Microsoft’s expertise in LLM training and algorithms. Our goal is to create a unified model that significantly improves accuracy and raises student satisfaction rates to 95% and beyond,” Govil explained.</p>



<p>The teams are also integrating a new tool from Microsoft Research called <a class="msr-external-link glyph-append glyph-append-open-in-new-tab glyph-append-xsmall" href="https://github.com/microsoft/PromptWizard/" target="_blank" rel="noreferrer noopener">PromptWizard<span class="sr-only"> (opens in new tab)</span></a>, an automated framework for optimizing the instructions given to a model, into Physics Wallah’s offerings. New prompts can now be generated in minutes, eliminating months of manual work, while providing more accurate and aligned answers for students.</p>



<p>For Nambi and the Microsoft Research India team, the collaboration is the latest example of their deep commitment to cultivating the AI ecosystem in India and translating new technology from the lab into useful business applications.</p>



<p>“By leveraging advanced reasoning techniques and domain expertise, we are transforming how AI addresses challenges across multiple subjects. This represents a key step in building AI systems that act as holistic personal tutors, enhancing student understanding and creating a more engaging learning experience,” Nambi said.</p>



<h3 class="wp-block-heading" id="explore-more">Explore more</h3>



<div class="wp-block-columns is-layout-flex wp-container-core-columns-is-layout-1 wp-block-columns-is-layout-flex">
<div class="wp-block-column is-layout-flow wp-block-column-is-layout-flow">
<div class="annotations " data-bi-aN="citation">
	<ul class="annotations__list card depth-16 bg-body p-4 ">
		<li class="annotations__list-item">
							<a href="https://www.microsoft.com/en-us/research/blog/promptwizard-the-future-of-prompt-optimization-through-feedback-driven-self-evolving-prompts/" target="_self" aria-label="PromptWizard: The future of prompt optimization through feedback-driven self-evolving prompts" data-bi-type="annotated-link" data-bi-cN="PromptWizard: The future of prompt optimization through feedback-driven self-evolving prompts" class="annotations__list-thumbnail" >
					<img loading="lazy" decoding="async" width="172" height="96" src="https://www.microsoft.com/en-us/research/uploads/prod/2024/12/PromptWizard-BlogHeroFeature-1400x788-1-240x135.png" class="mb-2" alt="A diagram illustrating the joint optimization process of instructions and in-context examples in PromptWizard. The figure demonstrates how the framework iteratively refines both components, integrating feedback to enhance the overall prompt effectiveness and adaptability across tasks." srcset="https://www.microsoft.com/en-us/research/uploads/prod/2024/12/PromptWizard-BlogHeroFeature-1400x788-1-240x135.png 240w, https://www.microsoft.com/en-us/research/uploads/prod/2024/12/PromptWizard-BlogHeroFeature-1400x788-1-300x169.png 300w, https://www.microsoft.com/en-us/research/uploads/prod/2024/12/PromptWizard-BlogHeroFeature-1400x788-1-1024x576.png 1024w, https://www.microsoft.com/en-us/research/uploads/prod/2024/12/PromptWizard-BlogHeroFeature-1400x788-1-768x432.png 768w, https://www.microsoft.com/en-us/research/uploads/prod/2024/12/PromptWizard-BlogHeroFeature-1400x788-1-1066x600.png 1066w, https://www.microsoft.com/en-us/research/uploads/prod/2024/12/PromptWizard-BlogHeroFeature-1400x788-1-655x368.png 655w, https://www.microsoft.com/en-us/research/uploads/prod/2024/12/PromptWizard-BlogHeroFeature-1400x788-1-640x360.png 640w, https://www.microsoft.com/en-us/research/uploads/prod/2024/12/PromptWizard-BlogHeroFeature-1400x788-1-960x540.png 960w, https://www.microsoft.com/en-us/research/uploads/prod/2024/12/PromptWizard-BlogHeroFeature-1400x788-1-1280x720.png 1280w, https://www.microsoft.com/en-us/research/uploads/prod/2024/12/PromptWizard-BlogHeroFeature-1400x788-1.png 1400w" sizes="auto, (max-width: 172px) 100vw, 172px" />				</a>
							<span class="annotations__type d-block text-uppercase font-weight-semibold text-neutral-300 small">Blog</span>
			<a href="https://www.microsoft.com/en-us/research/blog/promptwizard-the-future-of-prompt-optimization-through-feedback-driven-self-evolving-prompts/" target="_self" class="annotations__link font-weight-semibold text-decoration-none" data-bi-type="annotated-link" aria-label="PromptWizard: The future of prompt optimization through feedback-driven self-evolving prompts" data-bi-aN="citation" data-bi-cN="PromptWizard: The future of prompt optimization through feedback-driven self-evolving prompts">
				PromptWizard: The future of prompt optimization through feedback-driven self-evolving prompts&nbsp;<span class="glyph-append glyph-append-chevron-right glyph-append-xsmall"></span>
			</a>
					</li>
	</ul>
</div>
</div>



<div class="wp-block-column is-layout-flow wp-block-column-is-layout-flow">
<div class="annotations " data-bi-aN="citation">
	<ul class="annotations__list card depth-16 bg-body p-4 ">
		<li class="annotations__list-item">
							<a href="https://www.microsoft.com/en-us/research/podcast/ideas-language-technologies-for-everyone-with-kalika-bali/" target="_self" aria-label="Ideas: Language technologies for everyone with Kalika Bali" data-bi-type="annotated-link" data-bi-cN="Ideas: Language technologies for everyone with Kalika Bali" class="annotations__list-thumbnail" >
					<img loading="lazy" decoding="async" width="172" height="96" src="https://www.microsoft.com/en-us/research/uploads/prod/2024/04/Kalika-Bali_IDEAS_Hero_Feature_No_Text_1400x788_AH-240x135.png" class="mb-2" alt="Microsoft Research Podcast | Ideas | Kalika Bali" srcset="https://www.microsoft.com/en-us/research/uploads/prod/2024/04/Kalika-Bali_IDEAS_Hero_Feature_No_Text_1400x788_AH-240x135.png 240w, https://www.microsoft.com/en-us/research/uploads/prod/2024/04/Kalika-Bali_IDEAS_Hero_Feature_No_Text_1400x788_AH-300x169.png 300w, https://www.microsoft.com/en-us/research/uploads/prod/2024/04/Kalika-Bali_IDEAS_Hero_Feature_No_Text_1400x788_AH-1024x576.png 1024w, https://www.microsoft.com/en-us/research/uploads/prod/2024/04/Kalika-Bali_IDEAS_Hero_Feature_No_Text_1400x788_AH-768x432.png 768w, https://www.microsoft.com/en-us/research/uploads/prod/2024/04/Kalika-Bali_IDEAS_Hero_Feature_No_Text_1400x788_AH-1066x600.png 1066w, https://www.microsoft.com/en-us/research/uploads/prod/2024/04/Kalika-Bali_IDEAS_Hero_Feature_No_Text_1400x788_AH-655x368.png 655w, https://www.microsoft.com/en-us/research/uploads/prod/2024/04/Kalika-Bali_IDEAS_Hero_Feature_No_Text_1400x788_AH-640x360.png 640w, https://www.microsoft.com/en-us/research/uploads/prod/2024/04/Kalika-Bali_IDEAS_Hero_Feature_No_Text_1400x788_AH-960x540.png 960w, https://www.microsoft.com/en-us/research/uploads/prod/2024/04/Kalika-Bali_IDEAS_Hero_Feature_No_Text_1400x788_AH-1280x720.png 1280w, https://www.microsoft.com/en-us/research/uploads/prod/2024/04/Kalika-Bali_IDEAS_Hero_Feature_No_Text_1400x788_AH.png 1400w" sizes="auto, (max-width: 172px) 100vw, 172px" />				</a>
							<span class="annotations__type d-block text-uppercase font-weight-semibold text-neutral-300 small">Podcast</span>
			<a href="https://www.microsoft.com/en-us/research/podcast/ideas-language-technologies-for-everyone-with-kalika-bali/" target="_self" class="annotations__link font-weight-semibold text-decoration-none" data-bi-type="annotated-link" aria-label="Ideas: Language technologies for everyone with Kalika Bali" data-bi-aN="citation" data-bi-cN="Ideas: Language technologies for everyone with Kalika Bali">
				Ideas: Language technologies for everyone with Kalika Bali&nbsp;<span class="glyph-append glyph-append-chevron-right glyph-append-xsmall"></span>
			</a>
					</li>
	</ul>
</div>
</div>
</div>



<div class="wp-block-columns is-layout-flex wp-container-core-columns-is-layout-2 wp-block-columns-is-layout-flex">
<div class="wp-block-column is-layout-flow wp-block-column-is-layout-flow">
<div class="annotations " data-bi-aN="citation">
	<ul class="annotations__list card depth-16 bg-body p-4 ">
		<li class="annotations__list-item">
							<a href="https://www.microsoft.com/en-us/research/blog/teachers-in-india-help-microsoft-research-design-ai-tool-for-creating-great-classroom-content/" target="_self" aria-label="Teachers in India help Microsoft Research design AI tool for creating great classroom content" data-bi-type="annotated-link" data-bi-cN="Teachers in India help Microsoft Research design AI tool for creating great classroom content" class="annotations__list-thumbnail" >
					<img loading="lazy" decoding="async" width="172" height="96" src="https://www.microsoft.com/en-us/research/uploads/prod/2023/10/VeLLUM-BlogHeroFeature-1400x788-2-240x135.jpg" class="mb-2" alt="a group of people sitting at a desk in front of a crowd" srcset="https://www.microsoft.com/en-us/research/uploads/prod/2023/10/VeLLUM-BlogHeroFeature-1400x788-2-240x135.jpg 240w, https://www.microsoft.com/en-us/research/uploads/prod/2023/10/VeLLUM-BlogHeroFeature-1400x788-2-300x169.jpg 300w, https://www.microsoft.com/en-us/research/uploads/prod/2023/10/VeLLUM-BlogHeroFeature-1400x788-2-1024x576.jpg 1024w, https://www.microsoft.com/en-us/research/uploads/prod/2023/10/VeLLUM-BlogHeroFeature-1400x788-2-768x432.jpg 768w, https://www.microsoft.com/en-us/research/uploads/prod/2023/10/VeLLUM-BlogHeroFeature-1400x788-2-1066x600.jpg 1066w, https://www.microsoft.com/en-us/research/uploads/prod/2023/10/VeLLUM-BlogHeroFeature-1400x788-2-655x368.jpg 655w, https://www.microsoft.com/en-us/research/uploads/prod/2023/10/VeLLUM-BlogHeroFeature-1400x788-2-343x193.jpg 343w, https://www.microsoft.com/en-us/research/uploads/prod/2023/10/VeLLUM-BlogHeroFeature-1400x788-2-640x360.jpg 640w, https://www.microsoft.com/en-us/research/uploads/prod/2023/10/VeLLUM-BlogHeroFeature-1400x788-2-960x540.jpg 960w, https://www.microsoft.com/en-us/research/uploads/prod/2023/10/VeLLUM-BlogHeroFeature-1400x788-2-1280x720.jpg 1280w, https://www.microsoft.com/en-us/research/uploads/prod/2023/10/VeLLUM-BlogHeroFeature-1400x788-2.jpg 1400w" sizes="auto, (max-width: 172px) 100vw, 172px" />				</a>
							<span class="annotations__type d-block text-uppercase font-weight-semibold text-neutral-300 small">Blog</span>
			<a href="https://www.microsoft.com/en-us/research/blog/teachers-in-india-help-microsoft-research-design-ai-tool-for-creating-great-classroom-content/" target="_self" class="annotations__link font-weight-semibold text-decoration-none" data-bi-type="annotated-link" aria-label="Teachers in India help Microsoft Research design AI tool for creating great classroom content" data-bi-aN="citation" data-bi-cN="Teachers in India help Microsoft Research design AI tool for creating great classroom content">
				Teachers in India help Microsoft Research design AI tool for creating great classroom content&nbsp;<span class="glyph-append glyph-append-chevron-right glyph-append-xsmall"></span>
			</a>
					</li>
	</ul>
</div>
</div>



<div class="wp-block-column is-layout-flow wp-block-column-is-layout-flow">
<div class="annotations " data-bi-aN="citation">
	<ul class="annotations__list card depth-16 bg-body p-4 ">
		<li class="annotations__list-item">
							<a href="https://youtu.be/EgXJj5X260M" target="_blank" aria-label="Shiksha copilot demo" data-bi-type="annotated-link" data-bi-cN="Shiksha copilot demo" class="annotations__list-thumbnail" >
					<img loading="lazy" decoding="async" width="172" height="96" src="https://www.microsoft.com/en-us/research/uploads/prod/2024/12/shiksha-Hero-640x360.jpg" class="mb-2" alt="group of students talking to their teacher" srcset="https://www.microsoft.com/en-us/research/uploads/prod/2024/12/shiksha-Hero-640x360.jpg 640w, https://www.microsoft.com/en-us/research/uploads/prod/2024/12/shiksha-Hero-1066x600.jpg 1066w, https://www.microsoft.com/en-us/research/uploads/prod/2024/12/shiksha-Hero-655x368.jpg 655w, https://www.microsoft.com/en-us/research/uploads/prod/2024/12/shiksha-Hero-960x540.jpg 960w, https://www.microsoft.com/en-us/research/uploads/prod/2024/12/shiksha-Hero-1280x720.jpg 1280w, https://www.microsoft.com/en-us/research/uploads/prod/2024/12/shiksha-Hero-1920x1080.jpg 1920w" sizes="auto, (max-width: 172px) 100vw, 172px" />				</a>
							<span class="annotations__type d-block text-uppercase font-weight-semibold text-neutral-300 small">Video</span>
			<a href="https://youtu.be/EgXJj5X260M" target="_blank" class="annotations__link font-weight-semibold text-decoration-none" data-bi-type="annotated-link" aria-label="Shiksha copilot demo" data-bi-aN="citation" data-bi-cN="Shiksha copilot demo">
				Shiksha copilot demo&nbsp;<span class="glyph-append glyph-append-share glyph-append-xsmall"></span>
			</a>
					</li>
	</ul>
</div>
</div>
</div>
<span id="label-external-link" class="sr-only" aria-hidden="true">Opens in a new tab</span><p>The post <a href="https://www.microsoft.com/en-us/research/blog/microsoft-research-and-physics-wallah-team-up-to-enhance-ai-based-tutoring/">Microsoft Research and Physics Wallah team up to enhance AI-based tutoring</a> appeared first on <a href="https://www.microsoft.com/en-us/research">Microsoft Research</a>.</p>
]]></content:encoded>
					
		
		
			</item>
		<item>
		<title>ExACT: Improving AI agents’ decision-making via test-time compute scaling</title>
		<link>https://www.microsoft.com/en-us/research/blog/exact-improving-ai-agents-decision-making-via-test-time-compute-scaling/</link>
		
		<dc:creator><![CDATA[Alyssa Hughes (2ADAPTIVE LLC dba 2A Consulting)]]></dc:creator>
		<pubDate>Tue, 11 Feb 2025 22:21:47 +0000</pubDate>
				<category><![CDATA[Research Blog]]></category>
		<guid isPermaLink="false">https://www.microsoft.com/en-us/research/?p=1121829</guid>

					<description><![CDATA[<p>ExACT combines Reflective-MCTS and Exploratory Learning to improve AI agents' decision-making, enabling test-time compute scaling. Learn how these methods help agents refine strategies for state-of-the-art performance and improved computational efficiency.</p>
<p>The post <a href="https://www.microsoft.com/en-us/research/blog/exact-improving-ai-agents-decision-making-via-test-time-compute-scaling/">ExACT: Improving AI agents’ decision-making via test-time compute scaling</a> appeared first on <a href="https://www.microsoft.com/en-us/research">Microsoft Research</a>.</p>
]]></description>
										<content:encoded><![CDATA[
<figure class="wp-block-image size-full"><img loading="lazy" decoding="async" width="1400" height="788" src="https://www.microsoft.com/en-us/research/uploads/prod/2025/01/ExACT-BlogHeroFeature-1400x788-1.png" alt="A gradient blue to green background features a white flowchart with rectangular boxes connected by arrows, ending in a hexagonal “STOP” sign and a check mark on the right side." class="wp-image-1124370" srcset="https://www.microsoft.com/en-us/research/uploads/prod/2025/01/ExACT-BlogHeroFeature-1400x788-1.png 1400w, https://www.microsoft.com/en-us/research/uploads/prod/2025/01/ExACT-BlogHeroFeature-1400x788-1-300x169.png 300w, https://www.microsoft.com/en-us/research/uploads/prod/2025/01/ExACT-BlogHeroFeature-1400x788-1-1024x576.png 1024w, https://www.microsoft.com/en-us/research/uploads/prod/2025/01/ExACT-BlogHeroFeature-1400x788-1-768x432.png 768w, https://www.microsoft.com/en-us/research/uploads/prod/2025/01/ExACT-BlogHeroFeature-1400x788-1-1066x600.png 1066w, https://www.microsoft.com/en-us/research/uploads/prod/2025/01/ExACT-BlogHeroFeature-1400x788-1-655x368.png 655w, https://www.microsoft.com/en-us/research/uploads/prod/2025/01/ExACT-BlogHeroFeature-1400x788-1-240x135.png 240w, https://www.microsoft.com/en-us/research/uploads/prod/2025/01/ExACT-BlogHeroFeature-1400x788-1-640x360.png 640w, https://www.microsoft.com/en-us/research/uploads/prod/2025/01/ExACT-BlogHeroFeature-1400x788-1-960x540.png 960w, https://www.microsoft.com/en-us/research/uploads/prod/2025/01/ExACT-BlogHeroFeature-1400x788-1-1280x720.png 1280w" sizes="auto, (max-width: 1400px) 100vw, 1400px" /></figure>



<p>Autonomous AI agents are transforming the way we approach multi-step decision-making processes, streamlining tasks like web browsing, video editing, and file management. By applying advanced machine learning, they automate workflows, optimize performance, and reduce the need for human input.&nbsp;</p>



<p>However, these systems struggle in complex, dynamic environments. A key challenge lies in balancing <em>exploitation, </em>using known strategies for immediate gains, with <em>exploration</em>, which involves seeking new strategies that could yield long-term benefits. Additionally, they often have difficulty adapting to unpredictable changes in conditions and objectives, as well as generalizing knowledge across contexts, limiting their ability to transfer learned strategies between domains.&nbsp;</p>



<p>In response, we developed <a href="https://www.microsoft.com/en-us/research/publication/exact-teaching-ai-agents-to-explore-with-reflective-mcts-and-exploratory-learning/?msockid=03509714880a63312154827889b062b6">ExACT</a>, an approach for teaching AI agents to explore more effectively, enabling them to intelligently navigate their environments, gather valuable information, evaluate options, and identify optimal decision-making and planning strategies. ExACT combines two key techniques: Reflective-MCTS (R-MCTS) and Exploratory Learning.</p>



<p>R-MCTS builds on the traditional Monte Carlo Tree Search (MCTS) algorithm, introducing features like contrastive reflection and a multi-agent debate function. Through contrastive reflection, the agent refines its decision-making by comparing expected outcomes with actual results, allowing it to learn from both its successes and mistakes. The multi-agent debate function provides various evaluations of a given state, where multiple agents offer contrasting perspectives to help provide a balanced and reliable assessment.</p>



<p>Exploratory Learning trains agents to navigate environments effectively. Together, these techniques show strong computational scalability during both training and testing, as demonstrated on VisualWebArena—a benchmark for evaluating multimodal autonomous language agents (Figure 1).&nbsp;</p>



<figure class="wp-block-image aligncenter size-full"><a data-bi-bhvr="14"  data-bi-cn="Evaluation demonstrates the compute scaling properties of GPT-4o during both training and testing. The assessment includes two scenarios: (1) applying the GPT-4o-based R-MCTS agent to all 234 tasks from the Classifieds category in VisualWebArena (left), and (2) testing fine-tuned GPT-4o on 169 previously unseen tasks from Classifieds without using search algorithms (right)." href="https://www.microsoft.com/en-us/research/uploads/prod/2025/01/Figure-1-Scaling.gif.gif"><img loading="lazy" decoding="async" width="1920" height="728" src="https://www.microsoft.com/en-us/research/uploads/prod/2025/01/Figure-1-Scaling.gif.gif" alt="Evaluation demonstrates the compute scaling properties of GPT-4o during both training and testing. The assessment includes two scenarios: (1) applying the GPT-4o-based R-MCTS agent to all 234 tasks from the Classifieds category in VisualWebArena (left), and (2) testing fine-tuned GPT-4o on 169 previously unseen tasks from Classifieds without using search algorithms (right)." class="wp-image-1121919" style="object-fit:cover"/></a><figcaption class="wp-element-caption">Figure 1. Evaluation demonstrates the compute scaling properties of GPT-4o during both training and testing. The assessment includes two scenarios: (1) applying the GPT-4o-based R-MCTS agent to all 234 tasks from the Classifieds category in VisualWebArena (left), and (2) testing fine-tuned GPT-4o on 169 previously unseen tasks from Classifieds without using search algorithms (right).</figcaption></figure>



<p>R-MCTS extends the classic MCTS by enabling real-time improvements in decision-making. Shown in Figure 2, an iterative feedback loop allows R-MCTS to learn from past experiences, avoid prior mistakes, and focus on more effective actions in similar contexts.</p>



<figure class="wp-block-image aligncenter size-full is-resized"><a data-bi-bhvr="14"  data-bi-cn="Overview of the R-MCTS process in ExACT. " href="https://www.microsoft.com/en-us/research/uploads/prod/2025/01/ExACT_Fig2.png"><img loading="lazy" decoding="async" width="852" height="820" src="https://www.microsoft.com/en-us/research/uploads/prod/2025/01/ExACT_Fig2.png" alt="Overview of the R-MCTS process in ExACT. " class="wp-image-1121877" style="width:504px;height:auto" srcset="https://www.microsoft.com/en-us/research/uploads/prod/2025/01/ExACT_Fig2.png 852w, https://www.microsoft.com/en-us/research/uploads/prod/2025/01/ExACT_Fig2-300x289.png 300w, https://www.microsoft.com/en-us/research/uploads/prod/2025/01/ExACT_Fig2-768x739.png 768w, https://www.microsoft.com/en-us/research/uploads/prod/2025/01/ExACT_Fig2-187x180.png 187w" sizes="auto, (max-width: 852px) 100vw, 852px" /></a><figcaption class="wp-element-caption">Figure 2. Overview of the R-MCTS process in ExACT.<em>&nbsp;</em></figcaption></figure>



<h3 class="wp-block-heading" id="evaluating-r-mcts">Evaluating R-MCTS</h3>



<p>R-MCTS demonstrates state-of-the-art performance across all VisualWebArena environments, surpassing the previous best-performing method, Search Agent, with improvements ranging from 6% to 30% (Table 1). Additionally, as of January 2025, it holds the second position on the OSWorld leaderboard and demonstrates state-of-the-art performance in the blind test setting, where there is no prior access to the test environment, reflecting its advanced capabilities (Table 2).&nbsp;</p>



<figure class="wp-block-table aligncenter is-style-stripes"><table><thead><tr><th>Rank</th><th>Model</th><th>Score</th></tr></thead><tbody><tr><td><strong>1</strong></td><td>GPT-4o + ExACT</td><td>33.70</td></tr><tr><td><strong>2</strong></td><td>GPT-4o + Search</td><td>26.40</td></tr><tr><td><strong>3</strong></td><td>GPT-4o + WebDreamer</td><td>23.60</td></tr><tr><td><strong>4</strong></td><td>GPT-4o + ICAL</td><td>23.40</td></tr><tr><td><strong>5</strong></td><td>GPT-4o</td><td>19.78</td></tr><tr><td><strong>6</strong></td><td>Llama-3-70B + Search</td><td>16.70</td></tr></tbody></table><figcaption class="wp-element-caption">Table 1. The VisualWebArena leaderboard highlights R-MCTS as achieving state-of-the-art performance as of December 2024.<em>&nbsp;</em></figcaption></figure>



<figure class="wp-block-table aligncenter is-style-stripes"><table><thead><tr><th>Rank</th><th>Model</th><th>Blind Test</th><th>Score</th></tr></thead><tbody><tr><td><strong>1</strong></td><td>learn-by-interact w/ Claude-3.5-sonnet</td><td>🗶</td><td>22.50</td></tr><tr><td><strong>2</strong></td><td>ExACT w/ GPT-4o</td><td><img src="https://s.w.org/images/core/emoji/15.0.3/72x72/2714.png" alt="✔" class="wp-smiley" style="height: 1em; max-height: 1em;" /></td><td>16.60</td></tr><tr><td><strong>3</strong></td><td>GPT-4</td><td><img src="https://s.w.org/images/core/emoji/15.0.3/72x72/2714.png" alt="✔" class="wp-smiley" style="height: 1em; max-height: 1em;" /></td><td>12.24</td></tr><tr><td><strong>4</strong></td><td>GPT-4o</td><td><img src="https://s.w.org/images/core/emoji/15.0.3/72x72/2714.png" alt="✔" class="wp-smiley" style="height: 1em; max-height: 1em;" /></td><td>11.36</td></tr><tr><td><strong>5</strong></td><td>GPT-4 Vision (0409)</td><td><img src="https://s.w.org/images/core/emoji/15.0.3/72x72/2714.png" alt="✔" class="wp-smiley" style="height: 1em; max-height: 1em;" /></td><td>10.82</td></tr><tr><td><strong>6</strong></td><td>learn-by-interact w/ Gemini-1.5-pro</td><td><img src="https://s.w.org/images/core/emoji/15.0.3/72x72/2714.png" alt="✔" class="wp-smiley" style="height: 1em; max-height: 1em;" /></td><td>10.30</td></tr></tbody></table><figcaption class="wp-element-caption">Table 2. The OSWorld leaderboard for the category of A11y tree inputs shows that ExACT with GPT-4o ranks second and demonstrates state-of-the-art performance in the blind test setting, as of December 2024.</figcaption></figure>



<h2 class="wp-block-heading" id="how-exploratory-learning-works">How Exploratory Learning works</h2>



<p>Exploratory Learning enables agents to dynamically search and adjust their computational resources during testing without depending on MCTS. In contrast to Imitation Learning, which centers on training models using the optimal actions identified through search, Exploratory Learning focuses on cultivating the agent&#8217;s ability to navigate its environment by teaching it to evaluate states, explore different pathways, and efficiently backtrack from unpromising paths to identify more favorable alternatives.&nbsp;</p>



<figure class="wp-block-image aligncenter size-full is-resized"><a data-bi-bhvr="14"  data-bi-cn="In contrast to Imitation Learning, Exploratory Learning uses the entire search trajectory for training." href="https://www.microsoft.com/en-us/research/uploads/prod/2025/01/ExACT_Fig3.png"><img loading="lazy" decoding="async" width="1334" height="453" src="https://www.microsoft.com/en-us/research/uploads/prod/2025/01/ExACT_Fig3.png" alt="In contrast to Imitation Learning, Exploratory Learning uses the entire search trajectory for training." class="wp-image-1121880" style="width:776px;height:auto" srcset="https://www.microsoft.com/en-us/research/uploads/prod/2025/01/ExACT_Fig3.png 1334w, https://www.microsoft.com/en-us/research/uploads/prod/2025/01/ExACT_Fig3-300x102.png 300w, https://www.microsoft.com/en-us/research/uploads/prod/2025/01/ExACT_Fig3-1024x348.png 1024w, https://www.microsoft.com/en-us/research/uploads/prod/2025/01/ExACT_Fig3-768x261.png 768w, https://www.microsoft.com/en-us/research/uploads/prod/2025/01/ExACT_Fig3-240x81.png 240w" sizes="auto, (max-width: 1334px) 100vw, 1334px" /></a><figcaption class="wp-element-caption">Figure 3. In contrast to Imitation Learning, Exploratory Learning uses the entire search trajectory for training.</figcaption></figure>



<h3 class="wp-block-heading" id="evaluating-exploratory-learning">Evaluating Exploratory Learning</h3>



<p>We conducted experiments using GPT-4o fine-tuned with Exploratory Learning in the VisualWebArena environment. Results demonstrate the following key benefits:&nbsp;</p>



<ul class="wp-block-list">
<li><strong>Improved performance</strong>: GPT-4o achieves performance improvement, comparable with scaling test-time compute with MCTS, even without search.</li>



<li><strong>Test-time compute scaling</strong>: GPT-4o performs better when given more actions per task, leading to improved decision-making and task completion, which increased from 5% to 12.4%.&nbsp;</li>



<li><strong>Improved generalization on unseen tasks</strong>: Exploratory Learning helps fine-tuned GPT-4o handle unseen tasks more effectively than agents trained with Imitation Learning or no additional training.</li>
</ul>



<p>The following video provides a detailed demonstration of how R-MCTS and Exploratory Learning function.</p>



<figure class="wp-block-video"><video controls src="https://www.microsoft.com/en-us/research/uploads/prod/2025/01/ExACT_Videos_010925_V1.mp4" playsinline></video></figure>



<h2 class="wp-block-heading" id="continued-exploration">Continued exploration</h2>



<p>Advancing autonomous AI agents is key to enabling them to handle complex, multi-step tasks with greater precision and adaptability. ExACT represents a significant step toward creating agents that can perform complex decision-making before taking action, leading to improved performance, but challenges remain. How can AI agents improve decision-making in real-world scenarios, where they may be constrained by time or resources? How can they learn effectively and efficiently from environmental feedback? We are currently investigating these questions, and we invite you to explore them with us by building on the ExACT framework. Access the ExACT code at our <a class="msr-external-link glyph-append glyph-append-open-in-new-tab glyph-append-xsmall" href="https://github.com/microsoft/ExACT" target="_blank" rel="noreferrer noopener">GitHub repository<span class="sr-only"> (opens in new tab)</span></a>.&nbsp;</p>
<span id="label-external-link" class="sr-only" aria-hidden="true">Opens in a new tab</span><p>The post <a href="https://www.microsoft.com/en-us/research/blog/exact-improving-ai-agents-decision-making-via-test-time-compute-scaling/">ExACT: Improving AI agents’ decision-making via test-time compute scaling</a> appeared first on <a href="https://www.microsoft.com/en-us/research">Microsoft Research</a>.</p>
]]></content:encoded>
					
		
		<enclosure url="https://www.microsoft.com/en-us/research/uploads/prod/2025/01/ExACT_Videos_010925_V1.mp4" length="47136083" type="video/mp4" />

			</item>
		<item>
		<title>Ideas: Building AI for population-scale systems with Akshay Nambi</title>
		<link>https://www.microsoft.com/en-us/research/podcast/ideas-building-ai-for-population-scale-systems-with-akshay-nambi/</link>
		
		<dc:creator><![CDATA[Alyssa Hughes (2ADAPTIVE LLC dba 2A Consulting)]]></dc:creator>
		<pubDate>Tue, 11 Feb 2025 04:26:10 +0000</pubDate>
				<category><![CDATA[Microsoft Research Podcast]]></category>
		<guid isPermaLink="false">https://www.microsoft.com/en-us/research/?p=1127448</guid>

					<description><![CDATA[<p>Advances in AI are driving meaningful real-world impact. Principal Researcher Akshay Nambi shares how his passion for tackling real-world challenges across various domains fuels his work in building reliable and robust AI systems.</p>
<p>The post <a href="https://www.microsoft.com/en-us/research/podcast/ideas-building-ai-for-population-scale-systems-with-akshay-nambi/">Ideas: Building AI for population-scale systems with Akshay Nambi</a> appeared first on <a href="https://www.microsoft.com/en-us/research">Microsoft Research</a>.</p>
]]></description>
										<content:encoded><![CDATA[
<figure class="wp-block-image size-full"><img loading="lazy" decoding="async" width="1401" height="788" src="https://www.microsoft.com/en-us/research/uploads/prod/2025/02/Akshay-Nambi_Ideas_Hero_Feature_No_Text_1400x788-2.jpg" alt="Outline illustration of Akshay Nambi | Ideas podcast" class="wp-image-1128111" srcset="https://www.microsoft.com/en-us/research/uploads/prod/2025/02/Akshay-Nambi_Ideas_Hero_Feature_No_Text_1400x788-2.jpg 1401w, https://www.microsoft.com/en-us/research/uploads/prod/2025/02/Akshay-Nambi_Ideas_Hero_Feature_No_Text_1400x788-2-300x169.jpg 300w, https://www.microsoft.com/en-us/research/uploads/prod/2025/02/Akshay-Nambi_Ideas_Hero_Feature_No_Text_1400x788-2-1024x576.jpg 1024w, https://www.microsoft.com/en-us/research/uploads/prod/2025/02/Akshay-Nambi_Ideas_Hero_Feature_No_Text_1400x788-2-768x432.jpg 768w, https://www.microsoft.com/en-us/research/uploads/prod/2025/02/Akshay-Nambi_Ideas_Hero_Feature_No_Text_1400x788-2-1066x600.jpg 1066w, https://www.microsoft.com/en-us/research/uploads/prod/2025/02/Akshay-Nambi_Ideas_Hero_Feature_No_Text_1400x788-2-655x368.jpg 655w, https://www.microsoft.com/en-us/research/uploads/prod/2025/02/Akshay-Nambi_Ideas_Hero_Feature_No_Text_1400x788-2-240x135.jpg 240w, https://www.microsoft.com/en-us/research/uploads/prod/2025/02/Akshay-Nambi_Ideas_Hero_Feature_No_Text_1400x788-2-640x360.jpg 640w, https://www.microsoft.com/en-us/research/uploads/prod/2025/02/Akshay-Nambi_Ideas_Hero_Feature_No_Text_1400x788-2-960x540.jpg 960w, https://www.microsoft.com/en-us/research/uploads/prod/2025/02/Akshay-Nambi_Ideas_Hero_Feature_No_Text_1400x788-2-1280x720.jpg 1280w" sizes="auto, (max-width: 1401px) 100vw, 1401px" /></figure>


<div class="wp-block-msr-podcast-container my-4">
	<iframe loading="lazy" src="https://player.blubrry.com/?podcast_id=142024931&modern=1" class="podcast-player" frameborder="0" height="164px" width="100%" scrolling="no" title="Podcast Player"></iframe>
</div>



<p>Behind every emerging technology is a great idea propelling it forward. In the Microsoft Research Podcast series <em>Ideas</em>, members of the research community at Microsoft discuss the beliefs that animate their research, the experiences and thinkers that inform it, and the positive human impact it targets.</p>



<p>In this episode, guest host Chris Stetkiewicz talks with Microsoft Principal Researcher <a href="https://www.microsoft.com/en-us/research/people/akshayn/?msockid=35739e94ab6c69d41b738b93aa076831">Akshay Nambi</a> about his focus on developing AI-driven technology that addresses real-world challenges at scale. Drawing on firsthand experiences, Nambi combines his expertise in electronics and computer science to create systems that enhance road safety, agriculture, and energy infrastructure. He’s currently working on AI-powered tools to improve education, including a digital assistant that can help teachers work more efficiently and create effective lesson plans and solutions to help improve the accuracy of models underpinning AI tutors.</p>



<p><strong>Learn more:</strong></p>



<p><a href="https://www.microsoft.com/en-us/research/blog/teachers-in-india-help-microsoft-research-design-ai-tool-for-creating-great-classroom-content/">Teachers in India help Microsoft Research design AI tool for creating great classroom content</a><br>Microsoft Research Blog, October 2023</p>



<p><a href="https://www.microsoft.com/en-us/research/project/hams/automated-driver-license-testing/">HAMS: Harnessing AutoMobiles for Safety</a><br>Project homepage</p>



<p><a class="msr-external-link glyph-append glyph-append-open-in-new-tab glyph-append-xsmall" href="https://news.microsoft.com/en-in/features/microsoft-ai-automates-drivers-license-test-india/">Microsoft Research AI project automates driver&#8217;s license tests in India<span class="sr-only"> (opens in new tab)</span></a><br>Microsoft Source Asia Blog</p>



<p><a href="https://www.microsoft.com/en-us/research/publication/insight-monitoring-the-state-of-the-driver-in-low-light-using-smartphones/">InSight: Monitoring the State of the Driver in Low-Light Using Smartphones</a><br>Publication, September 2020</p>



<p><a href="https://www.microsoft.com/en-us/research/publication/chanakya-learning-runtime-decisions-for-adaptive-real-time-perception/">Chanakya: Learning Runtime Decisions for Adaptive Real-Time Perception</a><br>Publication, December 2023</p>



<p><a href="https://www.microsoft.com/en-us/research/publication/alt-towards-automating-driver-license-testing-using-smartphones/">ALT: Towards Automating Driver License Testing using Smartphones</a><br>Publication, November 2019</p>



<p><a href="https://www.microsoft.com/en-us/research/project/dependableiot/">Dependable IoT</a><br>Project homepage</p>



<p><a href="https://www.microsoft.com/en-us/research/project/vasudha/">Vasudha</a><br>Project homepage</p>



<section class="wp-block-msr-subscribe-to-podcast subscribe-to-podcast">
	<div class="subscribe-to-podcast__inner border-top border-bottom border-width-2">
		<h2 class="h5 subscribe-to-podcast__heading">
			Subscribe to the <a href="https://www.microsoft.com/en-us/research/podcast">Microsoft Research Podcast</a>:		</h2>
		<ul class="subscribe-to-podcast__list list-unstyled">
							<li class="subscribe-to-podcast__list-item">
					<a class="subscribe-to-podcast__link" href="https://itunes.apple.com/us/podcast/microsoft-research-a-podcast/id1318021537?mt=2" target="_blank" rel="noreferrer noopener">
						<svg class="subscribe-to-podcast__svg" xmlns="http://www.w3.org/2000/svg" fill="black" viewBox="0 0 32 32">  <path d="M7.12 0c-3.937-0.011-7.131 3.183-7.12 7.12v17.76c-0.011 3.937 3.183 7.131 7.12 7.12h17.76c3.937 0.011 7.131-3.183 7.12-7.12v-17.76c0.011-3.937-3.183-7.131-7.12-7.12zM15.817 3.421c3.115 0 5.932 1.204 8.079 3.453 1.631 1.693 2.547 3.489 3.016 5.855 0.161 0.787 0.161 2.932 0.009 3.817-0.5 2.817-2.041 5.339-4.317 7.063-0.812 0.615-2.797 1.683-3.115 1.683-0.12 0-0.129-0.12-0.077-0.615 0.099-0.792 0.192-0.953 0.64-1.141 0.713-0.296 1.932-1.167 2.677-1.911 1.301-1.303 2.229-2.932 2.677-4.719 0.281-1.1 0.244-3.543-0.063-4.672-0.969-3.595-3.907-6.385-7.5-7.136-1.041-0.213-2.943-0.213-4 0-3.636 0.751-6.647 3.683-7.563 7.371-0.245 1.004-0.245 3.448 0 4.448 0.609 2.443 2.188 4.681 4.255 6.015 0.407 0.271 0.896 0.547 1.1 0.631 0.447 0.192 0.547 0.355 0.629 1.14 0.052 0.485 0.041 0.62-0.072 0.62-0.073 0-0.62-0.235-1.199-0.511l-0.052-0.041c-3.297-1.62-5.407-4.364-6.177-8.016-0.187-0.943-0.224-3.187-0.036-4.052 0.479-2.323 1.396-4.135 2.921-5.739 2.199-2.319 5.027-3.543 8.172-3.543zM16 7.172c0.541 0.005 1.068 0.052 1.473 0.14 3.715 0.828 6.344 4.543 5.833 8.229-0.203 1.489-0.713 2.709-1.619 3.844-0.448 0.573-1.537 1.532-1.729 1.532-0.032 0-0.063-0.365-0.063-0.803v-0.808l0.552-0.661c2.093-2.505 1.943-6.005-0.339-8.296-0.885-0.896-1.912-1.423-3.235-1.661-0.853-0.161-1.031-0.161-1.927-0.011-1.364 0.219-2.417 0.744-3.355 1.672-2.291 2.271-2.443 5.791-0.348 8.296l0.552 0.661v0.813c0 0.448-0.037 0.807-0.084 0.807-0.036 0-0.349-0.213-0.683-0.479l-0.047-0.016c-1.109-0.885-2.088-2.453-2.495-3.995-0.244-0.932-0.244-2.697 0.011-3.625 0.672-2.505 2.521-4.448 5.079-5.359 0.547-0.193 1.509-0.297 2.416-0.281zM15.823 11.156c0.417 0 0.828 0.084 1.131 0.24 0.645 0.339 1.183 0.989 1.385 1.677 0.62 2.104-1.609 3.948-3.631 3.005h-0.015c-0.953-0.443-1.464-1.276-1.475-2.36 0-0.979 0.541-1.828 1.484-2.328 0.297-0.156 0.709-0.235 1.125-0.235zM15.812 17.464c1.319-0.005 2.271 0.463 2.625 1.291 0.265 0.62 0.167 2.573-0.292 5.735-0.307 2.208-0.479 2.765-0.905 3.141-0.589 0.52-1.417 0.667-2.209 0.385h-0.004c-0.953-0.344-1.157-0.808-1.553-3.527-0.452-3.161-0.552-5.115-0.285-5.735 0.348-0.823 1.296-1.285 2.624-1.291z"/></svg>
						<span class="subscribe-to-podcast__link-text">Apple Podcasts</span>
					</a>
				</li>
			
							<li class="subscribe-to-podcast__list-item">
					<a class="subscribe-to-podcast__link" href="https://subscribebyemail.com/www.blubrry.com/feeds/microsoftresearch.xml" target="_blank" rel="noreferrer noopener">
						<svg class="subscribe-to-podcast__svg" xmlns="http://www.w3.org/2000/svg" fill="none" viewBox="0 0 32 32"><path fill="currentColor" d="M6.4 6a2.392 2.392 0 00-2.372 2.119L16 15.6l11.972-7.481A2.392 2.392 0 0025.6 6H6.4zM4 10.502V22.8a2.4 2.4 0 002.4 2.4h19.2a2.4 2.4 0 002.4-2.4V10.502l-11.365 7.102a1.2 1.2 0 01-1.27 0L4 10.502z"/></svg>
						<span class="subscribe-to-podcast__link-text">Email</span>
					</a>
				</li>
			
							<li class="subscribe-to-podcast__list-item">
					<a class="subscribe-to-podcast__link" href="https://subscribeonandroid.com/www.blubrry.com/feeds/microsoftresearch.xml" target="_blank" rel="noreferrer noopener">
						<svg class="subscribe-to-podcast__svg" xmlns="http://www.w3.org/2000/svg" fill="none" viewBox="0 0 32 32"><path fill="currentColor" d="M12.414 4.02c-.062.012-.126.023-.18.06a.489.489 0 00-.12.675L13.149 6.3c-1.6.847-2.792 2.255-3.18 3.944h13.257c-.388-1.69-1.58-3.097-3.179-3.944l1.035-1.545a.489.489 0 00-.12-.675.492.492 0 00-.675.135l-1.14 1.68a7.423 7.423 0 00-2.55-.45c-.899 0-1.758.161-2.549.45l-1.14-1.68a.482.482 0 00-.494-.195zm1.545 3.824a.72.72 0 110 1.44.72.72 0 010-1.44zm5.278 0a.719.719 0 110 1.44.719.719 0 110-1.44zM8.44 11.204A1.44 1.44 0 007 12.644v6.718c0 .795.645 1.44 1.44 1.44.168 0 .33-.036.48-.09v-9.418a1.406 1.406 0 00-.48-.09zm1.44 0V21.76c0 .793.646 1.44 1.44 1.44h10.557c.793 0 1.44-.647 1.44-1.44V11.204H9.878zm14.876 0c-.169 0-.33.035-.48.09v9.418c.15.052.311.09.48.09a1.44 1.44 0 001.44-1.44v-6.719a1.44 1.44 0 00-1.44-1.44zM11.8 24.16v1.92a1.92 1.92 0 003.84 0v-1.92h-3.84zm5.759 0v1.92a1.92 1.92 0 003.84 0v-1.92h-3.84z"/></svg>
						<span class="subscribe-to-podcast__link-text">Android</span>
					</a>
				</li>
			
							<li class="subscribe-to-podcast__list-item">
					<a class="subscribe-to-podcast__link" href="https://open.spotify.com/show/4ndjUXyL0hH1FXHgwIiTWU" target="_blank" rel="noreferrer noopener">
						<svg class="subscribe-to-podcast__svg" xmlns="http://www.w3.org/2000/svg" fill="none" viewBox="0 0 32 32"><path fill="currentColor" d="M16 4C9.383 4 4 9.383 4 16s5.383 12 12 12 12-5.383 12-12S22.617 4 16 4zm5.08 17.394a.781.781 0 01-1.086.217c-1.29-.86-3.477-1.434-5.303-1.434-1.937.002-3.389.477-3.403.482a.782.782 0 11-.494-1.484c.068-.023 1.71-.56 3.897-.562 1.826 0 4.365.492 6.171 1.696.36.24.457.725.217 1.085zm1.56-3.202a.895.895 0 01-1.234.286c-2.338-1.457-4.742-1.766-6.812-1.747-2.338.02-4.207.466-4.239.476a.895.895 0 11-.488-1.723c.145-.041 2.01-.5 4.564-.521 2.329-.02 5.23.318 7.923 1.995.419.26.547.814.286 1.234zm1.556-3.745a1.043 1.043 0 01-1.428.371c-2.725-1.6-6.039-1.94-8.339-1.942h-.033c-2.781 0-4.923.489-4.944.494a1.044 1.044 0 01-.474-2.031c.096-.023 2.385-.55 5.418-.55h.036c2.558.004 6.264.393 9.393 2.23.497.292.663.931.371 1.428z"/></svg>
						<span class="subscribe-to-podcast__link-text">Spotify</span>
					</a>
				</li>
			
							<li class="subscribe-to-podcast__list-item">
					<a class="subscribe-to-podcast__link" href="https://www.blubrry.com/feeds/microsoftresearch.xml" target="_blank" rel="noreferrer noopener">
						<svg class="subscribe-to-podcast__svg" xmlns="http://www.w3.org/2000/svg" fill="none" viewBox="0 0 32 32"><path fill="currentColor" d="M6.667 4a2.676 2.676 0 00-2.612 2.13v.003c-.036.172-.055.35-.055.534v18.666c0 .183.019.362.055.534v.003a2.676 2.676 0 002.076 2.075h.002c.172.036.35.055.534.055h18.666A2.676 2.676 0 0028 25.333V6.667a2.676 2.676 0 00-2.13-2.612h-.003A2.623 2.623 0 0025.333 4H6.667zM8 8h1.333C17.42 8 24 14.58 24 22.667V24h-2.667v-1.333c0-6.618-5.382-12-12-12H8V8zm0 5.333h1.333c5.146 0 9.334 4.188 9.334 9.334V24H16v-1.333A6.674 6.674 0 009.333 16H8v-2.667zM10 20a2 2 0 11-.001 4.001A2 2 0 0110 20z"/></svg>
						<span class="subscribe-to-podcast__link-text">RSS Feed</span>
					</a>
				</li>
					</ul>
	</div>
</section>


<div class="wp-block-msr-show-more">
	<div class="bg-neutral-100 p-5">
		<div class="show-more-show-less" data-mount="show-more-show-less">
			<div>
				<span>
					

<h2 class="wp-block-heading" id="transcript">Transcript</h2>



<p>[TEASER]</p>



<p>[MUSIC PLAYS UNDER DIALOGUE]</p>



<p><strong>AKSHAY NAMBI:</strong> For me, research is just not about pushing the boundaries of the knowledge. It&#8217;s about ensuring that these advancements translate to meaningful impact on the ground. So, yes, the big goals that guide most of my work is twofold. One, how do we build technology that&#8217;s scaled to benefit large populations? And two, at the same time, I&#8217;m motivated by the challenge of tackling complex problems. <em>That</em> provides opportunity to explore, learn, and also create something new, and that&#8217;s what keeps me excited.</p>



<p>[TEASER ENDS]</p>



<p><strong>CHRIS STETKIEWICZ:</strong> You&#8217;re listening to <em>Ideas</em>, a Microsoft Research Podcast that dives deep into the world of technology research and the profound questions behind the code. In this series, we&#8217;ll explore the technologies that are shaping our future and the big ideas that propel them forward.</p>



<p>[MUSIC FADES]</p>



<p>I&#8217;m your guest host, Chris Stetkiewicz. Today, I&#8217;m talking to Akshay Nambi. Akshay is a principal researcher at Microsoft Research. His work lies at the intersection of systems, AI, and machine learning with a focus on designing, deploying, and scaling AI systems to solve compelling real-world problems. Akshay&#8217;s research extends across education, agriculture, transportation, and energy. He is currently working on enhancing the quality and reliability of AI systems by addressing critical challenges such as reasoning, grounding, and managing complex queries.</p>



<p>Akshay, welcome to the podcast.</p>



				</span>
				<span id="show-more-show-less-toggle-1" class="show-more-show-less-toggleable-content">
					



<p><strong>AKSHAY NAMBI:</strong> Thanks for having me.</p>



<p><strong>STETKIEWICZ:</strong> I&#8217;d like to begin by asking you to tell us your origin story. How did you get started on your path? Was there a big idea or experience that captured your imagination or motivated you to do what you&#8217;re doing today?</p>



<p><strong>NAMBI:</strong> If I look back, my journey into research wasn&#8217;t a straight line. It was more about discovering my passion through some unexpected opportunities and also finding purpose along the way. So before I started with my undergrad studies, I was very interested in electronics and systems. My passion for electronics, kind of, started when I was in school. I was more like an average student, not a nerd or not too curious, but I was always tinkering around, doing things, building stuff, and playing with gadgets and that, kind of, made me very keen on electronics and putting things together, and that was my passion. But sometimes things don&#8217;t go as planned. So I didn&#8217;t get into the college which I had hoped to join for electronics, so I ended up pursuing computer science, which wasn&#8217;t too bad either. So during my final year of bachelor&#8217;s, I had to do a final semester project, which turned out to be a very pivotal moment. And that&#8217;s when I got to know this institute called Indian Institute of Science (IISc), which is a top research institute in India and also globally. And I had a chance to work on a project there. And it was my first real exposure to open-ended research, right, so I remember &#8230; where we were trying to build a solution that helped to efficiently construct an ontology for a specific domain, which simply means that we were building systems to help users uncover relationships in the data and allow them to query it more efficiently, right. And it was super exciting for me to design and build something new. And that experience made me realize that I wanted to pursue research further. And right after that project, I decided to explore research opportunities, which led me to join Indian Institute of Science again as a research assistant.</p>



<p><strong>STETKIEWICZ:</strong> So what made you want to take the skills you were developing and apply them to a research career?</p>



<p><strong>NAMBI:</strong> So interestingly when I joined IISc, the professor I worked with specialized in electronics, so things come back, so something I had always been passionate about. And I was the only computer science graduate in the lab at that time with others being electronic engineers, and I didn&#8217;t even know how to solder. But the lab environment was super encouraging, collaborative, so I, kind of, caught up very quickly. In that lab, basically, I worked on several projects in the emerging fields of embedded device and energy harvesting systems. Specifically, we were designing systems that could harvest energy from sources like sun, hydro, and even RF (radio frequency) signals. And my role was kind of twofold. One, I designed circuits and systems to make energy harvesting more efficient so that you can store this energy. And then I also wrote programs, software, to ensure that the harvested energy can be used efficiently. For instance, as we harvest some of this energy, you want to have your programs run very quickly so that you are able to sense the data, send it to the server in an efficient way. And one of the most exciting projects I worked during that time was on data-driven agriculture. So this was back in 2008, 2009, right, where we developed an embedded system device with sensors to monitor the agricultural fields, collecting data like soil moisture, soil temperature. And that was sent to the agronomists who were able to analyze this data and provide feedback to farmers. In many remote areas, still access to power is a huge challenge. So we used many of the technologies we were developing in the lab, specifically energy harvesting techniques, to power these sensors and devices in the rural farms, and that&#8217;s when I really got to see firsthand how technology could help people&#8217;s lives, particularly in rural settings. And that&#8217;s what, kind of, stood out in my experience at IISc, right, was that it was [the] end-to-end nature of the work. And it was not just writing code or designing circuits. It was about identifying the real-world problems, solving them efficiently, and deploying solutions in the field. And this cemented my passion for creating technology that solves real-world problems, and that&#8217;s what keeps me driving even today.</p>



<p><strong>STETKIEWICZ:</strong> And as you&#8217;re thinking about those problems that you want to try and solve, where did you look for, for inspiration? It sounds like some of these are happening right there in your home.</p>



<p><strong>NAMBI:</strong> That&#8217;s right. Growing up and living in India, I&#8217;ve been surrounded by these, kind of, many challenges. And these are not distant problems. These are right in front of us. And some of them are quite literally outside the door. So being here in India provides a unique opportunity to tackle some of the pressing real-world challenges in agriculture, education, or in road safety, where even small advancements can create significant impact.</p>



<p><strong>STETKIEWICZ:</strong> So how would you describe your research philosophy? Do you have some big goals that guide you?</p>



<p><strong>NAMBI:</strong> Right, as I mentioned, right, my research philosophy is mainly rooted in solving real-world problems through end-to-end innovation. For me, research is just not about pushing the boundaries of the knowledge. It&#8217;s about ensuring that these advancements translate to meaningful impact on the ground, right. So, yes, the big goals that guide most of my work is twofold. One, how do we build technology that&#8217;s scaled to benefit large populations? And two, at the same time, I&#8217;m motivated by the challenge of tackling complex problems. <em>That</em> provides opportunity to explore, learn, and also create something new. And that&#8217;s what keeps me excited.</p>



<p><strong>STETKIEWICZ:</strong> So let&#8217;s talk a little bit about your journey at Microsoft Research. I know you began as an intern, and some of the initial work you did was focused on computer vision, road safety, energy efficiency. Tell us about some of those projects.</p>



<p><strong>NAMBI:</strong> As I was nearing the completion of my PhD, I was eager to look for opportunities in industrial labs, and Microsoft Research obviously stood out as an exciting opportunity. And additionally, the fact that Microsoft Research India was in my hometown, Bangalore, made it even more appealing. So when I joined as an intern, I worked together with Venkat Padmanabhan, who now leads the lab, and we started this project called HAMS, which stands for <em>Harnessing Automobiles for Safety</em>. As you know, road safety is a major public health issue globally, responsible for almost 1.35 million fatalities annually and with the situation being even more severe in countries like India. For instance, there are estimates that there&#8217;s a life lost on the road every four minutes in India. When analyzing the factors which affect road safety, we saw mainly three elements. One, the vehicle. Second, the infrastructure. And then the driver. Among these, the driver plays the most critical role in many incidents, whether it&#8217;s over-speeding, driving without seat belts, drowsiness, fatigue, any of these, right. And this realization motivated us to focus on driver monitoring, which led to the development of HAMS. In a nutshell, HAMS is basically a smartphone-based system where you&#8217;re mounting your smartphone on a windshield of a vehicle to monitor both the driver and the driving in real time with the goal of improving road safety. Basically, it observes key aspects such as where the driver is looking, whether they are distracted or fatigued<a id="_ftnref1" href="#_ftn1">[1]</a>, while also considering the external driving environment, because we truly believe to improve road safety, we need to understand not just the driver&#8217;s action but also the context in which they are driving. For example, if the smartphone&#8217;s accelerometer detects sharp braking, the system would automatically check the distance to the vehicle in the front using the rear camera and whether the driver was distracted or fatigued using the front camera. And this holistic approach ensures a more accurate and comprehensive assessment of the driving behavior, enabling a more meaningful feedback.</p>



<p><strong>STETKIEWICZ:</strong> So that sounds like a system that&#8217;s got several moving parts to it. And I imagine you had some technical challenges you had to deal with there. Can you talk about that?</p>



<p><strong>NAMBI:</strong> One of our guiding principles in HAMS was to use commodity, off-the-shelf smartphone devices, right. This should be affordable, in the range of $100 to $200, so that you can just take out regular smartphones and enable this driver and driving monitoring. And that led to handling several technical challenges. For instance, we had to develop efficient computer vision algorithms that could run locally on the device with cheap smartphone processing units while still performing very well at low-light conditions. We wrote multiple papers and developed many of the novel algorithms which we implemented on very low-cost smartphones. And once we had such a monitoring system, right, you can imagine there&#8217;s several deployment opportunities, starting from fleet monitoring to even training new drivers, right. However, one application we hadn&#8217;t originally envisioned but turned out to be its most impactful use case even today is automated driver&#8217;s license testing. As you know, before you get a license, a driver is supposed to pass a test, but what happens in many places, including India, is that licenses are issued with very minimal or no actual testing, leading to unsafe and untrained drivers on the road. At the same time as we were working on HAMS, Indian government were looking at introducing technology to make testing more transparent and also automated. So we worked with the right set of partners, and we demonstrated to the government that HAMS could actually completely automate the entire license testing process. So we first deployed this system in Dehradun RTO (Regional Transport Office)—which is the equivalent of a DMV in the US—in 2019, working very closely with RTO officials to define what should be some of the evaluation criteria, right. Some of these would be very simple like, oh, is it the same candidate who is taking the test who actually registered for the test, right? And whether they are wearing seat belts. Did they scan their mirrors before taking a left turn and how well they performed in tasks like reverse parking and things like that.</p>



<p><strong>STETKIEWICZ:</strong> So what&#8217;s been the government response to that? Have they embraced it or deployed it in a wider extent?</p>



<p><strong>NAMBI:</strong> Yes, yes. So after the deployment in Dehradun in 2019, we actually open sourced the entire HAMS technology and our partners are now working with several state governments and scaled HAMS to several states in India. And as of today, we have around 28 RTOs where HAMS is actually being deployed, and the pass rate of such license test is just 60% as compared to 90-plus percent with manual testing. That&#8217;s the extensive rigor the system brings in. And now what excites me is after nearly five years later, we are now taking the next step in this project where we are now evaluating the long-term impact of this intervention on driving behavior and road safety. So we are collaborating with Professor Michael Kremer, who is a Nobel laureate and professor at University of Chicago, and his team to study how this technology has influenced driving patterns and accident rates over time. So this focus on closing the loop and moving beyond just deployment in the field to actually measuring the real impact, right, is something that truly excites me and that makes research at Microsoft is very unique. And that is actually one of the reasons why I joined Microsoft Research as a full-time after my internship, and this unique flexibility to work on real-world problems, develop novel research ideas, and actually collaborate with partners both internally and externally to deploy at scale is something that is very unique here.</p>



<p><strong>STETKIEWICZ:</strong> So have you actually received any evidence that the project is working? Is driving getting safer?</p>



<p><strong>NAMBI:</strong> Yes, these are very early analysis, and there are very positive insights we are getting from that. Soon we will be releasing a white paper on our study on this long-term impact.</p>



<p><strong>STETKIEWICZ:</strong> That’s great. I look forward to that one. So you&#8217;ve also done some interesting work involving the Internet of Things, with an emphasis on making it more reliable and practical. So for those in our audience who may not know, the Internet of Things, or <em>IoT</em>, is a network that includes billions of devices and sensors in things like smart thermostats and fitness trackers. So talk a little bit about your work in this area.</p>



<p><strong>NAMBI:</strong> Right, so IoT, as you know, is already transforming several industries with billions of sensors being deployed in areas like industrial monitoring, manufacturing, agriculture, smart buildings, and also air pollution monitoring. And if you think about it, these sensors provide critical data that businesses rely for decision making. However, a fundamental challenge is ensuring that the data collected from these sensors is actually reliable. If the data is faulty, it can lead to poor decisions and inefficiencies. And the challenge is that these sensor failures are always not obvious. What I mean by that is when a sensor stops working, it always doesn&#8217;t stop sending data, but it often continues to send some data which appear to be normal. And that&#8217;s one of the biggest problems, right. So detecting these errors is non-trivial because the faulty sensors can mimic real-world working data, and traditional solutions like deploying redundant sensors or even manually inspecting them are very expensive, labor intensive, and also sometimes infeasible, especially for remote deployments. Our goal in this work was to develop a simple and efficient way to remotely monitor the health of the IoT sensors. So what we did was we hypothesized that most sensor failures occurred due to the electronic malfunctions. It could be either due to short circuits or component degradation or due to environmental factors such as heat, humidity, or pollution. Since these failures originate within the sensor hardware itself, we saw an opportunity to leverage some of the basic electronic principles to create a novel solution. The core idea was to develop a way to automatically generate a fingerprint for each sensor. And by fingerprint, I mean the unique electrical characteristic exhibited by a properly working sensor. We built a system that could devise these fingerprints for different types of sensors, allowing us to detect failures purely based on the sensors internal characteristics, that is the fingerprint, and even without looking at the data it produces. Essentially what it means now is that we were able to tag each sensor data with a reliability score, ensuring verifiability.</p>



<p><strong>STETKIEWICZ:</strong> So how does that technology get deployed in the real world? Is there an application where it&#8217;s being put to work today?</p>



<p><strong>NAMBI:</strong> Yes, this technology, we worked together with Azure IoT and open-sourced it where there were several opportunities and several companies took the solution into their systems, including air pollution monitoring, smart buildings, industrial monitoring. The one which I would like to talk about today is about air pollution monitoring. As you know, air pollution is a major challenge in many parts of the world, especially in India. And traditionally, air quality monitoring relies on these expensive fixed sensors, which provide limited coverage. On the other hand, there is a rich body of work on low-cost sensors, which can offer wider deployment. Like, you can put these sensors on a bus or a vehicle and have it move around the entire city, where you can get much more fine-grained, accurate picture on the ground. But these are often unreliable because these are low-cost sensors and have reliability issues. So we collaborated with several startups who were developing these low-cost air pollution sensors who were finding it very challenging to gain trust because one of the main concerns was the&nbsp;accuracy of the data from low-cost sensors. So our solution seamlessly integrated with these sensors, which enabled verification of the data quality coming out from these low-cost air pollution sensors. So this bridged the trust gap, allowing government agencies&nbsp;to initiate large-scale pilots using low-cost sensors for fine-grain air-quality monitoring.</p>



<p><strong>STETKIEWICZ:</strong> So as we&#8217;re talking about evolving technology, large language models, or LLMs, are also enabling big changes, and they&#8217;re not theoretical. They&#8217;re happening today. And you&#8217;ve been working on LLMs and their applicability to real-world problems. Can you talk about your work there and some of the latest releases?</p>



<p><strong>NAMBI:</strong> So when ChatGPT was first released, I, like many people, was very skeptical. However, I was also curious both of how it worked and, more importantly, whether it could accelerate solutions to real-world problems. That led to the exploration of LLMs in education, where we fundamentally asked this question, can AI help improve educational outcomes? And this was one of the key questions which led to the development of Shiksha copilot, which is a genAI-powered assistant designed to support teachers in their daily work, starting from helping them to create personalized learning experience, design assignments, generate hands-on activities, and even more. Teachers today universally face several challenges, from time management to lesson planning. And our goal with Shiksha was to empower them to significantly reduce the time spent on this task. For instance, lesson planning, which traditionally took about 60 minutes, can now be completed in just five minutes using the Shiksha copilot. And what makes Shiksha unique is that it&#8217;s completely grounded in the local curriculum and the learning objectives, ensuring that the AI-generated content aligns very well with the pedagogical best practices. The system actually supports multilingual interactions, multimodal capabilities, and also integration with external knowledge base, making it very highly adaptable for different curriculums. Initially, many teachers were skeptical. Some feared this would limit their creativity. However, as they began starting to use Shiksha, they realized that it didn&#8217;t replace their expertise, but rather amplified it, enabling them to do work faster and more efficiently.</p>



<p><strong>STETKIEWICZ:</strong> So, Akshay, the last time you and I talked about Shiksha copilot, it was very much in the pilot phase and the teachers were just getting their hands on it. So it sounds like, though, you&#8217;ve gotten some pretty good feedback from them since then.</p>



<p><strong>NAMBI:</strong> Yes, so when we were discussing, we were doing this six-month pilot with 50-plus teachers where we gathered overwhelming positive feedback on how technologies are helping teachers to reduce time in their lesson planning. And in fact, they were using the system so much that they really enjoyed working with Shiksha copilot where they were able to do more things with much less time, right. And with a lot of feedback from teachers, we have improved Shiksha copilot over the past few months. And starting this academic year, we have already deployed Shiksha to 1,000-plus teachers in Karnataka. This is with close collaboration with our partners in … with the Sikshana Foundation and also with the government of Karnataka. And the response has been already incredibly encouraging. And looking ahead, we are actually focusing on again, closing this loop, right, and measuring the impact on the ground, where we are doing a lot of studies with the teachers to understand not just improving efficiency of the teachers but also measuring how AI-generated content enriched by teachers is actually enhancing student learning objectives. So that&#8217;s the study we are conducting, which hopefully will close this loop and understand our original question that, can AI actually help improve educational outcomes?</p>



<p><strong>STETKIEWICZ:</strong> And is the deployment primarily in rural areas, or does it include urban centers, or what&#8217;s the target?</p>



<p><strong>NAMBI:</strong> So the current deployment with 1,000 teachers is a combination of both rural and urban public schools. These are covering both English medium and Kannada medium teaching schools with grades from Class 5 to Class 10.</p>



<p><strong>STETKIEWICZ:</strong> Great. So Shiksha was focused on helping teachers and making their jobs easier, but I understand you&#8217;re also working on some opportunities to use AI to help <em>students</em> succeed. Can you talk about that?</p>



<p><strong>NAMBI:</strong> So as you know, LLMs are still evolving and inherently they are fragile, and deploying them in real-world settings, especially in education, presents a lot of challenges. With Shiksha, if you think about it, teachers remain in control throughout the interaction, making the final decision on whether to use the AI-generated content in the classroom or not. However, when it comes to AI tutors for students, the stakes are slightly higher, where we need to ensure the AI doesn&#8217;t produce incorrect answers, misrepresent concepts, or even mislead explanations. Currently, we are developing solutions to enhance accuracy and also the reasoning capabilities of these foundational models, particularly solving math problems. This represents a major step towards building AI systems that&#8217;s much more holistic personal tutors, which help student understanding and create more engaging, effective learning experience.</p>



<p><strong>STETKIEWICZ: </strong>So you&#8217;ve talked about working in computer vision and IoT and LLMs. What do those areas have in common? Is there some thread that weaves through the work that you&#8217;re doing?</p>



<p><strong>NAMBI: </strong>That&#8217;s a great question. As a systems researcher, I&#8217;m quite interested in this end-to-end systems development, which means that my focus is not just about improving a particular algorithm but also thinking about the end-to-end system, which means that I, kind of, think about computer vision, IoT, and even LLMs as tools, where we would want to improve them for a particular application. It could be agriculture, education, or road safety. And then how do you think this holistically to come up with the best efficient system that can be deployed at population scale, right. I think that&#8217;s the connecting story here, that how do you have this systemic thinking which kind of takes the existing tools, improves them, makes it more efficient, and takes it out from the lab to real world.</p>



<p><strong>STETKIEWICZ:</strong> So you&#8217;re working on some very powerful technology that is creating tangible benefits for society, which is your goal. At the same time, we&#8217;re still in the very early stages of the development of AI and machine learning. Have you ever thought about unintended consequences? Are there some things that could go wrong, even if we get the technology right? And does that kind of thinking ever influence the development process?</p>



<p><strong>NAMBI:</strong> Absolutely. Unintended consequences are something I think about deeply. Even the most well-designed technology can have these ripple effects that we may not fully anticipate, especially when we are deploying it at population scale. For me, being proactive is one of the key important aspects. This means not only designing the technology at the lab but actually also carefully deploying them in real world, measuring its impact, and working with the stakeholders to minimize the harm. In most of my work, I try to work very closely with the partner team on the ground to monitor, analyze, how the technology is being used and what are some of the risks and how can we eliminate that. At the same time, I also remain very optimistic. It&#8217;s also about responsibility. If we are able to embed societal values, ethics, into the design of the system and involve diverse perspectives, especially from people on the ground, we can remain vigilant as the technology evolves and we can create systems that can truly deliver immense societal benefits while addressing many of the potential risks.</p>



<p><strong>STETKIEWICZ:</strong> So we&#8217;ve heard a lot of great examples today about building technology to solve real-world problems and your motivation to keep doing that. So as you look ahead, where do you see your research going next? How will people be better off because of the technology you develop and the advances that they support?</p>



<p><strong>NAMBI:</strong> Yeah, I&#8217;m deeply interested in advancing AI systems that can truly assist anyone in their daily tasks, whether it&#8217;s providing personalized guidance to a farmer in a rural village, helping a student get instant 24 by 7 support for their learning doubts, or even empowering professionals to work more efficiently. And to achieve this, my research is focusing on tackling some of the fundamental challenges in AI with respect to reasoning and reliability and also making sure that AI is more context aware and responsive to evolving user needs. And looking ahead, I envision AI as not just an assistant but also as an intelligent and equitable copilot seamlessly integrated into our everyday life, empowering individuals across various domains.</p>



<p><strong>STETKIEWICZ:</strong> Great. Well, Akshay, thank you for joining us on <em>Ideas</em>. It&#8217;s been a pleasure.</p>



<p>[MUSIC]</p>



<p><strong>NAMBI:</strong> Yeah, I really enjoyed talking to you, Chris. Thank you.</p>



<p><strong>STETKIEWICZ:</strong> Till next time.</p>



<p>[MUSIC FADES]</p>

				</span>
			</div>
			<button
				class="action-trigger glyph-prepend mt-2 mb-0 show-more-show-less-toggle"
				aria-expanded="false"
				data-show-less-text="Show less"
				type="button"
				aria-controls="show-more-show-less-toggle-1"
				aria-label="Show more content"
				data-alternate-aria-label="Show less content">
				Show more			</button>
		</div>
	</div>
</div>



<hr class="wp-block-separator has-alpha-channel-opacity"/>



<p><a id="_ftn1" href="#_ftnref1">[1]</a> To ensure data privacy, all processing is done locally on the smartphone. This approach ensures that driving behavior insights remain private and secure with no personal data stored or shared.</p>
<span id="label-external-link" class="sr-only" aria-hidden="true">Opens in a new tab</span><p>The post <a href="https://www.microsoft.com/en-us/research/podcast/ideas-building-ai-for-population-scale-systems-with-akshay-nambi/">Ideas: Building AI for population-scale systems with Akshay Nambi</a> appeared first on <a href="https://www.microsoft.com/en-us/research">Microsoft Research</a>.</p>
]]></content:encoded>
					
		
		
			</item>
		<item>
		<title>Advances to low-bit quantization enable LLMs on edge devices</title>
		<link>https://www.microsoft.com/en-us/research/blog/advances-to-low-bit-quantization-enable-llms-on-edge-devices/</link>
		
		<dc:creator><![CDATA[Brenda Potts]]></dc:creator>
		<pubDate>Wed, 05 Feb 2025 17:32:32 +0000</pubDate>
				<category><![CDATA[Research Blog]]></category>
		<guid isPermaLink="false">https://www.microsoft.com/en-us/research/?p=1123686</guid>

					<description><![CDATA[<p>Advances in low-bit quantization techniques enable efficient operation of LLMs on resource-constrained edge devices. Discover how innovations like T-MAC, Ladder, and LUT Tensor Core improve computational efficiency and enhance hardware compatibility.</p>
<p>The post <a href="https://www.microsoft.com/en-us/research/blog/advances-to-low-bit-quantization-enable-llms-on-edge-devices/">Advances to low-bit quantization enable LLMs on edge devices</a> appeared first on <a href="https://www.microsoft.com/en-us/research">Microsoft Research</a>.</p>
]]></description>
										<content:encoded><![CDATA[
<figure class="wp-block-image size-full"><img loading="lazy" decoding="async" width="1400" height="788" src="https://www.microsoft.com/en-us/research/uploads/prod/2025/01/Low-Bit-BlogHeroFeature-1400x788-1.jpg" alt="Three white icons that represent artificial intelligence, systems, and networking. These icons sit on a purple to pink gradient background." class="wp-image-1124472" srcset="https://www.microsoft.com/en-us/research/uploads/prod/2025/01/Low-Bit-BlogHeroFeature-1400x788-1.jpg 1400w, https://www.microsoft.com/en-us/research/uploads/prod/2025/01/Low-Bit-BlogHeroFeature-1400x788-1-300x169.jpg 300w, https://www.microsoft.com/en-us/research/uploads/prod/2025/01/Low-Bit-BlogHeroFeature-1400x788-1-1024x576.jpg 1024w, https://www.microsoft.com/en-us/research/uploads/prod/2025/01/Low-Bit-BlogHeroFeature-1400x788-1-768x432.jpg 768w, https://www.microsoft.com/en-us/research/uploads/prod/2025/01/Low-Bit-BlogHeroFeature-1400x788-1-1066x600.jpg 1066w, https://www.microsoft.com/en-us/research/uploads/prod/2025/01/Low-Bit-BlogHeroFeature-1400x788-1-655x368.jpg 655w, https://www.microsoft.com/en-us/research/uploads/prod/2025/01/Low-Bit-BlogHeroFeature-1400x788-1-240x135.jpg 240w, https://www.microsoft.com/en-us/research/uploads/prod/2025/01/Low-Bit-BlogHeroFeature-1400x788-1-640x360.jpg 640w, https://www.microsoft.com/en-us/research/uploads/prod/2025/01/Low-Bit-BlogHeroFeature-1400x788-1-960x540.jpg 960w, https://www.microsoft.com/en-us/research/uploads/prod/2025/01/Low-Bit-BlogHeroFeature-1400x788-1-1280x720.jpg 1280w" sizes="auto, (max-width: 1400px) 100vw, 1400px" /></figure>



<p>Large language models (LLMs) are increasingly being deployed on edge devices—hardware that processes data locally near the data source, such as smartphones, laptops, and robots. Running LLMs on these devices supports advanced AI and real-time services, but their massive size, with hundreds of millions of parameters, requires significant memory and computational power, limiting widespread adoption. Low-bit quantization, a technique that compresses models and reduces memory demands, offers a solution by enabling more efficient operation.</p>



<p>Recent advances in low-bit quantization have made mixed-precision matrix multiplication (mpGEMM) viable for LLMs. This deep learning technique allows data of the same or different formats to be multiplied, such as int8*int1, int8*int2, or FP16*int4. By combining a variety of precision levels, mpGEMM strikes a balance among speed, memory efficiency, and computational accuracy.&nbsp;</p>



<p>However, most hardware supports only symmetric computations—operations on data of similar formats—creating challenges for mixed-precision calculations during General Matrix Multiplication (GEMM), a critical operation for LLMs. Overcoming these hardware limitations is essential to fully benefit from mpGEMM and support asymmetrical computations.&nbsp;</p>



<p>To unlock the potential of low-bit quantization on resource-constrained edge devices, hardware must natively support mpGEMM. To address this, we developed the following three approaches for computing kernels and hardware architectures:&nbsp;</p>



<ul class="wp-block-list">
<li><strong>Ladder</strong> <strong>data type compiler:</strong> Supports various low-precision data types by converting unsupported types into hardware-compatible ones without data loss, while also generating high-performance conversion code.&nbsp;</li>



<li><strong>T-MAC mpGEMM library:</strong> Implements GEMM using a lookup table (LUT) approach, eliminating multiplications to significantly reduce computational overhead. Optimized for diverse CPUs, T-MAC delivers several times the speed of other libraries.&nbsp;</li>



<li><strong>LUT Tensor Core hardware architecture:</strong> Introduces a cutting-edge design for next-generation AI hardware, tailored for low-bit quantization and mixed-precision computations.</li>
</ul>



<p>The following sections describe these techniques in detail.</p>



<h2 class="wp-block-heading" id="ladder-bridging-the-gap-between-custom-data-and-hardware-limits">Ladder: Bridging the gap between custom data and hardware limits</h2>



<p>Cutting-edge hardware accelerators, such as GPUs, TPUs, and specialized chips, are designed to speed up computationally intensive tasks like deep learning by efficiently handling large-scale operations. These accelerators now integrate lower-bit computing units, such as FP32, FP16, and even FP8, into their architectures.&nbsp;&nbsp;</p>



<p>However, constraints in chip area and hardware costs limit the availability of these units for standard data types. For instance, the NVIDIA V100 Tensor Core GPU supports only FP16, while the A100 supports int2, int4, and int8 but not newer formats like FP8 or OCP-MXFP. Additionally, the rapid development of LLMs often outpaces hardware upgrades, leaving many new data formats unsupported and complicating deployment.</p>



<p>Additionally, while hardware accelerators may lack direct support for custom data types, their memory systems can convert these types into fixed-width data blocks that store any data format. For instance, NF4 tensors can be converted into FP16 or FP32 for floating-point operations.</p>



<p>Building on these insights, we developed the <a href="https://www.microsoft.com/en-us/research/publication/ladder-enabling-efficient-low-precision-deep-learning-computing-through-hardware-aware-tensor-transformation/" target="_blank" rel="noreferrer noopener">Ladder</a> data type compiler, a method to separate data storage from computation, enabling broader support for custom data types. It bridges the gap between emerging custom data formats with the precision types supported by current hardware.</p>



<p>Ladder offers a flexible system for converting between algorithm-specific and hardware-supported data types without data loss. For low-bit applications, it optimizes performance by translating low-bit data into the most efficient formats for the hardware being used. As shown in Figure 1, this includes mapping low-bit computations to supported instructions and efficiently managing data storage across the memory hierarchy.&nbsp;</p>



<figure class="wp-block-image aligncenter size-full"><img loading="lazy" decoding="async" width="1024" height="465" src="https://www.microsoft.com/en-us/research/uploads/prod/2025/01/Low-bit_figure1.png" alt="Figure 1: A diagram illustrating the Ladder architecture. At the top, the tTile-Graph shows a computational flow where inputs in NF4 and FP16 formats feed into a matrix multiplication (MatMul) operation, which outputs in FP16. This output, along with another FP16 input, proceeds to an addition (Add) operation, also in FP16. Below, the tTile-Device schematic depicts a hierarchical memory structure with L2/Global Memory, L1/Shared Memory, and L0/Register, organized under 'Core.' Transformations occur in the loading and storing stages around computation, with arrows indicating data flow. The scheduling mechanism assigns operations to different layers of the memory hierarchy to optimize performance." class="wp-image-1123677" srcset="https://www.microsoft.com/en-us/research/uploads/prod/2025/01/Low-bit_figure1.png 1024w, https://www.microsoft.com/en-us/research/uploads/prod/2025/01/Low-bit_figure1-300x136.png 300w, https://www.microsoft.com/en-us/research/uploads/prod/2025/01/Low-bit_figure1-768x349.png 768w, https://www.microsoft.com/en-us/research/uploads/prod/2025/01/Low-bit_figure1-240x109.png 240w" sizes="auto, (max-width: 1024px) 100vw, 1024px" /><figcaption class="wp-element-caption">Figure 1: The Ladder architecture</figcaption></figure>



<h3 class="wp-block-heading" id="evaluating-ladder">Evaluating Ladder</h3>



<p>Evaluations of Ladder on NVIDIA and AMD GPUs show that it outperforms existing deep neural network (DNN) compilers for natively supported data types. It also handles custom data types not supported by GPUs, achieving speedups of up to 14.6 times.&nbsp;</p>



<p>As the first system to support custom low-precision data types for running DNNs on modern hardware accelerators, Ladder provides researchers with flexibility in optimizing data types. It also enables hardware developers to support a wider range of data types without requiring hardware modifications.&nbsp;</p>



<h2 class="wp-block-heading" id="t-mac-table-lookup-for-mpgemm-without-multiplication">T-MAC: Table-lookup for mpGEMM without multiplication</h2>



<p>Deploying low-bit quantized LLMs on edge devices often requires dequantizing models to ensure hardware compatibility. However, this approach has two major drawbacks:&nbsp;</p>



<ol class="wp-block-list">
<li><strong>Performance:</strong> Dequantization overhead can result in poor performance, negating the benefits of low-bit quantization.</li>



<li><strong>Development:</strong> Developers must redesign data layouts and kernels for different mixed precisions.</li>
</ol>



<p>To address these challenges, we introduce <a href="https://www.microsoft.com/en-us/research/publication/t-mac-cpu-renaissance-via-table-lookup-for-low-bit-llm-deployment-on-edge/" target="_blank" rel="noreferrer noopener">T-MAC</a>, a novel LUT-based method that enables mpGEMM without dequantization or multiplication.&nbsp;</p>



<p>T-MAC replaces traditional multiplication operations with bit-wise table lookups, offering a unified and scalable solution for mpGEMM. It incorporates techniques to reduce the size of tables and store them directly on the chip, minimizing the overhead of accessing data from memory. By eliminating dequantization and lowering computational costs, T-MAC enables efficient inference of low-bit LLMs on resource-constrained edge devices. Figure 2 illustrates T-MAC’s architecture.&nbsp;</p>



<figure class="wp-block-image aligncenter size-full"><img loading="lazy" decoding="async" width="1268" height="719" src="https://www.microsoft.com/en-us/research/uploads/prod/2025/01/Low-bit_figure2.png" alt="Figure 2: A diagram showing offline and online processes for bit-serial computation. Offline: integer weights are decomposed into 1-bit indices and permuted into tiles. Online: activations are precomputed with 1-bit patterns, processed via a lookup table (LUT), and aggregated using weighted summation in bit-serial aggregation." class="wp-image-1123683" srcset="https://www.microsoft.com/en-us/research/uploads/prod/2025/01/Low-bit_figure2.png 1268w, https://www.microsoft.com/en-us/research/uploads/prod/2025/01/Low-bit_figure2-300x170.png 300w, https://www.microsoft.com/en-us/research/uploads/prod/2025/01/Low-bit_figure2-1024x581.png 1024w, https://www.microsoft.com/en-us/research/uploads/prod/2025/01/Low-bit_figure2-768x435.png 768w, https://www.microsoft.com/en-us/research/uploads/prod/2025/01/Low-bit_figure2-240x136.png 240w" sizes="auto, (max-width: 1268px) 100vw, 1268px" /><figcaption class="wp-element-caption">Figure 2. Overview of the T-MAC system</figcaption></figure>



<h3 class="wp-block-heading" id="evaluating-t-mac">Evaluating T-MAC</h3>



<p>Performance evaluations of T-MAC on low-bit models demonstrated substantial benefits in efficiency and speed. On the Surface Laptop 7 with the Qualcomm Snapdragon X Elite chipset, T-MAC achieved:&nbsp;</p>



<ul class="wp-block-list">
<li>48 tokens per second for the 3B BitNet-b1.58 model&nbsp;</li>



<li>30 tokens per second for the 2-bit 7B Llama model&nbsp;</li>



<li>20 tokens per second for the 4-bit 7B Llama model</li>
</ul>



<p>These speeds far exceed average human reading rates, outperforming llama.cpp by 4–5 times and doubling the speed of a dedicated NPU accelerator.&nbsp;Even on lower-end devices like the Raspberry Pi 5, T-MAC made it possible for the 3B BitNet-b1.58 model to generate 11 tokens per second. It also proved highly power-efficient, matching llama.cpp&#8217;s generation rate while using only <sup>1</sup>/<sub>4</sub> to <sup>1</sup>/<sub>6</sub> of the CPU cores.</p>



<p>These results establish T-MAC as a practical solution for deploying LLMs on edge devices with standard CPUs, without relying on GPUs or NPUs. T-MAC allows LLMs to run efficiently on resource-constrained devices, expanding their applicability across a wider range of scenarios.</p>



<h2 class="wp-block-heading" id="lut-tensor-core-driving-hardware-for-mpgemm">LUT Tensor Core: Driving hardware for mpGEMM</h2>



<p>While T-MAC and Ladder optimize mpGEMM on existing CPU and GPU architectures, improving computational efficiency, they cannot match the performance of dedicated hardware accelerators with built-in LUT support. Achieving significant improvements in performance, power, and area (PPA) requires overcoming four key challenges:</p>



<ol class="wp-block-list">
<li><strong>Table precompute and storage:</strong> Precomputing and storing LUTs add overhead, increasing area usage, latency, and storage requirements, which can reduce overall efficiency gains.</li>



<li><strong>Bit-width flexibility:</strong> Hardware must support various precision levels, such as int4/2/1 for weights and FP16/8 or int8 for activations, along with their combinations. This flexibility is crucial for accommodating diverse model architectures and use cases.</li>



<li><strong>LUT tiling shape: </strong>Inefficient tiling shapes can raise storage costs and limit reuse opportunities, adversely affecting performance and efficiency.</li>



<li><strong>Instruction and compilation: </strong>LUT-based mpGEMM requires a new instruction set. Existing compilation stacks, designed for standard GEMM hardware, may not optimally map and schedule these instructions, complicating integration with LLM inference software.</li>
</ol>



<p>In response, we developed <a href="https://www.microsoft.com/en-us/research/publication/lut-tensor-core-lookup-table-enables-efficient-low-bit-llm-inference-acceleration/">LUT Tensor Core</a>, a software-hardware codesign for low-bit LLM inference. To address precomputation overhead in conventional LUT-based methods, we introduce techniques like software-based DFG transformation, operator fusion, and table symmetrization to optimize table precomputation and storage. Additionally, we propose a hardware design with an elongated tiling shape to support table reuse and a bit-serial design to handle various precision combinations in mpGEMM.</p>



<p>To integrate with existing GPU microarchitectures and software stacks, we extended the MMA instruction set, added new LMMA instructions, and developed a cuBLAS-like software stack for easy integration into existing DNN frameworks. We also created a compiler for end-to-end execution planning on GPUs with LUT Tensor Core. This design and workflow, illustrated in Figure 3, enabled the quick and seamless adoption of LUT Tensor Core.</p>



<figure class="wp-block-image aligncenter size-full"><img loading="lazy" decoding="async" width="1266" height="533" src="https://www.microsoft.com/en-us/research/uploads/prod/2025/01/Low-bit_figure3.png" alt="Figure 3: Diagram of the LUT Tensor Core workflow. The left side shows operator fusion, where 'Norm' produces activations for pre-computation, and 'Weight Reinterpretation' processes low-bit weights. Both feed into LUT-mpGEMM, utilizing an activation LUT table and reinterpreted weights. The right side illustrates the LUT Tensor Core, comprising a LUT table for precomputed values, low-bit weights, and multiplexers (MUX) for computation." class="wp-image-1123680" srcset="https://www.microsoft.com/en-us/research/uploads/prod/2025/01/Low-bit_figure3.png 1266w, https://www.microsoft.com/en-us/research/uploads/prod/2025/01/Low-bit_figure3-300x126.png 300w, https://www.microsoft.com/en-us/research/uploads/prod/2025/01/Low-bit_figure3-1024x431.png 1024w, https://www.microsoft.com/en-us/research/uploads/prod/2025/01/Low-bit_figure3-768x323.png 768w, https://www.microsoft.com/en-us/research/uploads/prod/2025/01/Low-bit_figure3-240x101.png 240w" sizes="auto, (max-width: 1266px) 100vw, 1266px" /><figcaption class="wp-element-caption">Figure 3. The LUT Tensor Core workflow</figcaption></figure>



<h3 class="wp-block-heading" id="evaluating-lut-tensor-core">Evaluating LUT Tensor Core</h3>



<p>Testing LUT Tensor Core on low-bit LLMs, such as BitNet and Llama, showed significant performance gains, achieving 6.93 times the inference speed while using just 38.3% of the area of a traditional Tensor Core. With nearly identical model accuracy, this results in a 20.9-fold increase in computational density and an 11.2-fold boost in energy efficiency. As AI models grow in scale and complexity, LUT Tensor Core enables low-bit LLMs to be applied in new and diverse scenarios.</p>



<p>We believe the LUT technique could drive a paradigm shift in AI model inference. Traditional methods rely on multiplication and accumulation operations, whereas LUT implementations provide higher transistor density, greater throughput per chip area, lower energy costs, and better scalability. As large models adopt low-bit quantization, the LUT method could become the standard for system and hardware design, advancing the next generation of AI hardware innovation.</p>



<h2 class="wp-block-heading" id="unlocking-new-possibilities-for-embodied-ai">Unlocking new possibilities for embodied AI</h2>



<p>Low-bit quantization improves the efficiency of running large models on edge devices while also enabling model scaling by reducing the bits used to represent each parameter. This scaling enhances model capabilities, generality, and expressiveness, as shown by the <a href="https://www.microsoft.com/en-us/research/publication/the-era-of-1-bit-llms-all-large-language-models-are-in-1-58-bits/">BitNet model</a>, which starts with a low-bit configuration and expands.</p>



<p>Technologies like T-MAC, Ladder, and LUT Tensor Core provide solutions for running low-bit quantized LLMs, supporting efficient operation across edge devices and encouraging researchers to design and optimize LLMs using low-bit quantization. By reducing memory and computational demands, low-bit LLMs could power embodied AI systems, such as robots, enabling dynamic perception and real-time environmental interaction.</p>



<p><a class="msr-external-link glyph-append glyph-append-open-in-new-tab glyph-append-xsmall" href="https://github.com/microsoft/T-MAC" target="_blank" rel="noreferrer noopener">T-MAC<span class="sr-only"> (opens in new tab)</span></a> and <a class="msr-external-link glyph-append glyph-append-open-in-new-tab glyph-append-xsmall" href="https://github.com/microsoft/BitBLAS" target="_blank" rel="noreferrer noopener">Ladder<span class="sr-only"> (opens in new tab)</span></a> are open source and available on GitHub. We invite you to test and explore these innovations in AI technology with Microsoft Research.</p>



	<div class="border-bottom border-top border-gray-300 mt-5 mb-5 msr-promo text-center text-md-left alignwide" data-bi-aN="promo" data-bi-id="670821">
		

		<p class="msr-promo__label text-gray-800 text-center text-uppercase">
		<span class="px-4 bg-white display-inline-block font-weight-semibold small">Spotlight: Microsoft research newsletter</span>
	</p>
	
	<div class="row pt-3 pb-4 align-items-center">
						<div class="msr-promo__media col-12 col-md-5">
				<a class="bg-gray-300" href="https://info.microsoft.com/ww-landing-microsoft-research-newsletter.html" aria-label="Microsoft Research Newsletter" data-bi-cN="Microsoft Research Newsletter" target="_blank">
					<img decoding="async" class="w-100 display-block" src="https://www.microsoft.com/en-us/research/uploads/prod/2019/09/Newsletter_Banner_08_2019_v1_1920x1080.png" alt="" />
				</a>
			</div>
			
			<div class="msr-promo__content p-3 px-5 col-12 col-md">

									<h2 class="h4">Microsoft Research Newsletter</h2>
				
								<p class="large">Stay connected to the research community at Microsoft.</p>
				
								<div class="wp-block-buttons justify-content-center justify-content-md-start">
					<div class="wp-block-button is-style-fill-chevron">
						<a href="https://info.microsoft.com/ww-landing-microsoft-research-newsletter.html" class="btn btn-brand glyph-append glyph-append-chevron-right" aria-label="Microsoft Research Newsletter" data-bi-cN="Microsoft Research Newsletter" target="_blank">
							Subscribe today						</a>
					</div>
				</div>
							</div><!--/.msr-promo__content-->
	</div><!--/.msr-promo__inner-wrap-->
<span id="label-external-link" class="sr-only" aria-hidden="true">Opens in a new tab</span>	</div><!--/.msr-promo-->
	<span id="label-external-link" class="sr-only" aria-hidden="true">Opens in a new tab</span><p>The post <a href="https://www.microsoft.com/en-us/research/blog/advances-to-low-bit-quantization-enable-llms-on-edge-devices/">Advances to low-bit quantization enable LLMs on edge devices</a> appeared first on <a href="https://www.microsoft.com/en-us/research">Microsoft Research</a>.</p>
]]></content:encoded>
					
		
		
			</item>
		<item>
		<title>Research Focus: Week of January 27, 2025</title>
		<link>https://www.microsoft.com/en-us/research/blog/research-focus-week-of-january-27-2025/</link>
		
		<dc:creator><![CDATA[Brenda Potts]]></dc:creator>
		<pubDate>Fri, 31 Jan 2025 17:17:08 +0000</pubDate>
				<category><![CDATA[Research Blog]]></category>
		<guid isPermaLink="false">https://www.microsoft.com/en-us/research/?p=1124682</guid>

					<description><![CDATA[<p>In this issue: A new approach to multimodal pretraining for remote sensing; Managed-retention memory for the AI era; Improving detection of macular telangiectasia type 2; Generalizing symbolic automata.</p>
<p>The post <a href="https://www.microsoft.com/en-us/research/blog/research-focus-week-of-january-27-2025/">Research Focus: Week of January 27, 2025</a> appeared first on <a href="https://www.microsoft.com/en-us/research">Microsoft Research</a>.</p>
]]></description>
										<content:encoded><![CDATA[
<p class="has-text-align-center"><strong>In this edition:</strong></p>



<ul class="wp-block-list">
<li>We introduce FLAVARS, a multimodal foundation language and vision alignment model for remote sensing; Managed-retention memory, a new class of memory which is more optimized to store key data structures for AI inference workloads; and Enhanced detection of macular telangiectasia type 2 (MacTel 2) using self-supervised learning and ensemble models.</li>



<li>We present a new approach to generalizing symbolic automata, which brings together a variety of classic automata and logics in a unified framework with all the necessary ingredients to support symbolic model checking modulo <em>A</em>.&nbsp;</li>



<li>And we invite you to join an upcoming workshop: LLM4Eval@WSDM 2025: Large Language Models for Evaluation in Information Retrieval. LLM4Eval is a promising technique in the areas of automated judgments, natural language generation, and retrieval augmented generation (RAG) systems. Researchers from Microsoft and experts from industry and academia will explore this technique at an interactive workshop on Friday, March 14, in Hanover, Germany.&nbsp;</li>
</ul>



<figure class="wp-block-image size-full"><img loading="lazy" decoding="async" width="1400" height="788" src="https://www.microsoft.com/en-us/research/uploads/prod/2025/01/NEWRF57-BlogHeroFeature-1400x788-1.jpg" alt="Research Focus: Week of January 31, 2025" class="wp-image-1125636" srcset="https://www.microsoft.com/en-us/research/uploads/prod/2025/01/NEWRF57-BlogHeroFeature-1400x788-1.jpg 1400w, https://www.microsoft.com/en-us/research/uploads/prod/2025/01/NEWRF57-BlogHeroFeature-1400x788-1-300x169.jpg 300w, https://www.microsoft.com/en-us/research/uploads/prod/2025/01/NEWRF57-BlogHeroFeature-1400x788-1-1024x576.jpg 1024w, https://www.microsoft.com/en-us/research/uploads/prod/2025/01/NEWRF57-BlogHeroFeature-1400x788-1-768x432.jpg 768w, https://www.microsoft.com/en-us/research/uploads/prod/2025/01/NEWRF57-BlogHeroFeature-1400x788-1-1066x600.jpg 1066w, https://www.microsoft.com/en-us/research/uploads/prod/2025/01/NEWRF57-BlogHeroFeature-1400x788-1-655x368.jpg 655w, https://www.microsoft.com/en-us/research/uploads/prod/2025/01/NEWRF57-BlogHeroFeature-1400x788-1-240x135.jpg 240w, https://www.microsoft.com/en-us/research/uploads/prod/2025/01/NEWRF57-BlogHeroFeature-1400x788-1-640x360.jpg 640w, https://www.microsoft.com/en-us/research/uploads/prod/2025/01/NEWRF57-BlogHeroFeature-1400x788-1-960x540.jpg 960w, https://www.microsoft.com/en-us/research/uploads/prod/2025/01/NEWRF57-BlogHeroFeature-1400x788-1-1280x720.jpg 1280w" sizes="auto, (max-width: 1400px) 100vw, 1400px" /></figure>



<div class="wp-block-group is-layout-constrained wp-block-group-is-layout-constrained">
<h2 class="wp-block-heading h6 has-blue-color has-text-color has-link-color wp-elements-e734c6e9609233ab051742bb3beeed63" id="new-research">NEW RESEARCH</h2>



<h3 class="wp-block-heading h2" id="heading">FLAVARS: A Multimodal Foundational Language and Vision Alignment Model for Remote Sensing</h3>



<p>In the field of remote sensing, imagery is generally dense with objects and visual content which can vary regionally across the globe. This creates a need for vision-language datasets to be highly detailed when describing imagery, and for pretraining to better balance visual task performance while retaining the ability to perform zero-shot classification and image-text retrieval.</p>



<p>One strategy is to combine paired satellite images and text captions for pretraining performant encoders for downstream tasks. However, while contrastive image-text methods like CLIP enable vision-language alignment and zero-shot classification ability, CLIP’s vision-only downstream performance tends to degrade compared to image-only pretraining, such as Masked Autoencoders (MAE).</p>



<p>To better approach multimodal pretraining for remote sensing, researchers from Microsoft propose a pretraining method that combines the best of both contrastive learning and masked modeling, along with geospatial alignment via contrastive location encoding, in the recent paper: <a href="https://www.microsoft.com/en-us/research/publication/flavars-a-multimodal-foundational-language-and-vision-alignment-model-for-remote-sensing/">FLAVARS: A Multimodal Foundational Language and Vision Alignment Model for Remote Sensing</a>. The research shows that FLAVARS significantly outperforms a baseline of SkyCLIP for vision-only tasks such as KNN classification and semantic segmentation, +6% mIOU on SpaceNet1, while retaining the ability to perform zero-shot classification, unlike MAE pretrained methods.</p>



<div class="wp-block-buttons is-content-justification-center is-content-justification-center is-layout-flex wp-container-core-buttons-is-layout-1 wp-block-buttons-is-layout-flex">
<div class="wp-block-button is-style-outline is-style-outline--2"><a data-bi-type="button" class="wp-block-button__link wp-element-button" href="https://www.microsoft.com/en-us/research/publication/flavars-a-multimodal-foundational-language-and-vision-alignment-model-for-remote-sensing/">Read the paper</a></div>
</div>



<hr class="wp-block-separator has-alpha-channel-opacity is-style-dots"/>
</div>



<div class="wp-block-group is-layout-constrained wp-block-group-is-layout-constrained">
<h2 class="wp-block-heading h6 has-blue-color has-text-color has-link-color wp-elements-e734c6e9609233ab051742bb3beeed63" id="new-research">NEW RESEARCH</h2>



<h3 class="wp-block-heading h2" id="heading">Managed-Retention Memory: A New Class of Memory for the AI Era</h3>



<p>AI clusters today are one of the major uses of high bandwidth memory (HBM), a high-performance type of computer memory. However, HBM is suboptimal for AI inference workloads for several reasons. Analysis shows that HBM is overprovisioned on write performance, underprovisioned on density and read bandwidth, and has significant energy-per-bit overhead. It is also expensive, with lower yield than DRAM due to manufacturing complexity.</p>



<p>In a recent paper: <a href="https://www.microsoft.com/en-us/research/publication/managed-retention-memory-a-new-class-of-memory-for-the-ai-era/">Managed-Retention Memory: A New Class of Memory for the AI Era</a>, researchers from Microsoft propose a memory class which is more optimized to store key data structures for AI inference workloads. The paper makes the case that MRM may finally provide a path to viability for technologies that were originally proposed to support storage class memory (SCM). These technologies traditionally offered long-term persistence (10+ years) but provided poor IO performance and/or endurance. MRM makes different trade-offs, and by understanding the workload IO patterns, MRM foregoes long-term data retention and write performance for better potential performance on the metrics important for AI inference.</p>



<div class="wp-block-buttons is-content-justification-center is-content-justification-center is-layout-flex wp-container-core-buttons-is-layout-2 wp-block-buttons-is-layout-flex">
<div class="wp-block-button is-style-outline is-style-outline--3"><a data-bi-type="button" class="wp-block-button__link wp-element-button" href="https://www.microsoft.com/en-us/research/publication/managed-retention-memory-a-new-class-of-memory-for-the-ai-era/">Read the paper</a></div>
</div>



<hr class="wp-block-separator has-alpha-channel-opacity is-style-dots"/>
</div>



<div class="wp-block-group is-layout-constrained wp-block-group-is-layout-constrained">
<h2 class="wp-block-heading h6 has-blue-color has-text-color has-link-color wp-elements-e734c6e9609233ab051742bb3beeed63" id="new-research">NEW RESEARCH</h2>



<h3 class="wp-block-heading h2" id="heading">Enhanced Macular Telangiectasia Type 2 Detection: Leveraging Self-Supervised Learning and Ensemble Models</h3>



<p>Macular telangiectasia type 2 (MacTel) is a retinal disease that is challenging to diagnose. While increased awareness has led to improved diagnostic outcomes, MacTel diagnosis relies significantly upon a multimodal image set and the expertise of clinicians familiar with the disease. Optical coherence tomography (OCT) imaging has emerged as a valuable tool for the diagnosis and monitoring of various retinal diseases. With the increasing integration of OCT into clinical practice, deep learning models may be able to achieve accurate MacTel prediction comparable to that of retinal specialists, even when working with limited data.</p>



<p>Researchers from Microsoft and external colleagues address this challenge in a recent paper: <a href="https://www.microsoft.com/en-us/research/publication/enhanced-macular-telangiectasia-type-2-detection-leveraging-self-supervised-learning-and-ensemble-models/">Enhanced Macular Telangiectasia Type 2 Detection: Leveraging Self-Supervised Learning and Ensemble Models</a>. Published in the journal of Ophthalmology Science, the paper focuses on the accurate classification of macular telangiectasia type 2 using OCT images, with the overarching goal of facilitating early and precise detection of this neurodegenerative disease.</p>



<p>The researchers present results leveraging self-supervised learning and ensemble models, showing their approach improves both MacTel classification accuracy and interpretability when compared to the use of individual models. Ensemble models exhibited superior agreement with the assessments of the most experienced individual human experts, as well as the ensemble of human experts.</p>



<div class="wp-block-buttons is-content-justification-center is-content-justification-center is-layout-flex wp-container-core-buttons-is-layout-3 wp-block-buttons-is-layout-flex">
<div class="wp-block-button is-style-outline is-style-outline--4"><a data-bi-type="button" class="wp-block-button__link wp-element-button" href="https://www.microsoft.com/en-us/research/publication/enhanced-macular-telangiectasia-type-2-detection-leveraging-self-supervised-learning-and-ensemble-models/">Read the paper</a></div>
</div>



<hr class="wp-block-separator has-alpha-channel-opacity is-style-dots"/>
</div>



	<div class="border-bottom border-top border-gray-300 mt-5 mb-5 msr-promo text-center text-md-left alignwide" data-bi-aN="promo" data-bi-id="1061244">
		

	
	<div class="row pt-3 pb-4 align-items-center">
						<div class="msr-promo__media col-12 col-md-5">
				<a class="bg-gray-300" href="https://www.microsoft.com/en-us/research/about-microsoft-research/" aria-label="About Microsoft Research" data-bi-cN="About Microsoft Research" target="_blank">
					<img decoding="async" class="w-100 display-block" src="https://www.microsoft.com/en-us/research/uploads/prod/2024/07/About-page-promo_1066x600.jpg" alt="" />
				</a>
			</div>
			
			<div class="msr-promo__content p-3 px-5 col-12 col-md">

									<h2 class="h4">About Microsoft Research</h2>
				
								<p class="large">Advancing science and technology to benefit humanity</p>
				
								<div class="wp-block-buttons justify-content-center justify-content-md-start">
					<div class="wp-block-button">
						<a href="https://www.microsoft.com/en-us/research/about-microsoft-research/" class="btn btn-brand glyph-append glyph-append-chevron-right" aria-label="View our story" data-bi-cN="About Microsoft Research" target="_blank">
							View our story						</a>
					</div>
				</div>
							</div><!--/.msr-promo__content-->
	</div><!--/.msr-promo__inner-wrap-->
<span id="label-external-link" class="sr-only" aria-hidden="true">Opens in a new tab</span>	</div><!--/.msr-promo-->
	


<div class="wp-block-group is-layout-constrained wp-block-group-is-layout-constrained">
<h2 class="wp-block-heading h6 has-blue-color has-text-color has-link-color wp-elements-e734c6e9609233ab051742bb3beeed63" id="new-research">NEW RESEARCH</h2>



<h3 class="wp-block-heading h2" id="heading">Symbolic Automata: Omega-Regularity Modulo Theories</h3>



<p>Symbolic automata are finite state automata that support potentially infinite alphabets, such as the set of rational numbers, generally applied to regular expressions and languages over finite words. In symbolic automata (or automata modulo<em> A</em>), an alphabet is represented by an effective Boolean algebra <em>A</em>, supported by a decision procedure for satisfiability. Regular languages over infinite words (so called 𝜔-regular languages) have a rich history paralleling that of regular languages over finite words, with well-known applications to model checking via Büchi automata and temporal logics.</p>



<p>In a recent paper: <a href="https://www.microsoft.com/en-us/research/publication/symbolic-automata-omega-regularity-modulo-theories/">Symbolic Automata: Omega-Regularity Modulo Theories</a>, researchers from Microsoft generalize symbolic automata to support 𝜔-regular languages via <em>transition terms</em> and <em>symbolic derivatives</em>. This brings together a variety of classic automata and logics in a unified framework that provides all the necessary ingredients to support symbolic model checking modulo <em>A</em>.</p>



<div class="wp-block-buttons is-content-justification-center is-content-justification-center is-layout-flex wp-container-core-buttons-is-layout-4 wp-block-buttons-is-layout-flex">
<div class="wp-block-button is-style-outline is-style-outline--5"><a data-bi-type="button" class="wp-block-button__link wp-element-button" href="https://www.microsoft.com/en-us/research/publication/symbolic-automata-omega-regularity-modulo-theories/">Read the paper</a></div>
</div>



<hr class="wp-block-separator has-alpha-channel-opacity is-style-dots"/>
</div>



<div class="wp-block-group is-layout-constrained wp-block-group-is-layout-constrained">
<h2 class="wp-block-heading h6 has-blue-color has-text-color has-link-color wp-elements-b60fbfa117bcce78e07885aa24d19fc7" id="new-research">EVENT</h2>



<h3 class="wp-block-heading h2" id="heading">LLM4Eval@WSDM 2025: Large Language Models for Evaluation in Information Retrieval – March 14, 2025</h3>



<p>LLMs have shown increasing task-solving abilities not present in smaller models. Using LLMs for automated evaluation (LLM4Eval) is a promising technique in the areas of automated judgments, natural language generation, and retrieval augmented generation (RAG) systems.</p>



<p>Join researchers from Microsoft and experts from industry and academia for a discussion on using LLMs for evaluation in information retrieval at <a class="msr-external-link glyph-append glyph-append-open-in-new-tab glyph-append-xsmall" href="https://llm4eval.github.io/WSDM2025/" target="_blank" rel="noreferrer noopener">LLM4Eval Workshop &#8211; WSDM 2025<span class="sr-only"> (opens in new tab)</span></a>, March 14, 2025, in Hanover, Germany.</p>



<p>This interactive workshop will cover automated judgments, RAG pipeline evaluation, altering human evaluation, robustness, and trustworthiness of LLMs for evaluation in addition to their impact on real-world applications. The organizers believe that the information retrieval community can significantly contribute to this growing research area by designing, implementing, analyzing, and evaluating various aspects of LLMs with applications to LLM4Eval tasks.</p>



<div class="wp-block-buttons is-content-justification-center is-content-justification-center is-layout-flex wp-container-core-buttons-is-layout-5 wp-block-buttons-is-layout-flex">
<div class="wp-block-button is-style-outline is-style-outline--6"><a data-bi-type="button" class="wp-block-button__link wp-element-button" href="https://llm4eval.github.io/WSDM2025/" target="_blank" rel="noreferrer noopener">Learn more about the workshop</a></div>
</div>



<hr class="wp-block-separator has-alpha-channel-opacity is-style-dots"/>
</div>



<div style="padding-bottom:64px; padding-top:64px" class="wp-block-msr-immersive-section alignfull row wp-block-msr-immersive-section">
	
	<div class="container">
		<div class="wp-block-msr-immersive-section__inner">
			<div class="wp-block-msr-cards msr-cards msr-cards--default mt-4 has-text-align-left" data-bi-aN="microsoft-research-in-case-you-missed-it">
	<div class="msr-cards__inner">
					<div class="heading-wrapper">
				<h2 class="mb-5 ">Microsoft Research | In case you missed it</h2>
			</div>
		
		<div class="row row-cols-1 row-cols-sm-2 row-cols-lg-3">
	<div class="msr-cards__card msr-cards__card--default col">
	<div class="card has-spectrum-border-top__hover material-card h-100 p-0" data-mount="click-group">

		
		<div class="card-body bg-white p-4 pt-3">
							<h3 class="h5">
					<a
						class="text-decoration-none text-black"
						data-bi-cN="Microsoft Team Uses Diffusion Model For Materials Science"
						href="https://www.forbes.com/sites/johnwerner/2025/01/21/microsoft-team-uses-diffusion-model-for-materials-science/"
					>
						<span>Microsoft Team Uses Diffusion Model For Materials Science</span>&nbsp;<span class="glyph-prepend glyph-prepend-small glyph-prepend-chevron-right" aria-hidden="true"></span>
					</a>
				</h3>
										<div class="card__description card__citation small">
					<p>January 21, 2025</p><p>“Finding a new material for a target application is like finding a needle in a haystack,” write the authors of a blog post at Microsoft, where they have been working on just such a program, something called, aptly, MatterGen.</p>				</div>
			
					</div>
	</div>
</div>
<div class="msr-cards__card msr-cards__card--default col">
	<div class="card has-spectrum-border-top__hover material-card h-100 p-0" data-mount="click-group">

		
		<div class="card-body bg-white p-4 pt-3">
							<h3 class="h5">
					<a
						class="text-decoration-none text-black"
						data-bi-cN="Microsoft AutoGen v0.4: A turning point toward more intelligent AI agents for enterprise developers"
						href="https://venturebeat.com/ai/microsoft-autogen-v0-4-a-turning-point-toward-more-intelligent-ai-agents-for-enterprise-developers/"
					>
						<span>Microsoft AutoGen v0.4: A turning point toward more intelligent AI agents for enterprise developers</span>&nbsp;<span class="glyph-prepend glyph-prepend-small glyph-prepend-chevron-right" aria-hidden="true"></span>
					</a>
				</h3>
										<div class="card__description card__citation small">
					<p>January 18, 2025</p><p>The world of AI agents is undergoing a revolution, and Microsoft’s release of AutoGen v0.4 this week marked a significant leap forward in this journey. Positioned as a robust, scalable and extensible framework, AutoGen represents Microsoft’s latest attempt to address the challenges of building multi-agent systems for enterprise applications. </p>				</div>
			
					</div>
	</div>
</div>
<div class="msr-cards__card msr-cards__card--default col">
	<div class="card has-spectrum-border-top__hover material-card h-100 p-0" data-mount="click-group">

		
		<div class="card-body bg-white p-4 pt-3">
							<h3 class="h5">
					<a
						class="text-decoration-none text-black"
						data-bi-cN="2 AI breakthroughs unlock new potential for health and science"
						href="https://news.microsoft.com/source/features/ai/2-ai-breakthroughs-unlock-new-potential-for-health-and-science/"
					>
						<span>2 AI breakthroughs unlock new potential for health and science</span>&nbsp;<span class="glyph-prepend glyph-prepend-small glyph-prepend-chevron-right" aria-hidden="true"></span>
					</a>
				</h3>
										<div class="card__description card__citation small">
					<p>January 17, 2025</p><p>Two new research papers published this week in scientific journals, one in Nature and one in Nature Machine Intelligence, show how generative AI foundation models can exponentially speed up scientific discovery of new materials and help doctors access and analyze radiology results faster.</p>				</div>
			
					</div>
	</div>
</div>
<div class="msr-cards__card msr-cards__card--default col">
	<div class="card has-spectrum-border-top__hover material-card h-100 p-0" data-mount="click-group">

		
		<div class="card-body bg-white p-4 pt-3">
							<h3 class="h5">
					<a
						class="text-decoration-none text-black"
						data-bi-cN="ChatGPT gets proactive with 'Tasks'"
						href="https://www.therundown.ai/p/chatgpt-gets-proactive-with-tasks"
					>
						<span>ChatGPT gets proactive with 'Tasks'</span>&nbsp;<span class="glyph-prepend glyph-prepend-small glyph-prepend-chevron-right" aria-hidden="true"></span>
					</a>
				</h3>
										<div class="card__description card__citation small">
					<p>January 15, 2025</p><p>Good morning, AI enthusiasts. OpenAI’s AI agent era just got its unofficial start — with ChatGPT gaining the ability to schedule and manage daily tasks. With ‘Tasks’ rolling out and mysterious &#8216;Operator&#8217; whispers in the air, is OpenAI finally ready to move from chatbots to full-on autonomous assistants?</p>				</div>
			
					</div>
	</div>
</div>
<div class="msr-cards__card msr-cards__card--default col">
	<div class="card has-spectrum-border-top__hover material-card h-100 p-0" data-mount="click-group">

		
		<div class="card-body bg-white p-4 pt-3">
							<h3 class="h5">
					<a
						class="text-decoration-none text-black"
						data-bi-cN="Mayo Clinic and Microsoft partner to advance generative AI in radiology"
						href="https://healthimaging.com/topics/artificial-intelligence/mayo-clinic-and-microsoft-partner-advance-generative-ai-radiology"
					>
						<span>Mayo Clinic and Microsoft partner to advance generative AI in radiology</span>&nbsp;<span class="glyph-prepend glyph-prepend-small glyph-prepend-chevron-right" aria-hidden="true"></span>
					</a>
				</h3>
										<div class="card__description card__citation small">
					<p>January 15, 2025</p><p>The Mayo Clinic is seeking to advance the use of generative artificial intelligence in imaging through a new collaboration with Microsoft Research. The duo made the announcement during the 43rd Annual J.P. Morgan Healthcare Conference taking place now in San Francisco. </p>				</div>
			
					</div>
	</div>
</div>
</div>

					<div class="justify-content-center text-center mb-4">
				<a
					href="https://www.microsoft.com/en-us/research/news-and-awards/"
					class="btn btn-outline-primary glyph-append glyph-append-small glyph-append-chevron-right msr-cards__cta"
					data-bi-cN="View more news and awards"
					data-bi-type="button"
				>
					View more news and awards				</a>
			</div>
			</div>
</div>		</div>
	</div>

	</div>
<span id="label-external-link" class="sr-only" aria-hidden="true">Opens in a new tab</span><p>The post <a href="https://www.microsoft.com/en-us/research/blog/research-focus-week-of-january-27-2025/">Research Focus: Week of January 27, 2025</a> appeared first on <a href="https://www.microsoft.com/en-us/research">Microsoft Research</a>.</p>
]]></content:encoded>
					
		
		
			</item>
		<item>
		<title>Ideas: Bug hunting with Shan Lu</title>
		<link>https://www.microsoft.com/en-us/research/podcast/ideas-bug-hunting-with-shan-lu/</link>
		
		<dc:creator><![CDATA[Alyssa Hughes (2ADAPTIVE LLC dba 2A Consulting)]]></dc:creator>
		<pubDate>Thu, 23 Jan 2025 17:07:54 +0000</pubDate>
				<category><![CDATA[Microsoft Research Podcast]]></category>
		<guid isPermaLink="false">https://www.microsoft.com/en-us/research/?p=1122786</guid>

					<description><![CDATA[<p>Struggles with programming languages helped research manager Shan Lu find her calling as a bug hunter. She discusses one bug that really haunted her, the thousands she’s identified since, and how she’s turning to LLMs to help make software more reliable.</p>
<p>The post <a href="https://www.microsoft.com/en-us/research/podcast/ideas-bug-hunting-with-shan-lu/">Ideas: Bug hunting with Shan Lu</a> appeared first on <a href="https://www.microsoft.com/en-us/research">Microsoft Research</a>.</p>
]]></description>
										<content:encoded><![CDATA[
<figure class="wp-block-image size-full"><img loading="lazy" decoding="async" width="1401" height="788" src="https://www.microsoft.com/en-us/research/uploads/prod/2025/01/Shan-Lu_Ideas_Hero_Feature_No_Text_1400x788.jpg" alt="Ideas podcast | illustration of Shan Lu" class="wp-image-1123245" srcset="https://www.microsoft.com/en-us/research/uploads/prod/2025/01/Shan-Lu_Ideas_Hero_Feature_No_Text_1400x788.jpg 1401w, https://www.microsoft.com/en-us/research/uploads/prod/2025/01/Shan-Lu_Ideas_Hero_Feature_No_Text_1400x788-300x169.jpg 300w, https://www.microsoft.com/en-us/research/uploads/prod/2025/01/Shan-Lu_Ideas_Hero_Feature_No_Text_1400x788-1024x576.jpg 1024w, https://www.microsoft.com/en-us/research/uploads/prod/2025/01/Shan-Lu_Ideas_Hero_Feature_No_Text_1400x788-768x432.jpg 768w, https://www.microsoft.com/en-us/research/uploads/prod/2025/01/Shan-Lu_Ideas_Hero_Feature_No_Text_1400x788-1066x600.jpg 1066w, https://www.microsoft.com/en-us/research/uploads/prod/2025/01/Shan-Lu_Ideas_Hero_Feature_No_Text_1400x788-655x368.jpg 655w, https://www.microsoft.com/en-us/research/uploads/prod/2025/01/Shan-Lu_Ideas_Hero_Feature_No_Text_1400x788-240x135.jpg 240w, https://www.microsoft.com/en-us/research/uploads/prod/2025/01/Shan-Lu_Ideas_Hero_Feature_No_Text_1400x788-640x360.jpg 640w, https://www.microsoft.com/en-us/research/uploads/prod/2025/01/Shan-Lu_Ideas_Hero_Feature_No_Text_1400x788-960x540.jpg 960w, https://www.microsoft.com/en-us/research/uploads/prod/2025/01/Shan-Lu_Ideas_Hero_Feature_No_Text_1400x788-1280x720.jpg 1280w" sizes="auto, (max-width: 1401px) 100vw, 1401px" /></figure>


<div class="wp-block-msr-podcast-container my-4">
	<iframe loading="lazy" src="https://player.blubrry.com/?podcast_id=141329016&modern=1" class="podcast-player" frameborder="0" height="164px" width="100%" scrolling="no" title="Podcast Player"></iframe>
</div>



<p>Behind every emerging technology is a great idea propelling it forward. In the Microsoft Research Podcast series <em>Ideas</em>, members of the research community at Microsoft discuss the beliefs that animate their research, the experiences and thinkers that inform it, and the positive human impact it targets.</p>



<p>In this episode, host Gretchen Huizinga talks with <a href="https://www.microsoft.com/en-us/research/people/shanlu/?msockid=35739e94ab6c69d41b738b93aa076831">Shan Lu</a>, a senior principal research manager at Microsoft. As a college student studying computer science, Lu saw classmates seemingly learn and navigate one new programming language after another with ease while she struggled. She felt like she just wasn’t meant to be a programmer. But this perceived lack of skill turned out to be, as an early mentor pointed out when she began grad school, what made Lu an ideal bug hunter. It’s a path she’s pursued since. After studying bugs in concurrent systems for more than 15 years—she and her coauthors built a tool that identified over a thousand in a <a href="https://www.microsoft.com/en-us/research/publication/efficient-and-scalable-thread-safety-violation-detection-finding-thousands-of-concurrency-bugs-during-testing/?msockid=35739e94ab6c69d41b738b93aa076831">2019 award-winning paper</a>—Lu is focusing on other types of code defects. Recently, Lu and collaborators combined traditional program analysis and large language models in the search for retry bugs, and she’s now exploring the potential role of LLMs in verifying the correctness of large software systems.</p>



<p><strong>Learn more:</strong></p>



<p><a href="https://www.microsoft.com/en-us/research/publication/if-at-first-you-dont-succeed-try-try-again-insights-and-llm-informed-tooling-for-detecting-retry-bugs-in-software-systems/?msockid=35739e94ab6c69d41b738b93aa076831">If at First You Don’t Succeed, Try, Try, Again&#8230;? Insights and LLM-informed Tooling for Detecting Retry Bugs in Software Systems</a><br>Publication, November 2024</p>



<p><a href="https://www.microsoft.com/en-us/research/podcast/abstracts-november-4-2024/">Abstracts: November 4, 2024</a><br>Microsoft Research Podcast, November 2024</p>



<p><a href="https://www.microsoft.com/en-us/research/publication/automated-proof-generation-for-rust-code-via-self-evolution/" target="_blank" rel="noreferrer noopener">Automated Proof Generation for Rust Code via Self-Evolution</a>&nbsp;<br>Publication, October 2024</p>



<p><a href="https://www.microsoft.com/en-us/research/publication/autoverus-automated-proof-generation-for-rust-code/">AutoVerus: Automated Proof Generation for Rust Code</a><br>Publication, September 2024</p>



<p><a href="https://www.microsoft.com/en-us/research/publication/efficient-and-scalable-thread-safety-violation-detection-finding-thousands-of-concurrency-bugs-during-testing/?msockid=35739e94ab6c69d41b738b93aa076831">Efficient and Scalable Thread-Safety Violation Detection &#8211; Finding thousands of concurrency bugs during testing</a><br>Publication, October 2019</p>



<p><a href="https://www.microsoft.com/en-us/research/publication/learning-from-mistakes-a-comprehensive-study-on-real-world-concurrency-bug-characteristics/">Learning from Mistakes: A Comprehensive Study on Real World Concurrency Bug Characteristics</a><br>Publication, March 2008&nbsp;</p>



<p><a href="https://www.microsoft.com/en-us/research/publication/verus-a-practical-foundation-for-systems-verification/?msockid=35739e94ab6c69d41b738b93aa076831">Verus: A Practical Foundation for Systems Verification</a><br>Publication, November 2024</p>



<section class="wp-block-msr-subscribe-to-podcast subscribe-to-podcast">
	<div class="subscribe-to-podcast__inner border-top border-bottom border-width-2">
		<h2 class="h5 subscribe-to-podcast__heading">
			Subscribe to the <a href="https://www.microsoft.com/en-us/research/podcast">Microsoft Research Podcast</a>:		</h2>
		<ul class="subscribe-to-podcast__list list-unstyled">
							<li class="subscribe-to-podcast__list-item">
					<a class="subscribe-to-podcast__link" href="https://itunes.apple.com/us/podcast/microsoft-research-a-podcast/id1318021537?mt=2" target="_blank" rel="noreferrer noopener">
						<svg class="subscribe-to-podcast__svg" xmlns="http://www.w3.org/2000/svg" fill="black" viewBox="0 0 32 32">  <path d="M7.12 0c-3.937-0.011-7.131 3.183-7.12 7.12v17.76c-0.011 3.937 3.183 7.131 7.12 7.12h17.76c3.937 0.011 7.131-3.183 7.12-7.12v-17.76c0.011-3.937-3.183-7.131-7.12-7.12zM15.817 3.421c3.115 0 5.932 1.204 8.079 3.453 1.631 1.693 2.547 3.489 3.016 5.855 0.161 0.787 0.161 2.932 0.009 3.817-0.5 2.817-2.041 5.339-4.317 7.063-0.812 0.615-2.797 1.683-3.115 1.683-0.12 0-0.129-0.12-0.077-0.615 0.099-0.792 0.192-0.953 0.64-1.141 0.713-0.296 1.932-1.167 2.677-1.911 1.301-1.303 2.229-2.932 2.677-4.719 0.281-1.1 0.244-3.543-0.063-4.672-0.969-3.595-3.907-6.385-7.5-7.136-1.041-0.213-2.943-0.213-4 0-3.636 0.751-6.647 3.683-7.563 7.371-0.245 1.004-0.245 3.448 0 4.448 0.609 2.443 2.188 4.681 4.255 6.015 0.407 0.271 0.896 0.547 1.1 0.631 0.447 0.192 0.547 0.355 0.629 1.14 0.052 0.485 0.041 0.62-0.072 0.62-0.073 0-0.62-0.235-1.199-0.511l-0.052-0.041c-3.297-1.62-5.407-4.364-6.177-8.016-0.187-0.943-0.224-3.187-0.036-4.052 0.479-2.323 1.396-4.135 2.921-5.739 2.199-2.319 5.027-3.543 8.172-3.543zM16 7.172c0.541 0.005 1.068 0.052 1.473 0.14 3.715 0.828 6.344 4.543 5.833 8.229-0.203 1.489-0.713 2.709-1.619 3.844-0.448 0.573-1.537 1.532-1.729 1.532-0.032 0-0.063-0.365-0.063-0.803v-0.808l0.552-0.661c2.093-2.505 1.943-6.005-0.339-8.296-0.885-0.896-1.912-1.423-3.235-1.661-0.853-0.161-1.031-0.161-1.927-0.011-1.364 0.219-2.417 0.744-3.355 1.672-2.291 2.271-2.443 5.791-0.348 8.296l0.552 0.661v0.813c0 0.448-0.037 0.807-0.084 0.807-0.036 0-0.349-0.213-0.683-0.479l-0.047-0.016c-1.109-0.885-2.088-2.453-2.495-3.995-0.244-0.932-0.244-2.697 0.011-3.625 0.672-2.505 2.521-4.448 5.079-5.359 0.547-0.193 1.509-0.297 2.416-0.281zM15.823 11.156c0.417 0 0.828 0.084 1.131 0.24 0.645 0.339 1.183 0.989 1.385 1.677 0.62 2.104-1.609 3.948-3.631 3.005h-0.015c-0.953-0.443-1.464-1.276-1.475-2.36 0-0.979 0.541-1.828 1.484-2.328 0.297-0.156 0.709-0.235 1.125-0.235zM15.812 17.464c1.319-0.005 2.271 0.463 2.625 1.291 0.265 0.62 0.167 2.573-0.292 5.735-0.307 2.208-0.479 2.765-0.905 3.141-0.589 0.52-1.417 0.667-2.209 0.385h-0.004c-0.953-0.344-1.157-0.808-1.553-3.527-0.452-3.161-0.552-5.115-0.285-5.735 0.348-0.823 1.296-1.285 2.624-1.291z"/></svg>
						<span class="subscribe-to-podcast__link-text">Apple Podcasts</span>
					</a>
				</li>
			
							<li class="subscribe-to-podcast__list-item">
					<a class="subscribe-to-podcast__link" href="https://subscribebyemail.com/www.blubrry.com/feeds/microsoftresearch.xml" target="_blank" rel="noreferrer noopener">
						<svg class="subscribe-to-podcast__svg" xmlns="http://www.w3.org/2000/svg" fill="none" viewBox="0 0 32 32"><path fill="currentColor" d="M6.4 6a2.392 2.392 0 00-2.372 2.119L16 15.6l11.972-7.481A2.392 2.392 0 0025.6 6H6.4zM4 10.502V22.8a2.4 2.4 0 002.4 2.4h19.2a2.4 2.4 0 002.4-2.4V10.502l-11.365 7.102a1.2 1.2 0 01-1.27 0L4 10.502z"/></svg>
						<span class="subscribe-to-podcast__link-text">Email</span>
					</a>
				</li>
			
							<li class="subscribe-to-podcast__list-item">
					<a class="subscribe-to-podcast__link" href="https://subscribeonandroid.com/www.blubrry.com/feeds/microsoftresearch.xml" target="_blank" rel="noreferrer noopener">
						<svg class="subscribe-to-podcast__svg" xmlns="http://www.w3.org/2000/svg" fill="none" viewBox="0 0 32 32"><path fill="currentColor" d="M12.414 4.02c-.062.012-.126.023-.18.06a.489.489 0 00-.12.675L13.149 6.3c-1.6.847-2.792 2.255-3.18 3.944h13.257c-.388-1.69-1.58-3.097-3.179-3.944l1.035-1.545a.489.489 0 00-.12-.675.492.492 0 00-.675.135l-1.14 1.68a7.423 7.423 0 00-2.55-.45c-.899 0-1.758.161-2.549.45l-1.14-1.68a.482.482 0 00-.494-.195zm1.545 3.824a.72.72 0 110 1.44.72.72 0 010-1.44zm5.278 0a.719.719 0 110 1.44.719.719 0 110-1.44zM8.44 11.204A1.44 1.44 0 007 12.644v6.718c0 .795.645 1.44 1.44 1.44.168 0 .33-.036.48-.09v-9.418a1.406 1.406 0 00-.48-.09zm1.44 0V21.76c0 .793.646 1.44 1.44 1.44h10.557c.793 0 1.44-.647 1.44-1.44V11.204H9.878zm14.876 0c-.169 0-.33.035-.48.09v9.418c.15.052.311.09.48.09a1.44 1.44 0 001.44-1.44v-6.719a1.44 1.44 0 00-1.44-1.44zM11.8 24.16v1.92a1.92 1.92 0 003.84 0v-1.92h-3.84zm5.759 0v1.92a1.92 1.92 0 003.84 0v-1.92h-3.84z"/></svg>
						<span class="subscribe-to-podcast__link-text">Android</span>
					</a>
				</li>
			
							<li class="subscribe-to-podcast__list-item">
					<a class="subscribe-to-podcast__link" href="https://open.spotify.com/show/4ndjUXyL0hH1FXHgwIiTWU" target="_blank" rel="noreferrer noopener">
						<svg class="subscribe-to-podcast__svg" xmlns="http://www.w3.org/2000/svg" fill="none" viewBox="0 0 32 32"><path fill="currentColor" d="M16 4C9.383 4 4 9.383 4 16s5.383 12 12 12 12-5.383 12-12S22.617 4 16 4zm5.08 17.394a.781.781 0 01-1.086.217c-1.29-.86-3.477-1.434-5.303-1.434-1.937.002-3.389.477-3.403.482a.782.782 0 11-.494-1.484c.068-.023 1.71-.56 3.897-.562 1.826 0 4.365.492 6.171 1.696.36.24.457.725.217 1.085zm1.56-3.202a.895.895 0 01-1.234.286c-2.338-1.457-4.742-1.766-6.812-1.747-2.338.02-4.207.466-4.239.476a.895.895 0 11-.488-1.723c.145-.041 2.01-.5 4.564-.521 2.329-.02 5.23.318 7.923 1.995.419.26.547.814.286 1.234zm1.556-3.745a1.043 1.043 0 01-1.428.371c-2.725-1.6-6.039-1.94-8.339-1.942h-.033c-2.781 0-4.923.489-4.944.494a1.044 1.044 0 01-.474-2.031c.096-.023 2.385-.55 5.418-.55h.036c2.558.004 6.264.393 9.393 2.23.497.292.663.931.371 1.428z"/></svg>
						<span class="subscribe-to-podcast__link-text">Spotify</span>
					</a>
				</li>
			
							<li class="subscribe-to-podcast__list-item">
					<a class="subscribe-to-podcast__link" href="https://www.blubrry.com/feeds/microsoftresearch.xml" target="_blank" rel="noreferrer noopener">
						<svg class="subscribe-to-podcast__svg" xmlns="http://www.w3.org/2000/svg" fill="none" viewBox="0 0 32 32"><path fill="currentColor" d="M6.667 4a2.676 2.676 0 00-2.612 2.13v.003c-.036.172-.055.35-.055.534v18.666c0 .183.019.362.055.534v.003a2.676 2.676 0 002.076 2.075h.002c.172.036.35.055.534.055h18.666A2.676 2.676 0 0028 25.333V6.667a2.676 2.676 0 00-2.13-2.612h-.003A2.623 2.623 0 0025.333 4H6.667zM8 8h1.333C17.42 8 24 14.58 24 22.667V24h-2.667v-1.333c0-6.618-5.382-12-12-12H8V8zm0 5.333h1.333c5.146 0 9.334 4.188 9.334 9.334V24H16v-1.333A6.674 6.674 0 009.333 16H8v-2.667zM10 20a2 2 0 11-.001 4.001A2 2 0 0110 20z"/></svg>
						<span class="subscribe-to-podcast__link-text">RSS Feed</span>
					</a>
				</li>
					</ul>
	</div>
</section>


<div class="wp-block-msr-show-more">
	<div class="bg-neutral-100 p-5">
		<div class="show-more-show-less" data-mount="show-more-show-less">
			<div>
				<span>
					

<h2 class="wp-block-heading" id="transcript">Transcript</h2>



<p>[TEASER]</p>



<p>[MUSIC PLAYS UNDER DIALOGUE]</p>



<p><strong>SHAN LU:</strong> I remember, you know, those older days myself, right. That is really, like, I have this struggle that I feel like I can do better. I feel like I have ideas to contribute. But just for whatever reason, right, it took me forever to learn something which I feel like it&#8217;s a very mechanical thing, but it just takes me forever to learn, right. And then now actually, I see this hope, right, with AI. You know, a lot of mechanical things that can actually now be done in a much more automated way, you know, by AI, right. So then now truly, you know, my daughter, many girls, many kids out there, right, whatever, you know, they are good at, their creativity, it&#8217;ll be much easier, right, for them to contribute their creativity to whatever discipline they are passionate about.</p>



<p>[TEASER ENDS]</p>



<p><strong>GRETCHEN HUIZINGA:</strong><strong> </strong>You’re listening to <em>Ideas</em>, a Microsoft Research Podcast that dives deep into the world of technology research and the profound questions behind the code. I&#8217;m Gretchen Huizinga. In this series, we&#8217;ll explore the technologies that are shaping our future and the big ideas that propel them forward.<strong></strong></p>



<p>[MUSIC FADES]</p>



<p>Today I&#8217;m talking to Shan Lu, a senior principal research manager at Microsoft Research and a computer science professor at the University of Chicago. Part of the Systems Research Group, Shan and her colleagues are working to make our computer systems, and I quote, “secure, scalable, fault tolerant, manageable, fast, and efficient.” That&#8217;s no small order, so I&#8217;m excited to explore the big ideas behind Shan&#8217;s influential research and find out more about her reputation as a bug bounty hunter. Shan Lu, welcome to <em>Ideas</em>!</p>



				</span>
				<span id="show-more-show-less-toggle-7" class="show-more-show-less-toggleable-content">
					



<p><strong>SHAN LU:</strong> Thank you.</p>



<p><strong>HUIZINGA:</strong> So I like to start these episodes with what I&#8217;ve been calling the “research origin story,” and you have a unique, almost counterintuitive, story about what got you started in the field of systems research. Would you share that story with our listeners?</p>



<p><strong>LU:</strong> Sure, sure. Yeah. I grew up fascinating that I will become mathematician. I think I was good at math, and at some point, actually, until, I think, I entered college, I was still, you know, thinking about, should I do math? Should I do computer science? For whatever reason, I think someone told me, you know, doing computer science will help you; it&#8217;s easier to get a job. And I reluctantly pick up computer science major. And then there was a few years in my college, I had a really difficult time for programming. And I also remember that there was, like, I spent a lot of time learning one language—we started with Pascal—and I feel like I finally know what to do and then there&#8217;s yet another language, C, and another class, <em>Java</em>. And I remember, like, the teacher will ask us to do a programming project, and there are times I don&#8217;t even, I just don&#8217;t know how to get started. And I remember, at that time, in my class, I think there were … we only had like four girls taking this class that requires programming in Java, and none of us have learned Java before. And when we ask our classmates, when we ask the boys, they just naturally know what to do. It was really, really humiliating. Embarrassing. I had the feeling that, I felt like I&#8217;m just not born to be a programmer. And then, I came to graduate school. I was thinking about, you know, what kind of research direction I should do. And I was thinking that, oh, maybe I should do <em>theory</em> research, like, you know, complexity theory or something. You know, after a lot of back and forth, I met my eventual adviser. She was a great, great mentor to me, and she told me that, hey, Shan, you know, my group is doing research about finding bugs in software. And she said her group is doing system research, and she said a lot of current team members are all great programmers, and as a result, they are not really well-motivated [LAUGHS] by finding bugs in software!</p>



<p><strong>HUIZINGA:</strong> Interesting.</p>



<p><strong>LU:</strong> And then she said, you are really motivated, right, by, you know, getting help to developers, to help developers finding bugs in their software, so maybe that&#8217;s the research project for you. So that&#8217;s how I got started.<s></s></p>



<p><strong>HUIZINGA:</strong> Well, let&#8217;s go a little bit further on this mentor and mentors in general. As Dr. Seuss might say, every “what” has a “who.” So by that I mean an inspirational person or people behind every successful researcher&#8217;s career. And most often, they&#8217;re kind of big names and meaningful relationships, but you have another unique story on who has influenced you in your career, so why don&#8217;t you tell us about the spectrum of people who&#8217;ve been influential in your life and your career?</p>



<p><strong>LU:</strong> Mm-hmm. Yeah, I mean, I think I mentioned my adviser, and she&#8217;s just so supportive. And I remember, when I started doing research, I just felt like I seemed to be so far behind everyone else. You know, I felt like, how come everybody else knows how to ask, you know, insightful questions? And they, like, they know how to program really fast, bug free. And my adviser really encouraged me, saying, you know, there are background knowledge that you can pick up; you just need to be patient. But then there are also, like, you know how to do research, you know how to think about things, problem solving. And she encouraged me saying, Shan, you&#8217;re good at that!</p>



<p><strong>HUIZINGA:</strong> Interesting!</p>



<p><strong>LU:</strong> Well, I don&#8217;t know how she found out, and anyway, so she was super, super helpful.</p>



<p><strong>HUIZINGA:</strong> OK, so go a little further on this because I know you have others that have influence you, as well.</p>



<p><strong>LU:</strong> Yes. Yes, yes. And I think those, to be honest, I&#8217;m a very emotional, sensitive person. I would just, you know, move the timeline to be, kind of, more recent. So I joined Microsoft Research as a manager, and there&#8217;s something called Connect that, you know, people write down twice every year talking about what it is they’ve been doing. So I was just checking, you know, my members in my team to see what they have been doing over the years just to just get myself familiar with them. And I remember I read several of them. I felt like I almost have tears in my eyes! Like, I realized, wow, like … And just to give example, for Chris, Chris Hawblitzel, I read his Connect, and I saw that he&#8217;s working on something called program verification. It&#8217;s a very, very difficult problem, and [as an] outsider, you know, I&#8217;ve read many of his papers, but when I read, you know, his own writing, and I realized, wow, you know, it&#8217;s almost two decades, right. Like, he just keeps doing these very difficult things. And I read his words about, you know, how his old approach has problems, how he’s thinking about how to address that problem. <em>Oh, I have an idea</em>, right. And then spend multiple years to implement that idea and get improvement; find a new problem and then just find new solutions. And I really feel like, wow, I&#8217;m really, really, like, I feel like this is, kind of, like a, you know, there&#8217;s, how to say, a <em>hero-ish</em> story behind this, you know, this kind of goal, and you&#8217;re willing to spend many years to keep tackling this challenging problem. And I just feel like, wow, I&#8217;m so honored, you know, to be in the same group with a group of fighters, you know, determined to tackle difficult research problems.</p>



<p><strong>HUIZINGA:</strong> Yeah. And I think when you talk about it, it&#8217;s like this is a person that was working <em>for you</em>, a direct report. [LAUGHTER] And often, we think about our heroes as being the ones who mentored us, who taught us, who managed us, but yours is kind of 360! It’s like …</p>



<p><strong>LU:</strong> True!</p>



<p><strong>HUIZINGA:</strong> … your heroes [are] above, beside and below.</p>



<p><strong>LU:</strong> Right. And I would just say that I have many other, you know, direct reports in my group, and I have, you know, for example, say a couple other … my colleagues, my direct reports, Dan Ports and Jacob Nelson. And again, this is something like their story really inspired me. Like, they were, again, spent five or six years on something, and it looks like, oh, it&#8217;s close to the success of tech transfer, and then something out of their control happened. It happened because Intel decided to stop manufacturing a chip that their research relied on. And it&#8217;s, kind of, like the end of the world to them, …</p>



<p><strong>HUIZINGA: </strong>Yeah.</p>



<p><strong>LU: </strong>… and then they did not give up. And then, you know, like, one year later, they found a solution, you know, together with their product team collaborators.</p>



<p><strong>HUIZINGA:</strong> Wow.</p>



<p><strong>LU:</strong> And I still feel like, wow, you know, I feel so … I feel like I&#8217;m inspired every day! Like, I&#8217;m so happy to be working together with, you know, all these great people, great researchers in my team.</p>



<p><strong>HUIZINGA:</strong> Yeah. Wow. So much of your work centers on this idea of concurrent systems and I want you to talk about some specific examples of this work next, but I think it warrants a little explication upfront for those people in the audience who don&#8217;t spend all their time working on concurrent systems themselves. So give us a short “101” on concurrent systems and explain why the work you do matters to both the people who make it and the people who use it.</p>



<p><strong>LU:</strong> Sure. Yeah. So I think a lot of people may not realize … so actually, the software we&#8217;re using every day, almost every software we use these days are concurrent. So the meaning of <em>concurrent</em> is that you have multiple threads of execution going on at the same time, in parallel. And then, when we go to a web browser, right, so it&#8217;s not just one rendering that is going on. There are actually multiple concurrent renderings that is going on. So the problem of writing … for software developers to develop this type of concurrent system, a challenge is the timing. So because you have multiple concurrent things going on, it&#8217;s very difficult to manage and reason about, you know, what may happen first, what may happen second. And also, it’s, like, there&#8217;s an inherent non-determinism in it. What happened first this time may happen second next time. So as a result, a lot of bugs are introduced by this. And it was a very challenging problem because I would say about 20 years ago, there was a shift. Like, in the older days, actually most of our software is written in a sequential way instead of a concurrent way. So, you know, a lot of developers also have a difficult time to shift their mindset from the sequential way of reasoning to this concurrent way of reasoning.</p>



<p><strong>HUIZINGA:</strong> Right. Well, and I think, from a user&#8217;s perspective, all you experience is what I like to call the <em>spinning beachball of doom</em>. It&#8217;s like I&#8217;ve asked something, and it doesn&#8217;t want to give, so [LAUGHS] &#8230; And this is, like, behind the scenes from a reasoning perspective of, how do we keep that from happening to our users? How do we identify the bugs? Which we&#8217;ll get to in a second. Umm. Thanks for that. Your research <em>now</em> revolves around what I would call the <em>big idea</em> of learning from mistakes. And in fact, it all seems to have started with a paper that you published way back in 2008 called “Learning from Mistakes: A Comprehensive Study on Real World Concurrency Bug Characteristics,” and you say this strongly influenced your research style and approach. And by the way, I&#8217;ll note that this paper received the Most Influential Paper Award in 2022 from ASPLOS, which is the Architectural Support for Programming Languages and Operating Systems. Huge mouthful. And it also has more than a thousand citations, so I dare say it&#8217;s influenced other researchers’ approach to research, as well. Talk about the big idea behind this paper and exactly <em>how</em> it informed your research style and approach today.</p>



<p><strong>LU:</strong> Mm-hmm. Yeah. So I think this, like, again, went back to the days that I, you know, my PhD days, I started working with my adviser, you know, YY (Yuanyuan Zhou). So at that time, there had been a lot of people working on bug finding, but then now when I think about it, people just magically say, hey, I want to look at <em>this</em> type of bug. Just magically, oh, I want to look at <em>that</em> type of bug. And then, my adviser at that time suggested to me, saying, hey, maybe, you know, actually take a look, right. At that time, as I mentioned, software was kind of shifting from sequential software to concurrent software, and my adviser was saying, hey, just take a look at those real systems bug databases, and see what type of concurrency bugs are actually there. You know, instead of just randomly saying, oh, I want to work on this type of bug.</p>



<p><strong>HUIZINGA:</strong> Oh, yeah.</p>



<p><strong>LU:</strong> And then also, of course, it&#8217;s not just look at it. It&#8217;s not just like you read a novel or something, right. [LAUGHTER] And again, my adviser said, hey, Shan, right, you have this, you have a connection, natural connection, you know, with bugs and the developers who commit …</p>



<p><strong>HUIZINGA:</strong> Who make them …</p>



<p><strong>LU:</strong> Who make them! [LAUGHTER] So she said, you know, try to think about the patterns behind them, right. Try to think about whether you can generalize some …</p>



<p><strong>HUIZINGA:</strong> Interesting …</p>



<p><strong>LU: </strong>… characteristics, and use that to guide people&#8217;s research in this domain. And at that time, we were actually thinking we don&#8217;t know whether, you know, we can actually write a paper about it because traditionally you publish a paper, just say, oh, I have a new tool, right, which can do <em>this</em> and <em>that</em>. At that time in system conferences, people rarely have, you know, just say, here&#8217;s a study, right. But we studied that, and indeed, you know, I had this thought that, hey, why <em>I </em>make a lot of mistakes. And when I study a lot of bugs, the more and more, I feel, you know, there&#8217;s a reason behind it, right. It&#8217;s like I&#8217;m not the only dumb person in the world, right? [LAUGHTER] There&#8217;s a reason that, you know, there&#8217;s some part of this language is difficult to use, right, and there&#8217;s a certain type of concurrent reasoning, it’s just not natural to many people, right. So because of that, there are patterns behind these bugs. And so at that time, we were surprised that the paper was actually accepted. Because I&#8217;m just happy with the learning I get. But after this paper was accepted, in the next, I would say, many years, there are more and more people realize, hey, before we actually, you know, do bug-finding things, let&#8217;s first do a study, right, to understand, and then this paper was … yeah … I was very happy that it was cited many, many times.</p>



<p><strong>HUIZINGA:</strong> Yeah. And then gets the most influential paper many years later.</p>



<p><strong>LU:</strong> Many years later. Yes.</p>



<p><strong>HUIZINGA:</strong> Yeah, I feel like there&#8217;s a lot of things going through my head right now, one of which is what AI is, is a pattern detector, and you were doing that before AI even came on the scene. Which goes to show you that humans are pretty good at pattern detection also. We might not do as fast as …</p>



<p><strong>LU:</strong> True.</p>



<p><strong>HUIZINGA:</strong> … as an AI but … so this idea of learning from mistakes is a broad theme. Another theme that I see coming through your papers and your work is persistence. [LAUGHTER] And you mentioned this about your team, right. I was like, these people are people who don&#8217;t give up. So we covered this idea in an <em>Abstracts</em> podcast recently talking about a paper which really brings this to light: “If at First You Don&#8217;t Succeed, Try, Try Again.” That&#8217;s the name of the paper. And we didn&#8217;t have time to discuss it in depth at the time because the <em>Abstracts</em> show is so quick. But we do now. So I&#8217;d like you to expand a little bit on this big idea of persistence and how large language models are not only changing the way programming and verification happens but also providing insights into detecting <em>retry</em> bugs.</p>



<p><strong>LU:</strong> Yes. So I guess maybe I will, since you mentioned this persistence, you know, after that “Learning from Mistakes” paper—so that was in 2008—and in the next 10 years, a little bit more than 10 years, in terms of persistence, right, so we have continued, me and my students, my collaborators, we have continued working on, you know, finding concurrency bugs …</p>



<p><strong>HUIZINGA:</strong> Yeah.</p>



<p><strong>LU:</strong> … which is related to, kind of related to, why I&#8217;m here at Microsoft Research. And we keep doing it, doing it, and then I feel like a high point was that I had a collaboration with my now colleagues here, Madan Musuvathi and Suman Nath. So we built a tool to detect concurrency bugs, and after more than 15 years of effort on this, we were able to find more than 1,000 concurrency bugs. It was built in a tool called Torch that was deployed in the company, and it won the Best Paper Award at the top system conference, SOSP, and it was actually a bittersweet moment. This paper seems to, you know, put an end …</p>



<p><strong>HUIZINGA:</strong> Oh, interesting!</p>



<p><strong>LU:</strong> … to our research. And also some of the findings from that paper is that we used to do very sophisticated program analysis to reason about the timing. And in that paper, we realized actually, sometimes, if you’re a little bit fuzzy, don&#8217;t aim to do perfect analysis, the resulting tool is actually more effective. So after that paper, Madan, Suman, and me, we kind of, you know, shifted our focus to looking at other types of bugs. And at the same time, the three of us realized the traditional, very precise program analysis may not be needed for some of the bug finding. So then, for this paper, this retry bugs, after we shifted our focus away from concurrency bugs, we realized, oh, there are many other types of important bugs, such as, in this case, like retry, right, when your software goes wrong, right. Another thing we learned is that it looks like you can never eliminate <em>all</em> bugs, so something will go wrong, [LAUGHTER] and then so that&#8217;s why you need something like retry, right. So like if something goes wrong, at least you won&#8217;t give up immediately.</p>



<p><strong>HUIZINGA:</strong> Right.</p>



<p><strong>LU:</strong> The software will <em>retry</em>. And another thing that started from this earlier effort is we started using large language models because we realized, yeah, you know, traditional program analysis sometimes can give you a very strong guarantee, but in some other cases, like in this retry case, some kind of fuzzy analysis, you know, not so precise, offered by large language models is sometimes even more beneficial. Yeah. So that&#8217;s kind of, you know, the story behind this paper.<strong><s></s></strong></p>



<p><strong>HUIZINGA:</strong> Yeah, yeah, yeah, yeah. So, Shan, we&#8217;re hearing a lot about how large language models are writing code nowadays. In fact, NVIDIA&#8217;s CEO says, mamas, don&#8217;t let your babies grow up to be coders because AI’s going to do that. I don&#8217;t know if he&#8217;s right, but one of the projects you&#8217;re most excited about right now is called Verus, and your colleague Jay Lorch recently said that he sees a lot of synergy between AI and verification, where each discipline brings something to the other, and Rafah Hosn has referred to this as “co-innovation” or “bidirectional enrichment.” I don&#8217;t know if that&#8217;s exactly what is going on here, but it seems like it is. Tell us more about this project, Verus, and how AI and software verification are helping each other out.</p>



<p><strong>LU:</strong> Yes, yes, yes, yes. I&#8217;m very excited about this project now! So first of all, starting from Verus. So Verus is a tool that helps you verify the correctness of Rust code. So this is a … it’s a relatively new tool, but it’s creating a lot of, you know, excitement in the research community, and it’s created by my colleague Chris Hawblitzel and his collaborators outside Microsoft Research.</p>



<p><strong>HUIZINGA:</strong> Interesting.</p>



<p><strong>LU:</strong> And as I mentioned, right, this is a part that, you know, really inspired me. So traditionally to verify, right, your program is correct, it requires a lot of expertise. You actually have to write your proof typically in a special language. And, you know, so a lot of people, including me, right, who are so eager to get rid of bugs in my software, but there are people told me, saying just to learn that language—so they were referring to a language called Coq—just to learn that language, they said it takes one or two years. And then once you learn that language, right, then you have to learn about how to write proofs in that special language. So people, particularly in the bug-finding community, people know that, oh, in theory, you can verify it, but in reality, people don&#8217;t do that. OK, so now going back to this Verus tool, why it&#8217;s exciting … so it actually allows people to write proofs in Rust. So Rust is an increasingly popular language. And there are more and more people picking up Rust. It’s the first time I heard about, oh, you can, you know, write proofs in a popular language. And also, another thing is in the past, you cannot verify an implementation directly. You can only verify something written in a special language. And the proof is proving something that is in a special language. And then finally, that special language is maybe then transformed into an implementation. So it&#8217;s just, there&#8217;s just too many special languages there.</p>



<p><strong>HUIZINGA:</strong> A lot of layers.</p>



<p><strong>LU:</strong> A lot of layers. So now this Verus tool allows you to write a proof in Rust to prove an implementation that is <em>in</em> Rust. So it&#8217;s very direct. I just feel like I&#8217;m just not good at learning a new language.</p>



<p><strong>HUIZINGA:</strong> Interesting.</p>



<p><strong>LU:</strong> So when I came here, you know, and learned about this Verus tool, you know, by Chris and his collaborators, I feel like, oh, looks like maybe I can give it a try. And surprisingly, I realized, oh, wow! I can actually write proofs using this Verus tool.</p>



<p><strong>HUIZINGA:</strong> Right.</p>



<p><strong>LU:</strong> And then, of course, you know, I was told, if you really want to, right, write proofs for large systems, it still takes a lot of effort. And then this idea came to me that, hey, maybe, you know, these days, like, large language models can write code, then why not let large language models write proofs, right? And of course, you know, other people actually had this idea, as well, but there&#8217;s a doubt that, you know, can large language models <em>really</em> write proofs, right? And also, people have this feeling that, you know, large language models seem not very disciplined, you know, by nature. But, you know, that&#8217;s what intrigued me, right. And also, I used to be a doubter for, say, GitHub Copilot. <em>USED</em> to! Because I feel like, yes, it can generate a lot of code, but who knows [LAUGHS] …</p>



<p><strong>HUIZINGA:</strong> Whether it&#8217;s right …</p>



<p><strong>LU:</strong> What, what is … whether it&#8217;s right?</p>



<p><strong>HUIZINGA:</strong> Yeah.</p>



<p><strong>LU:</strong> Right, so I feel like, wow, you know, this could be a game-changer, right? Like, if AI can write not only code but also proofs. Yeah, so that&#8217;s what I have been doing. I&#8217;ve been working on this for one year, and I gradually get more collaborators both, you know, people in Microsoft Research Asia, and, you know, expertise here, like Chris, and Jay Lorch. They all help me a lot. So we actually have made a lot of progress.</p>



<p><strong>HUIZINGA:</strong> Yeah.</p>



<p><strong>LU:</strong> Like, now it&#8217;s, like, we&#8217;ve tried, like, for example, for some small programs, benchmarks, and we see that actually large language models can correctly prove the majority of the benchmarks that we throw to it. Yeah. It&#8217;s very, very exciting.</p>



<p><strong>HUIZINGA:</strong> Well, and so … and we&#8217;re going to talk a little bit more about some of those doubts and some of those interesting concerns in a bit. I do want you to address what I think Jay was getting at, which is that somehow the two help each other. The verification improves the AI. The AI improves the verification.</p>



<p><strong>LU:</strong> Yes, yes.</p>



<p><strong>HUIZINGA:</strong> How?</p>



<p><strong>LU:</strong> Yes. My feeling is that a lot of people, if they&#8217;re concerned with using AI, it’s because they feel like there&#8217;s no guarantee for the content generated by AI, right. And then we also all heard about, you know, hallucination. And I tried myself. Like, I remember, at some point, if I ask AI, say, you know, which is bigger: is it three times three or eight? And the AI will tell me eight is bigger. And … [LAUGHTER]</p>



<p><strong>HUIZINGA:</strong> Like, <em>what</em>?</p>



<p><strong>LU:</strong> So I feel like verification can really help AI …</p>



<p><strong>HUIZINGA:</strong> Get better …</p>



<p><strong>LU:</strong> … because now you can give, you know, kind of, add in mathematical rigors into whatever that is generated by AI, right. And I say it would help AI. It will also help people who use AI, right, so that they know what can be trusted, right.</p>



<p><strong>HUIZINGA: </strong>Right.</p>



<p><strong>LU: </strong>What is guaranteed by this content generated by AI?</p>



<p><strong>HUIZINGA:</strong> Yeah, yeah, yeah.</p>



<p><strong>LU:</strong> Yeah, and now of course AI can help verification because, you know, verification, you know, it&#8217;s hard. There is a lot of mathematical reasoning behind it. [LAUGHS] And so now with AI, it will enable verification to be picked up by more and more developers so that we can get higher-quality software.</p>



<p><strong>HUIZINGA:</strong> Yeah.</p>



<p><strong>LU:</strong> Yeah.</p>



<p><strong>HUIZINGA:</strong> Yeah. And we&#8217;ll get to that, too, about what I would call the democratization of things. But before that, I want to, again, say an observation that I had based on your work and my conversations with you is that you&#8217;ve basically dedicated your career to hunting bugs.</p>



<p><strong>LU:</strong> Yes.</p>



<p><strong>HUIZINGA:</strong> And maybe that&#8217;s partly due to a personal story about how a tiny mistake became a bug that haunted you for years. Tell us the story.</p>



<p><strong>LU:</strong> Yes.</p>



<p><strong>HUIZINGA:</strong> And explain why and how it launched a lifelong quest to understand, detect, and expose bugs of all kinds.</p>



<p><strong>LU:</strong> Yes. So before I came here, I already had multiple times, you know, interacting with Microsoft Research. So I was a summer intern at Microsoft Research Redmond almost 20 years ago.</p>



<p><strong>HUIZINGA:</strong> Oh, wow!</p>



<p><strong>LU:</strong> I think it was in the summer of 2005. And I remember I came here, you know, full of ambition. And I thought, OK, you know, I will implement some smart algorithm. I will deliver some useful tools. So at that time, I had just finished two years of my PhD, so I, kind of, just started my research on bug finding and so on. And I remember I came here, and I was told that I need to program in C#. And, you know, I just naturally have a fear of learning a new language. But anyway, I remember, I thought, oh, the task I was assigned was very straightforward. And I think I went ahead of myself. I was thinking, oh, I want to quickly finish this, and I want to do something more novel, you know, that can be more creative. But then this simple task I was assigned, I ended up spending the whole summer on it. So the tool that I wrote was supposed to process very huge logs. And then the problem is my software is, like, you run it initially … So, like, I can only run it for 10 minutes because my software used so much memory and it will crash. And then, I spent a lot of time … I was thinking, oh, my software is just using too much memory. Let me optimize it, right. And then so, I, you know, I try to make sure to use memory in a very efficient way, but then as a result, instead of crashing every 10 minutes, it will just crash after one hour. And I know there&#8217;s a bug at that time. So there&#8217;s a type of bug called memory leak. I know there&#8217;s a bug in my code, and I spent a lot of time and there was an engineer helping me checking my code. We spent a lot of time. We were just not able to find that bug. And at the end, we … the solution is I was just sitting in front of my computer waiting for my program to crash and restart. [LAUGHTER] And at that time, because there was very little remote working option, so in order to finish processing all those logs, it&#8217;s like, you know, after dinner, I …</p>



<p><strong>HUIZINGA:</strong> You have to stay all night!</p>



<p><strong>LU:</strong> I have to stay all night! And all my intern friends, they were saying, oh, Shan, you work really hard! And I&#8217;m just feeling like, you know what I&#8217;m doing is just sitting in front of my computer waiting [LAUGHTER]&nbsp;for my program to crash so that I can restart it! And near the end of my internship, I finally find the bug. It turns out that I missed a pair of brackets in one line of code.</p>



<p><strong>HUIZINGA:</strong> That&#8217;s it.</p>



<p><strong>LU:</strong> That&#8217;s it.</p>



<p><strong>HUIZINGA:</strong> Oh, my goodness.</p>



<p><strong>LU:</strong> And it turns out, because I was used to C, and in C, when you want to free, which means deallocate, an array, you just say “free array.” And if I remember correctly, in this language, C#, you have to say, “free <em>this array name</em>” and you put a bracket behind it. Otherwise, it will only free the first element. And I … it was a nightmare. And I also felt like, the most frustrating thing is, if it&#8217;s a clever bug, right … [LAUGHS]</p>



<p><strong>HUIZINGA:</strong> Sure.</p>



<p><strong>LU:</strong> &#8230; then you feel like at least I&#8217;m defeated by something complicated …</p>



<p><strong>HUIZINGA:</strong> Smart.</p>



<p><strong>LU:</strong> Something smart. And then it&#8217;s like, you know, also all this ambition I had about, you know, doing creative work, right, with all these smart researchers in MSR (Microsoft Research), I feel like I ended up achieving very little in my summer internship.</p>



<p><strong>HUIZINGA:</strong> But maybe the humility of making a stupid mistake is the kind of thing that somebody who&#8217;s good at hunting bugs … It&#8217;s like missing an error in the headline of an article, because the print is so big [LAUGHTER] that you&#8217;re looking for the little things in the … I know that&#8217;s a journalist&#8217;s problem. Actually, I actually love that story. And it, kind of, presents a big picture of you, Shan, as a person who has a realistic, self-awareness of … and <em>humility</em>, which I think is rare at times in the software world. So thanks for sharing that. So moving on. When we talked before, you mentioned the large variety of programming languages and how that can be a barrier to entry or at least a big hurdle to overcome in software programming and verification. But you also talked about, as we just mentioned, how LLMs have been a democratizing force …</p>



<p><strong>LU:</strong> Yes.</p>



<p><strong>HUIZINGA: </strong>…<strong> </strong>in this field. So going back to when you first started …</p>



<p><strong>LU:</strong> Yes.</p>



<p><strong>HUIZINGA:</strong> … and what you see now with the advent of tools like GitHub Copilot, …</p>



<p><strong>LU:</strong> Yes.</p>



<p><strong>HUIZINGA:</strong> … what … what&#8217;s changed?</p>



<p><strong>LU:</strong> Oh, so much has changed. Well, I don&#8217;t even know how to start. Like, I used to be really scared about programming. You know, when I tell this story, a lot of people say, no, I don&#8217;t believe you. And I feel like it&#8217;s a trauma, you know.</p>



<p><strong>HUIZINGA:</strong> Sure.</p>



<p><strong>LU:</strong> I almost feel like it&#8217;s like, you know, the college-day <em>me</em>, right, who was scared of starting any programming project. Somehow, I felt humiliated when asking those very, I feel like, stupid questions to my classmates. It almost changed my personality! It’s like … for a long time, whenever someone introduced me to a new software tool, my first reaction is, uh, I probably will not be able to successfully even install it. Like whenever, you know, there&#8217;s a new language, my first reaction is, uh, no, I&#8217;m not good at it. And then, like, for example, this GitHub Copilot thing, actually, I did not try it until I joined Microsoft. And then I, actually, I haven&#8217;t programmed for a long time. And then I started collaborating with people in Microsoft Research Asia, and he writes programs in Python, right. And I have never written a single line of Python code before. And also, this Verus tool. It helps you to verify code in Rust, but I have never learned Rust before. So I thought, OK, maybe let me just try GitHub Copilot. And wow! You know, it&#8217;s like I realized, wow! Like … [LAUGHS]</p>



<p><strong>HUIZINGA:</strong> I can do this!</p>



<p><strong>LU:</strong> I can do this! And, of course, sometimes I feel like my colleagues may sometimes be surprised because on one hand it looks like I&#8217;m able to just finish, you know, write a Rust function. But on some other days, I ask very basic questions, [LAUGHTER] and I have those questions because, you know, the GitHub Copilot just helps me finish! [LAUGHS]</p>



<p><strong>HUIZINGA:</strong> Right.</p>



<p><strong>LU:</strong> You know, I’m just starting something to start it, and then it just helps me finish. And I wish, when I started my college, if at that time there was GitHub Copilot, I feel like, you know, my mindset towards programming and towards computer science might be different. So it does make me feel very positive, you know, about, you know, what future we have, you know, with AI, with computer science.</p>



<p><strong>HUIZINGA:</strong> OK, <em>usually,</em> I ask researchers at this time, what could possibly go wrong if you got everything right? And I was thinking about this question in a different way until just this minute. I want to ask you … what do you think that it means to have a tool that can do things <em>for you</em> that you don&#8217;t have to struggle with? And maybe, is there anything good about the struggle? Because you&#8217;re framing it as it sapped your confidence.</p>



<p><strong>LU:</strong> [LAUGHS] Yes.</p>



<p><strong>HUIZINGA:</strong> And at the same time, I see a woman who emerged stronger because of this struggle with an amazing career, a huge list of publications, influential papers, citations, leadership role. [LAUGHTER] So in light of that …</p>



<p><strong>LU:</strong> Right.</p>



<p><strong>HUIZINGA:</strong> … what do you see as the tension between struggling to learn a new language versus having this tool that can just do it that makes you look amazing? And maybe the truth of it is you <em>don&#8217;t</em> know!</p>



<p><strong>LU:</strong> Yeah. That&#8217;s a very good point. I guess you need some kind of balance. And on one hand, yes, I feel like, again, right, this goes back to like my internship. I left with the frustration that I felt like I have so much creativity to contribute, and yet I could not because of this language barrier. You know, I feel positive in the sense that just from GitHub Copilot, right, how it has enabled me to just bravely try something new. I feel like this goes beyond just computer science, right. I can imagine it&#8217;ll help people to truly unleash their creativity, not being bothered by some challenges in learning the tool. But on the other hand, you made a very good point. My adviser told me she feels like, you know, I write code slowly, but I tend to make fewer mistakes. And the difficulty of learning, right, and all these nightmares I had definitely made me more … more cautious? I pay more respect to the task that is given to me, so there is definitely the other side of AI, right, which is, you feel like everything is easy and maybe you do not have the experience of those bugs, right, that a software can bring to you and you have overreliance, right, on this tool.</p>



<p><strong>HUIZINGA: </strong>Yeah!</p>



<p><strong>LU: </strong>So hopefully, you know, some of the things we we&#8217;re doing now, right, like for example, say verification, right, like bringing this mathematical rigor to AI, hopefully that can help.</p>



<p><strong>HUIZINGA:</strong> Yeah. You know, even as you unpack the nuances there, it strikes me that both are good. Both having to struggle and learning languages and understanding …</p>



<p><strong>LU:</strong> Yeah.</p>



<p><strong>HUIZINGA:</strong> … the core of it <em>and</em> the idea that in natural language, you could just say, here&#8217;s what I want to happen, and the AI does the code, the verification, etc. That said, do we trust it? And this was where I was going with the first “what could possibly go wrong?” question. How do we know that it is really as clever as it appears to be? [LAUGHS]</p>



<p><strong>LU:</strong> Yeah, I think I would just use the research problem we are working on now, right. Like, I think on one hand, I can use AI to generate a proof, right, to prove the code generated by AI is correct. But having said that, even if we&#8217;re wildly successful, you know, in this thing, human beings’ expertise is still needed because just take this as an example. What do you mean by “correct,” right?</p>



<p><strong>HUIZINGA:</strong> Sure.</p>



<p><strong>LU:</strong> And so someone first has to define what correctness means. And then so far, the experience shows that you can&#8217;t just define it using natural language because our natural language is inherently imprecise.</p>



<p><strong>HUIZINGA:</strong> Sure.</p>



<p><strong>LU:</strong> So you still need to translate it to a formal specification in a programming language. It could be in a popular language like in Rust, right, which is what Verus is aiming at. And then we are, like, for example, some of the research we do is showing that, yes, you know, I can also use AI to do this translation from natural language to specification. But again, then, who to verify <em>that</em>, right? So at the end of the day, I think we still do need to have humans in the loop. But what we can do is to lower the burden and make the interface not so complicated, right. So that it&#8217;ll be easy for human beings to check what AI has been doing.</p>



<p><strong>HUIZINGA:</strong> Yeah. You know, everything we&#8217;re talking about just reinforces this idea that we&#8217;re living in a time where the advances in computer science that seemed unrealistic or impossible, unattainable even a few years ago are now so common that we take it for granted. And they don&#8217;t even seem outrageous, but they are. So I&#8217;m interested to know what, if anything, you would classify now as “blue sky” research in your field. Maybe something in systems research today that looks like a moonshot. You&#8217;ve actually anchored this in the fact that you, kind of, have, you know, blinders on for the work you&#8217;re doing—head down in the in the work you&#8217;re doing—but even as you peek up from the work that might be outrageous, is there anything else? I just like to get this out there that, you know, what&#8217;s going on 10 years down the line?</p>



<p><strong>LU:</strong> You know, sometimes I feel like I&#8217;m just now so much into my own work, but, you know, occasionally, like, say, when I had a chat with my daughter and I explained to her, you know, oh, I&#8217;m working on, you know, not only having AI to generate code but also having AI to prove, right, the code is correct. And she would feel, wow, that sounds amazing! [LAUGHS] So I don&#8217;t know whether that is, you know, a moonshot thing, but that&#8217;s a thing that I&#8217;m super excited about …</p>



<p><strong>HUIZINGA:</strong> Yeah.</p>



<p><strong>LU:</strong> … about the potential. And then there also have, you know, my colleagues, we spend a lot of time building systems, and it&#8217;s not just about correctness, right. Like, the verification thing I&#8217;m doing now is related to automatically verify it’s correct. But also, you need to do a lot of performance tuning, right. Just so that your system can react fast, right. It can have good utilization of computer resources. And my colleagues are also working on using AI, right, to automatically do performance tuning. And I know what they are doing, so I don&#8217;t particularly feel that&#8217;s a <em>moonshot</em>, but I guess …</p>



<p><strong>HUIZINGA:</strong> I feel like, because you are so immersed, [LAUGHTER] that you just don&#8217;t see how much <em>we</em> think …</p>



<p><strong>LU:</strong> Yeah!</p>



<p><strong>HUIZINGA:</strong> … it&#8217;s amazing. Well, I&#8217;m just delighted to talk to you today, Shan. As we close … and you&#8217;ve sort of just done a little vision casting, but let&#8217;s take your daughter, my daughter,&nbsp;[LAUGHTER] all of our daughters …</p>



<p><strong>LU:</strong> Yes!</p>



<p><strong>HUIZINGA:</strong> How does what we believe about the future in terms of these things that we could accomplish influence the work we do today as sort of a vision casting for the next “Shan Lu” who&#8217;s struggling in undergrad/grad school?</p>



<p><strong>LU:</strong> Yes, yes, yes. Oh, thank you for asking that question. Yeah, I have to say, you know, I think we&#8217;re in a very interesting time, right, with all this AI thing.</p>



<p><strong>HUIZINGA:</strong> Isn’t that a curse in China? “May you live in interesting times!”</p>



<p><strong>LU:</strong> And I think there were times, actually, you know, before I myself fully embraced AI, I was … indeed I had my daughter in mind. I was worried when she grows up, what would happen? There will be no job for her because everything will be done by AI!</p>



<p><strong>HUIZINGA:</strong> Oh, interesting.</p>



<p><strong>LU:</strong> But then now, now that I have, you know, kind of fully embraced AI myself, actually, I see this more and more positive. Like you said, I remember, you know, those older days myself, right. That is really, like, I have this struggle that I feel like I can do better. I feel like I have ideas to contribute, but just for whatever reason, right, it took me forever to learn something which I feel like it&#8217;s a very mechanical thing, but it just takes me forever to learn, right. And then now actually, I see this hope, right, with AI, you know, a lot of mechanical things that can actually now be done in a much more automated way by AI, right. So then now truly, you know, my daughter, many girls, many kids out there, right, whatever you know, they are good at, their creativity, it&#8217;ll be much easier, right, for them to contribute their creativity to whatever discipline they are passionate about. Hopefully, they don&#8217;t have to, you know, go through what I went through, right, to finally be able to contribute. But then, of course, you know, at the same time, I do feel this responsibility of me, my colleagues, MSR, we have the capability and also the responsibility, right, of building AI tools in a responsible way so that it will be used in a positive way by the next generation.</p>



<p><strong>HUIZINGA:</strong> Yeah. Shan Lu, thank you so much for coming on the show today. [MUSIC] It&#8217;s been absolutely delightful, instructive, informative, wonderful.</p>



<p><strong>LU:</strong> Thank you. My pleasure.</p>

				</span>
			</div>
			<button
				class="action-trigger glyph-prepend mt-2 mb-0 show-more-show-less-toggle"
				aria-expanded="false"
				data-show-less-text="Show less"
				type="button"
				aria-controls="show-more-show-less-toggle-7"
				aria-label="Show more content"
				data-alternate-aria-label="Show less content">
				Show more			</button>
		</div>
	</div>
</div>
<span id="label-external-link" class="sr-only" aria-hidden="true">Opens in a new tab</span><p>The post <a href="https://www.microsoft.com/en-us/research/podcast/ideas-bug-hunting-with-shan-lu/">Ideas: Bug hunting with Shan Lu</a> appeared first on <a href="https://www.microsoft.com/en-us/research">Microsoft Research</a>.</p>
]]></content:encoded>
					
		
		
			</item>
		<item>
		<title>Research Focus: Week of January 13, 2025</title>
		<link>https://www.microsoft.com/en-us/research/blog/research-focus-week-of-january-13-2025/</link>
		
		<dc:creator><![CDATA[Brenda Potts]]></dc:creator>
		<pubDate>Fri, 17 Jan 2025 17:37:58 +0000</pubDate>
				<category><![CDATA[Research Blog]]></category>
		<guid isPermaLink="false">https://www.microsoft.com/en-us/research/?p=1116780</guid>

					<description><![CDATA[<p>In this edition: Privacy enhancements for multiparty deep learning; using smaller, open-source models to provide relevance judgments; new tool uses AI, data to automate innovation and development; Yasuyuki Matsushita named IEEE 2025 Computer Society Fellow.</p>
<p>The post <a href="https://www.microsoft.com/en-us/research/blog/research-focus-week-of-january-13-2025/">Research Focus: Week of January 13, 2025</a> appeared first on <a href="https://www.microsoft.com/en-us/research">Microsoft Research</a>.</p>
]]></description>
										<content:encoded><![CDATA[
<p class="has-text-align-center"><strong>In this edition:</strong></p>



<ul class="wp-block-list">
<li>We introduce privacy enhancements for multiparty deep learning, a framework using smaller, open-source models to provide relevance judgments, and other notable new research.</li>



<li>We congratulate Yasuyuki Matsushita, who was named an IEEE Computer Society Fellow.</li>



<li>We’ve included a recap of the extraordinary, far-reaching work done by researchers at Microsoft in 2024.&nbsp;&nbsp;</li>
</ul>



<figure class="wp-block-image aligncenter size-full"><img loading="lazy" decoding="async" width="1400" height="788" src="https://www.microsoft.com/en-us/research/uploads/prod/2025/01/NEW_RF56-BlogHeroFeature-1400x788-1.jpg" alt="Decorative graphic with wavy shapes in the background in blues and purples. Text overlay in center left reads: “Research Focus: January 17, 2024”" class="wp-image-1122399" srcset="https://www.microsoft.com/en-us/research/uploads/prod/2025/01/NEW_RF56-BlogHeroFeature-1400x788-1.jpg 1400w, https://www.microsoft.com/en-us/research/uploads/prod/2025/01/NEW_RF56-BlogHeroFeature-1400x788-1-300x169.jpg 300w, https://www.microsoft.com/en-us/research/uploads/prod/2025/01/NEW_RF56-BlogHeroFeature-1400x788-1-1024x576.jpg 1024w, https://www.microsoft.com/en-us/research/uploads/prod/2025/01/NEW_RF56-BlogHeroFeature-1400x788-1-768x432.jpg 768w, https://www.microsoft.com/en-us/research/uploads/prod/2025/01/NEW_RF56-BlogHeroFeature-1400x788-1-1066x600.jpg 1066w, https://www.microsoft.com/en-us/research/uploads/prod/2025/01/NEW_RF56-BlogHeroFeature-1400x788-1-655x368.jpg 655w, https://www.microsoft.com/en-us/research/uploads/prod/2025/01/NEW_RF56-BlogHeroFeature-1400x788-1-240x135.jpg 240w, https://www.microsoft.com/en-us/research/uploads/prod/2025/01/NEW_RF56-BlogHeroFeature-1400x788-1-640x360.jpg 640w, https://www.microsoft.com/en-us/research/uploads/prod/2025/01/NEW_RF56-BlogHeroFeature-1400x788-1-960x540.jpg 960w, https://www.microsoft.com/en-us/research/uploads/prod/2025/01/NEW_RF56-BlogHeroFeature-1400x788-1-1280x720.jpg 1280w" sizes="auto, (max-width: 1400px) 100vw, 1400px" /></figure>



<div class="wp-block-group is-layout-constrained wp-block-group-is-layout-constrained">
<p class="has-blue-color has-text-color has-link-color wp-elements-8d9d7d4143e56f533f8c36e4237c1c8d">NEW RESEARCH</p>



<h3 class="wp-block-heading h2" id="ai-meets-materials-discovery">AI meets materials discovery</h3>



<p>Two of the transformative tools that play a central role in Microsoft’s work on AI for science are MatterGen and MatterSim. In the world of materials discovery, each plays a distinct yet complementary role in reshaping how researchers design and validate new materials.</p>



<div class="wp-block-buttons is-content-justification-center is-content-justification-center is-layout-flex wp-container-core-buttons-is-layout-6 wp-block-buttons-is-layout-flex">
<div class="wp-block-button"><a data-bi-type="button" class="wp-block-button__link wp-element-button" href="https://www.microsoft.com/en-us/research/story/ai-meets-materials-discovery/">Read the story</a></div>
</div>



<hr class="wp-block-separator has-alpha-channel-opacity is-style-dots"/>



<h2 class="wp-block-heading h6 has-blue-color has-text-color has-link-color wp-elements-e734c6e9609233ab051742bb3beeed63" id="new-research">NEW RESEARCH</h2>



<h3 class="wp-block-heading h2" id="heading">Communication Efficient Secure and Private Multi-Party Deep Learning</h3>



<p>Distributed training enables multiple parties to jointly train a machine learning model on their respective datasets, which can help address the challenges posed by requirements in modern machine learning for large volumes of diverse data. However, this can raise security and privacy issues – protecting each party’s data <em>during</em> training and preventing leakage of private information from the model <em>after</em> training through various inference attacks.&nbsp;&nbsp;</p>



<p>In a recent paper, <a href="https://www.microsoft.com/en-us/research/publication/communication-efficient-secure-and-private-multi-party-deep-learning/" target="_blank" rel="noreferrer noopener">Communication Efficient Secure and Private Multi-Party Deep Learning</a>, researchers from Microsoft address these concerns simultaneously by designing efficient Differentially Private, secure Multiparty Computation (DP-MPC) protocols for jointly training a model on data distributed among multiple parties. This DP-MPC protocol in the two-party setting is 56-to-794 times more communication-efficient and 16-to-182 times faster than previous such protocols. This work simplifies and improves on previous attempts to combine techniques from secure multiparty computation and differential privacy, especially in the context of training machine learning models.&nbsp;</p>



<div class="wp-block-buttons is-content-justification-center is-content-justification-center is-layout-flex wp-container-core-buttons-is-layout-7 wp-block-buttons-is-layout-flex">
<div class="wp-block-button is-style-outline is-style-outline--8"><a data-bi-type="button" class="wp-block-button__link wp-element-button" href="https://www.microsoft.com/en-us/research/publication/communication-efficient-secure-and-private-multi-party-deep-learning/">Read the paper</a></div>
</div>



<hr class="wp-block-separator has-alpha-channel-opacity is-style-dots"/>
</div>



<div class="wp-block-group is-layout-constrained wp-block-group-is-layout-constrained">
<h2 class="wp-block-heading h6 has-blue-color has-text-color has-link-color wp-elements-e734c6e9609233ab051742bb3beeed63" id="new-research">NEW RESEARCH</h2>



<h3 class="wp-block-heading h2" id="heading">JudgeBlender: Ensembling Judgments for Automatic Relevance Assessment</h3>



<p>Training and evaluating retrieval systems requires significant relevance judgments, which are traditionally collected from human assessors. This process is both costly and time-consuming. Large language models (LLMs) have shown promise in generating relevance labels for search tasks, offering a potential alternative to manual assessments. Current approaches often rely on a single LLM. While effective, this approach can be expensive and prone to intra-model biases that can favor systems leveraging similar models.</p>



<p>In a recent paper: <a href="https://www.microsoft.com/en-us/research/publication/judgeblender-ensembling-judgments-for-automatic-relevance-assessment/">JudgeBlender: Ensembling Judgments for Automatic Relevance Assessment</a>, researchers from Microsoft we introduce a framework that employs smaller, open-source models to provide relevance judgments by combining evaluations across multiple LLMs (LLMBlender) or multiple prompts (PromptBlender). By leveraging the LLMJudge benchmark, they compare JudgeBlender with state-of-the-art methods and the top performers in the LLMJudge challenge. This research shows that JudgeBlender achieves competitive performance, demonstrating that very large models are often unnecessary for reliable relevance assessments.</p>



<div class="wp-block-buttons is-content-justification-center is-content-justification-center is-layout-flex wp-container-core-buttons-is-layout-8 wp-block-buttons-is-layout-flex">
<div class="wp-block-button is-style-outline is-style-outline--9"><a data-bi-type="button" class="wp-block-button__link wp-element-button" href="https://www.microsoft.com/en-us/research/publication/judgeblender-ensembling-judgments-for-automatic-relevance-assessment/">Read the paper</a></div>
</div>



<hr class="wp-block-separator has-alpha-channel-opacity is-style-dots"/>
</div>



<div class="wp-block-group is-layout-constrained wp-block-group-is-layout-constrained">
<h2 class="wp-block-heading h6 has-blue-color has-text-color has-link-color wp-elements-e734c6e9609233ab051742bb3beeed63" id="new-research">NEW RESEARCH</h2>



<h3 class="wp-block-heading h2" id="heading">Convergence to Equilibrium of No-regret Dynamics in Congestion Games</h3>



<p>Congestion games are used to describe the behavior of agents who share a set of resources. Each player chooses a combination of resources, which may become congested, decreasing utility for the players who choose them. Players can avoid congestion by choosing combinations that are less popular. This is useful for modeling a range of real-world scenarios, such as traffic flow, data routing, and wireless communication networks.</p>



<p>In a recent paper: <a href="https://www.microsoft.com/en-us/research/publication/convergence-to-equilibrium-of-no-regret-dynamics-in-congestion-games/">Convergence to Equilibrium of No-regret Dynamics in Congestion Games</a>; researchers from Microsoft and external colleagues propose CongestEXP, a decentralized algorithm based on the classic exponential weights method. They evaluate CongestEXP in a traffic congestion game setting. As more drivers use a particular route, congestion increases, leading to higher travel times and lower utility. Players can choose a different route every day to optimize their utility, but the observed utility by each player may be subject to randomness due to uncertainty (e.g., bad weather). The researchers show that this approach provides both regret guarantees and convergence to Nash Equilibrium, where no player can unilaterally improve their outcome by changing their strategy.</p>



<div class="wp-block-buttons is-content-justification-center is-content-justification-center is-layout-flex wp-container-core-buttons-is-layout-9 wp-block-buttons-is-layout-flex">
<div class="wp-block-button is-style-outline is-style-outline--10"><a data-bi-type="button" class="wp-block-button__link wp-element-button" href="https://www.microsoft.com/en-us/research/publication/convergence-to-equilibrium-of-no-regret-dynamics-in-congestion-games/">Read the paper</a></div>
</div>



<hr class="wp-block-separator has-alpha-channel-opacity is-style-dots"/>
</div>



<div class="wp-block-group is-layout-constrained wp-block-group-is-layout-constrained">
<h2 class="wp-block-heading h6 has-blue-color has-text-color has-link-color wp-elements-e734c6e9609233ab051742bb3beeed63" id="new-research">NEW RESEARCH</h2>



<h3 class="wp-block-heading h2" id="heading">RD-Agent: An open-source solution for smarter R&D</h3>



<p>Research and development (R&D) plays a pivotal role in boosting industrial productivity. However, the rapid advance of AI has exposed the limitations of traditional R&D automation. Current methods often lack the intelligence needed to support innovative research and complex development tasks, underperforming human experts with deep knowledge.</p>



<p>LLMs trained on vast datasets spanning many subjects are equipped with extensive knowledge and reasoning capabilities that support complex decision-making in diverse workflows. By autonomously performing tasks and analyzing data, LLMs can significantly increase the efficiency and precision of R&D processes.</p>



<p>In a <a href="https://www.microsoft.com/en-us/research/articles/rd-agent-an-open-source-solution-for-smarter-rd/">recent article</a>, researchers from Microsoft introduce RD-Agent, a tool that integrates data-driven R&D systems and harnesses advanced AI to automate innovation and development.</p>



<p>At the heart of RD-Agent is an autonomous agent framework with two key components: a) Research and b) Development. Research focuses on actively exploring and generating new ideas, while Development implements these ideas. Both components improve through an iterative process, illustrated in Figure 1 of the article, ensures the system becomes increasingly effective over time.</p>



<div class="wp-block-buttons is-content-justification-center is-content-justification-center is-layout-flex wp-container-core-buttons-is-layout-10 wp-block-buttons-is-layout-flex">
<div class="wp-block-button is-style-outline is-style-outline--11"><a data-bi-type="button" class="wp-block-button__link wp-element-button" href="https://www.microsoft.com/en-us/research/articles/rd-agent-an-open-source-solution-for-smarter-rd/">Read the article</a></div>
</div>
</div>



	<div class="border-bottom border-top border-gray-300 mt-5 mb-5 msr-promo text-center text-md-left alignwide" data-bi-aN="promo" data-bi-id="1044939">
		

		<p class="msr-promo__label text-gray-800 text-center text-uppercase">
		<span class="px-4 bg-white display-inline-block font-weight-semibold small">on-demand event</span>
	</p>
	
	<div class="row pt-3 pb-4 align-items-center">
						<div class="msr-promo__media col-12 col-md-5">
				<a class="bg-gray-300" href="https://www.microsoft.com/en-us/research/story/sep-2024-brief/?OCID=msr_researchforum_MCR_Blog_Promo" aria-label="Microsoft Research Forum Episode 4" data-bi-cN="Microsoft Research Forum Episode 4" target="_blank">
					<img decoding="async" class="w-100 display-block" src="https://www.microsoft.com/en-us/research/uploads/prod/2024/08/RF4_Panel_1400x788.jpg" alt="Research Forum | Episode 4 Panel | John Langford, Hoifung Poon, Katja Hofmann, Jianwei Yang" />
				</a>
			</div>
			
			<div class="msr-promo__content p-3 px-5 col-12 col-md">

									<h2 class="h4">Microsoft Research Forum Episode 4</h2>
				
								<p class="large">Learn about the latest multimodal AI models, advanced benchmarks for AI evaluation and model self-improvement, and an entirely new kind of computer for AI inference and hard optimization. </p>
				
								<div class="wp-block-buttons justify-content-center justify-content-md-start">
					<div class="wp-block-button">
						<a href="https://www.microsoft.com/en-us/research/story/sep-2024-brief/?OCID=msr_researchforum_MCR_Blog_Promo" class="btn btn-brand glyph-append glyph-append-chevron-right" aria-label="Watch on-demand" data-bi-cN="Microsoft Research Forum Episode 4" target="_blank">
							Watch on-demand						</a>
					</div>
				</div>
							</div><!--/.msr-promo__content-->
	</div><!--/.msr-promo__inner-wrap-->
<span id="label-external-link" class="sr-only" aria-hidden="true">Opens in a new tab</span>	</div><!--/.msr-promo-->
	


<div style="padding-bottom:64px; padding-top:64px" class="wp-block-msr-immersive-section alignfull row wp-block-msr-immersive-section">
	
	<div class="container">
		<div class="wp-block-msr-immersive-section__inner">
			<div class="wp-block-msr-cards msr-cards msr-cards--default mt-4 has-text-align-left" data-bi-aN="microsoft-research-in-case-you-missed-it">
	<div class="msr-cards__inner">
					<div class="heading-wrapper">
				<h2 class="mb-5 ">Microsoft Research | In case you missed it</h2>
			</div>
		
		<div class="row row-cols-1 row-cols-sm-2 row-cols-lg-3">
	<div class="msr-cards__card msr-cards__card--default col">
	<div class="card has-spectrum-border-top__hover material-card h-100 p-0" data-mount="click-group">

		
		<div class="card-body bg-white p-4 pt-3">
							<h3 class="h5">
					<a
						class="text-decoration-none text-black"
						data-bi-cN="Microsoft Research 2024: A year in review"
						href="https://www.microsoft.com/en-us/research/story/microsoft-research-2024-a-year-in-review/"
					>
						<span>Microsoft Research 2024: A year in review</span>&nbsp;<span class="glyph-prepend glyph-prepend-small glyph-prepend-chevron-right" aria-hidden="true"></span>
					</a>
				</h3>
										<div class="card__description card__citation small">
					<p>December 20, 2024</p><p>Microsoft Research did extraordinary work this year, using AI and scientific research to make progress on real-world challenges like climate change, food security, global health, and human trafficking. Here’s a look back at the broad range of accomplishments and advances in 2024.</p>				</div>
			
					</div>
	</div>
</div>
<div class="msr-cards__card msr-cards__card--default col">
	<div class="card has-spectrum-border-top__hover material-card h-100 p-0" data-mount="click-group">

		
		<div class="card-body bg-white p-4 pt-3">
							<h3 class="h5">
					<a
						class="text-decoration-none text-black"
						data-bi-cN="AIOpsLab: Building AI agents for autonomous clouds"
						href="https://www.microsoft.com/en-us/research/blog/aiopslab-building-ai-agents-for-autonomous-clouds/"
					>
						<span>AIOpsLab: Building AI agents for autonomous clouds</span>&nbsp;<span class="glyph-prepend glyph-prepend-small glyph-prepend-chevron-right" aria-hidden="true"></span>
					</a>
				</h3>
										<div class="card__description card__citation small">
					<p>December 20, 2024</p><p>AIOpsLab is a holistic evaluation framework for researchers and developers, to enable the design, development, evaluation, and enhancement of AIOps agents, which also serves the purpose of reproducible, standardized, interoperable, and scalable benchmarks.</p>				</div>
			
					</div>
	</div>
</div>
<div class="msr-cards__card msr-cards__card--default col">
	<div class="card has-spectrum-border-top__hover material-card h-100 p-0" data-mount="click-group">

		
		<div class="card-body bg-white p-4 pt-3">
							<h3 class="h5">
					<a
						class="text-decoration-none text-black"
						data-bi-cN="Yasuyuki Matsushita, IEEE Computer Society 2025 Fellow"
						href="https://www.computer.org/press-room/2025-class-fellows"
					>
						<span>Yasuyuki Matsushita, IEEE Computer Society 2025 Fellow</span>&nbsp;<span class="glyph-prepend glyph-prepend-small glyph-prepend-chevron-right" aria-hidden="true"></span>
					</a>
				</h3>
										<div class="card__description card__citation small">
					<p>December 19, 2024</p><p>Congratulations to Yasuyuki Matsushita, Senior Principal Research Manager at Microsoft Research, who was named a 2025 IEEE Computer Society Fellow. Matsushita was recognized for contributions to photometric 3D modeling and computational photography.</p>				</div>
			
					</div>
	</div>
</div>
</div>

					<div class="justify-content-center text-center mb-4">
				<a
					href="https://www.microsoft.com/en-us/research/news-and-awards/"
					class="btn btn-outline-primary glyph-append glyph-append-small glyph-append-chevron-right msr-cards__cta"
					data-bi-cN="View more news and awards"
					data-bi-type="button"
				>
					View more news and awards				</a>
			</div>
			</div>
</div>		</div>
	</div>

	</div>
<span id="label-external-link" class="sr-only" aria-hidden="true">Opens in a new tab</span><p>The post <a href="https://www.microsoft.com/en-us/research/blog/research-focus-week-of-january-13-2025/">Research Focus: Week of January 13, 2025</a> appeared first on <a href="https://www.microsoft.com/en-us/research">Microsoft Research</a>.</p>
]]></content:encoded>
					
		
		
			</item>
		<item>
		<title>Ideas: AI for materials discovery with Tian Xie and Ziheng Lu</title>
		<link>https://www.microsoft.com/en-us/research/podcast/ideas-ai-for-materials-discovery-with-tian-xie-and-ziheng-lu/</link>
		
		<dc:creator><![CDATA[Brenda Potts]]></dc:creator>
		<pubDate>Thu, 16 Jan 2025 10:12:46 +0000</pubDate>
				<category><![CDATA[Microsoft Research Podcast]]></category>
		<guid isPermaLink="false">https://www.microsoft.com/en-us/research/?p=1120956</guid>

					<description><![CDATA[<p>How do you generate and test materials that don’t exist yet? Researchers Tian Xie and Ziheng Lu share the story behind MatterGen and MatterSim, AI tools poised to transform materials discovery and help drive advances in energy, manufacturing, and sustainability.</p>
<p>The post <a href="https://www.microsoft.com/en-us/research/podcast/ideas-ai-for-materials-discovery-with-tian-xie-and-ziheng-lu/">Ideas: AI for materials discovery with Tian Xie and Ziheng Lu</a> appeared first on <a href="https://www.microsoft.com/en-us/research">Microsoft Research</a>.</p>
]]></description>
										<content:encoded><![CDATA[
<figure class="wp-block-image size-full"><img loading="lazy" decoding="async" width="1400" height="788" src="https://www.microsoft.com/en-us/research/uploads/prod/2025/01/Tian-Ziheng_Abstracts_Hero_Feature_No_Text_1400x788.jpg" alt="Ideas podcast | illustration of Tian Xie and Ziheng Lu" class="wp-image-1120947" srcset="https://www.microsoft.com/en-us/research/uploads/prod/2025/01/Tian-Ziheng_Abstracts_Hero_Feature_No_Text_1400x788.jpg 1400w, https://www.microsoft.com/en-us/research/uploads/prod/2025/01/Tian-Ziheng_Abstracts_Hero_Feature_No_Text_1400x788-300x169.jpg 300w, https://www.microsoft.com/en-us/research/uploads/prod/2025/01/Tian-Ziheng_Abstracts_Hero_Feature_No_Text_1400x788-1024x576.jpg 1024w, https://www.microsoft.com/en-us/research/uploads/prod/2025/01/Tian-Ziheng_Abstracts_Hero_Feature_No_Text_1400x788-768x432.jpg 768w, https://www.microsoft.com/en-us/research/uploads/prod/2025/01/Tian-Ziheng_Abstracts_Hero_Feature_No_Text_1400x788-1066x600.jpg 1066w, https://www.microsoft.com/en-us/research/uploads/prod/2025/01/Tian-Ziheng_Abstracts_Hero_Feature_No_Text_1400x788-655x368.jpg 655w, https://www.microsoft.com/en-us/research/uploads/prod/2025/01/Tian-Ziheng_Abstracts_Hero_Feature_No_Text_1400x788-240x135.jpg 240w, https://www.microsoft.com/en-us/research/uploads/prod/2025/01/Tian-Ziheng_Abstracts_Hero_Feature_No_Text_1400x788-640x360.jpg 640w, https://www.microsoft.com/en-us/research/uploads/prod/2025/01/Tian-Ziheng_Abstracts_Hero_Feature_No_Text_1400x788-960x540.jpg 960w, https://www.microsoft.com/en-us/research/uploads/prod/2025/01/Tian-Ziheng_Abstracts_Hero_Feature_No_Text_1400x788-1280x720.jpg 1280w" sizes="auto, (max-width: 1400px) 100vw, 1400px" /></figure>


<div class="wp-block-msr-podcast-container my-4">
	<iframe loading="lazy" src="https://player.blubrry.com/?podcast_id=141011047&modern=1" class="podcast-player" frameborder="0" height="164px" width="100%" scrolling="no" title="Podcast Player"></iframe>
</div>



<p>Behind every emerging technology is a great idea propelling it forward. In the Microsoft Research Podcast series <em>Ideas</em>, members of the research community at Microsoft discuss the beliefs that animate their research, the experiences and thinkers that inform it, and the positive human impact it targets.&nbsp;</p>



<p>In this episode, guest host Lindsay Kalter talks with Principal Research Manager <a href="https://www.microsoft.com/en-us/research/people/tianxie/?msockid=35739e94ab6c69d41b738b93aa076831" target="_blank" rel="noreferrer noopener">Tian Xie</a> and Principal Researcher <a href="https://www.microsoft.com/en-us/research/people/zihenglu/?msockid=35739e94ab6c69d41b738b93aa076831" target="_blank" rel="noreferrer noopener">Ziheng Lu</a> about their groundbreaking AI tools for materials discovery. Xie introduces MatterGen, which can generate new materials tailored to the specific needs of an application, such as materials with powerful magnetic properties or those that efficiently conduct lithium ions for better batteries. Lu explains how MatterSim accelerates simulations to&nbsp;validate and refine these discoveries. Together, these tools act as a “copilot” for scientists, proposing creative hypotheses and exploring vast material spaces far beyond traditional methods. The conversation highlights the challenges of bridging AI and experimental science and the potential of these tools to drive advancements in energy, manufacturing, and sustainability. At the cutting edge of AI research, Xie and Lu share their vision for the future of materials design and how these technologies could transform the field.</p>



<p><strong>Learn more:</strong></p>



<p><a href="https://www.microsoft.com/en-us/research/blog/mattersim-a-deep-learning-model-for-materials-under-real-world-conditions/" target="_blank" rel="noreferrer noopener">MatterSim: A deep-learning model for materials under real-world conditions</a>&nbsp;<br>Microsoft Research blog, May 2024&nbsp;</p>



<p><a href="https://www.microsoft.com/en-us/research/publication/mattersim-a-deep-learning-atomistic-model-across-elements-temperatures-and-pressures/" target="_blank" rel="noreferrer noopener">MatterSim: A Deep Learning Atomistic Model Across Elements, Temperatures and Pressures</a>&nbsp;<br>Publication, March 2024&nbsp;</p>



<p><a class="msr-external-link glyph-append glyph-append-open-in-new-tab glyph-append-xsmall" href="https://github.com/microsoft/mattersim" target="_blank" rel="noreferrer noopener">MatterSim<span class="sr-only"> (opens in new tab)</span></a>&nbsp;<br>GitHub repo&nbsp;</p>



<p><a class="msr-external-link glyph-append glyph-append-open-in-new-tab glyph-append-xsmall" href="https://www.nature.com/articles/s41586-025-08628-5" target="_blank" rel="noreferrer noopener">A generative model for inorganic materials design<span class="sr-only"> (opens in new tab)</span></a>&nbsp;<br>Publication, January 2025&nbsp;</p>



<p><a href="https://www.microsoft.com/en-us/research/articles/mattergen-a-generative-model-for-materials-design/" target="_blank" rel="noreferrer noopener">MatterGen: A Generative Model for Materials Design</a>&nbsp;<br>Video, Microsoft Research Forum, June 2024&nbsp;</p>



<p><a href="https://www.microsoft.com/en-us/research/blog/mattergen-property-guided-materials-design/" target="_blank" rel="noreferrer noopener">MatterGen: Property-guided materials design</a>&nbsp;<br>Microsoft Research blog, December 2023&nbsp;</p>



<p><a class="msr-external-link glyph-append glyph-append-open-in-new-tab glyph-append-xsmall" href="https://github.com/microsoft/mattergen" target="_blank" rel="noreferrer noopener">MatterGen<span class="sr-only"> (opens in new tab)</span></a>&nbsp;<br>GitHub repo&nbsp;</p>



<p><a href="https://www.microsoft.com/en-us/research/publication/crystal-diffusion-variational-autoencoder-for-periodic-material-generation/" target="_blank" rel="noreferrer noopener">Crystal Diffusion Variational Autoencoder for Periodic Material Generation</a>&nbsp;<br>Publication, October 2021</p>



<p><a href="https://www.microsoft.com/en-us/research/publication/crystal-graph-convolutional-neural-networks-for-an-accurate-and-interpretable-prediction-of-material-properties/" target="_blank" rel="noreferrer noopener">Crystal Graph Convolutional Neural Networks for an Accurate and Interpretable Prediction of Material Properties</a><br>Publication, April 2018</p>



<section class="wp-block-msr-subscribe-to-podcast subscribe-to-podcast">
	<div class="subscribe-to-podcast__inner border-top border-bottom border-width-2">
		<h2 class="h5 subscribe-to-podcast__heading">
			Subscribe to the <a href="https://www.microsoft.com/en-us/research/podcast">Microsoft Research Podcast</a>:		</h2>
		<ul class="subscribe-to-podcast__list list-unstyled">
							<li class="subscribe-to-podcast__list-item">
					<a class="subscribe-to-podcast__link" href="https://itunes.apple.com/us/podcast/microsoft-research-a-podcast/id1318021537?mt=2" target="_blank" rel="noreferrer noopener">
						<svg class="subscribe-to-podcast__svg" xmlns="http://www.w3.org/2000/svg" fill="black" viewBox="0 0 32 32">  <path d="M7.12 0c-3.937-0.011-7.131 3.183-7.12 7.12v17.76c-0.011 3.937 3.183 7.131 7.12 7.12h17.76c3.937 0.011 7.131-3.183 7.12-7.12v-17.76c0.011-3.937-3.183-7.131-7.12-7.12zM15.817 3.421c3.115 0 5.932 1.204 8.079 3.453 1.631 1.693 2.547 3.489 3.016 5.855 0.161 0.787 0.161 2.932 0.009 3.817-0.5 2.817-2.041 5.339-4.317 7.063-0.812 0.615-2.797 1.683-3.115 1.683-0.12 0-0.129-0.12-0.077-0.615 0.099-0.792 0.192-0.953 0.64-1.141 0.713-0.296 1.932-1.167 2.677-1.911 1.301-1.303 2.229-2.932 2.677-4.719 0.281-1.1 0.244-3.543-0.063-4.672-0.969-3.595-3.907-6.385-7.5-7.136-1.041-0.213-2.943-0.213-4 0-3.636 0.751-6.647 3.683-7.563 7.371-0.245 1.004-0.245 3.448 0 4.448 0.609 2.443 2.188 4.681 4.255 6.015 0.407 0.271 0.896 0.547 1.1 0.631 0.447 0.192 0.547 0.355 0.629 1.14 0.052 0.485 0.041 0.62-0.072 0.62-0.073 0-0.62-0.235-1.199-0.511l-0.052-0.041c-3.297-1.62-5.407-4.364-6.177-8.016-0.187-0.943-0.224-3.187-0.036-4.052 0.479-2.323 1.396-4.135 2.921-5.739 2.199-2.319 5.027-3.543 8.172-3.543zM16 7.172c0.541 0.005 1.068 0.052 1.473 0.14 3.715 0.828 6.344 4.543 5.833 8.229-0.203 1.489-0.713 2.709-1.619 3.844-0.448 0.573-1.537 1.532-1.729 1.532-0.032 0-0.063-0.365-0.063-0.803v-0.808l0.552-0.661c2.093-2.505 1.943-6.005-0.339-8.296-0.885-0.896-1.912-1.423-3.235-1.661-0.853-0.161-1.031-0.161-1.927-0.011-1.364 0.219-2.417 0.744-3.355 1.672-2.291 2.271-2.443 5.791-0.348 8.296l0.552 0.661v0.813c0 0.448-0.037 0.807-0.084 0.807-0.036 0-0.349-0.213-0.683-0.479l-0.047-0.016c-1.109-0.885-2.088-2.453-2.495-3.995-0.244-0.932-0.244-2.697 0.011-3.625 0.672-2.505 2.521-4.448 5.079-5.359 0.547-0.193 1.509-0.297 2.416-0.281zM15.823 11.156c0.417 0 0.828 0.084 1.131 0.24 0.645 0.339 1.183 0.989 1.385 1.677 0.62 2.104-1.609 3.948-3.631 3.005h-0.015c-0.953-0.443-1.464-1.276-1.475-2.36 0-0.979 0.541-1.828 1.484-2.328 0.297-0.156 0.709-0.235 1.125-0.235zM15.812 17.464c1.319-0.005 2.271 0.463 2.625 1.291 0.265 0.62 0.167 2.573-0.292 5.735-0.307 2.208-0.479 2.765-0.905 3.141-0.589 0.52-1.417 0.667-2.209 0.385h-0.004c-0.953-0.344-1.157-0.808-1.553-3.527-0.452-3.161-0.552-5.115-0.285-5.735 0.348-0.823 1.296-1.285 2.624-1.291z"/></svg>
						<span class="subscribe-to-podcast__link-text">Apple Podcasts</span>
					</a>
				</li>
			
							<li class="subscribe-to-podcast__list-item">
					<a class="subscribe-to-podcast__link" href="https://subscribebyemail.com/www.blubrry.com/feeds/microsoftresearch.xml" target="_blank" rel="noreferrer noopener">
						<svg class="subscribe-to-podcast__svg" xmlns="http://www.w3.org/2000/svg" fill="none" viewBox="0 0 32 32"><path fill="currentColor" d="M6.4 6a2.392 2.392 0 00-2.372 2.119L16 15.6l11.972-7.481A2.392 2.392 0 0025.6 6H6.4zM4 10.502V22.8a2.4 2.4 0 002.4 2.4h19.2a2.4 2.4 0 002.4-2.4V10.502l-11.365 7.102a1.2 1.2 0 01-1.27 0L4 10.502z"/></svg>
						<span class="subscribe-to-podcast__link-text">Email</span>
					</a>
				</li>
			
							<li class="subscribe-to-podcast__list-item">
					<a class="subscribe-to-podcast__link" href="https://subscribeonandroid.com/www.blubrry.com/feeds/microsoftresearch.xml" target="_blank" rel="noreferrer noopener">
						<svg class="subscribe-to-podcast__svg" xmlns="http://www.w3.org/2000/svg" fill="none" viewBox="0 0 32 32"><path fill="currentColor" d="M12.414 4.02c-.062.012-.126.023-.18.06a.489.489 0 00-.12.675L13.149 6.3c-1.6.847-2.792 2.255-3.18 3.944h13.257c-.388-1.69-1.58-3.097-3.179-3.944l1.035-1.545a.489.489 0 00-.12-.675.492.492 0 00-.675.135l-1.14 1.68a7.423 7.423 0 00-2.55-.45c-.899 0-1.758.161-2.549.45l-1.14-1.68a.482.482 0 00-.494-.195zm1.545 3.824a.72.72 0 110 1.44.72.72 0 010-1.44zm5.278 0a.719.719 0 110 1.44.719.719 0 110-1.44zM8.44 11.204A1.44 1.44 0 007 12.644v6.718c0 .795.645 1.44 1.44 1.44.168 0 .33-.036.48-.09v-9.418a1.406 1.406 0 00-.48-.09zm1.44 0V21.76c0 .793.646 1.44 1.44 1.44h10.557c.793 0 1.44-.647 1.44-1.44V11.204H9.878zm14.876 0c-.169 0-.33.035-.48.09v9.418c.15.052.311.09.48.09a1.44 1.44 0 001.44-1.44v-6.719a1.44 1.44 0 00-1.44-1.44zM11.8 24.16v1.92a1.92 1.92 0 003.84 0v-1.92h-3.84zm5.759 0v1.92a1.92 1.92 0 003.84 0v-1.92h-3.84z"/></svg>
						<span class="subscribe-to-podcast__link-text">Android</span>
					</a>
				</li>
			
							<li class="subscribe-to-podcast__list-item">
					<a class="subscribe-to-podcast__link" href="https://open.spotify.com/show/4ndjUXyL0hH1FXHgwIiTWU" target="_blank" rel="noreferrer noopener">
						<svg class="subscribe-to-podcast__svg" xmlns="http://www.w3.org/2000/svg" fill="none" viewBox="0 0 32 32"><path fill="currentColor" d="M16 4C9.383 4 4 9.383 4 16s5.383 12 12 12 12-5.383 12-12S22.617 4 16 4zm5.08 17.394a.781.781 0 01-1.086.217c-1.29-.86-3.477-1.434-5.303-1.434-1.937.002-3.389.477-3.403.482a.782.782 0 11-.494-1.484c.068-.023 1.71-.56 3.897-.562 1.826 0 4.365.492 6.171 1.696.36.24.457.725.217 1.085zm1.56-3.202a.895.895 0 01-1.234.286c-2.338-1.457-4.742-1.766-6.812-1.747-2.338.02-4.207.466-4.239.476a.895.895 0 11-.488-1.723c.145-.041 2.01-.5 4.564-.521 2.329-.02 5.23.318 7.923 1.995.419.26.547.814.286 1.234zm1.556-3.745a1.043 1.043 0 01-1.428.371c-2.725-1.6-6.039-1.94-8.339-1.942h-.033c-2.781 0-4.923.489-4.944.494a1.044 1.044 0 01-.474-2.031c.096-.023 2.385-.55 5.418-.55h.036c2.558.004 6.264.393 9.393 2.23.497.292.663.931.371 1.428z"/></svg>
						<span class="subscribe-to-podcast__link-text">Spotify</span>
					</a>
				</li>
			
							<li class="subscribe-to-podcast__list-item">
					<a class="subscribe-to-podcast__link" href="https://www.blubrry.com/feeds/microsoftresearch.xml" target="_blank" rel="noreferrer noopener">
						<svg class="subscribe-to-podcast__svg" xmlns="http://www.w3.org/2000/svg" fill="none" viewBox="0 0 32 32"><path fill="currentColor" d="M6.667 4a2.676 2.676 0 00-2.612 2.13v.003c-.036.172-.055.35-.055.534v18.666c0 .183.019.362.055.534v.003a2.676 2.676 0 002.076 2.075h.002c.172.036.35.055.534.055h18.666A2.676 2.676 0 0028 25.333V6.667a2.676 2.676 0 00-2.13-2.612h-.003A2.623 2.623 0 0025.333 4H6.667zM8 8h1.333C17.42 8 24 14.58 24 22.667V24h-2.667v-1.333c0-6.618-5.382-12-12-12H8V8zm0 5.333h1.333c5.146 0 9.334 4.188 9.334 9.334V24H16v-1.333A6.674 6.674 0 009.333 16H8v-2.667zM10 20a2 2 0 11-.001 4.001A2 2 0 0110 20z"/></svg>
						<span class="subscribe-to-podcast__link-text">RSS Feed</span>
					</a>
				</li>
					</ul>
	</div>
</section>


<div class="wp-block-msr-show-more">
	<div class="bg-neutral-100 p-5">
		<div class="show-more-show-less" data-mount="show-more-show-less">
			<div>
				<span>
					

<h2 class="wp-block-heading" id="transcript">Transcript</h2>



<p>[TEASER]&nbsp;</p>



<p>[MUSIC PLAYS UNDER DIALOGUE]&nbsp;</p>



<p><strong>TIAN XIE: </strong>Yeah,<strong> </strong>so<strong> </strong>the problem of generating materials from properties is actually a pretty old one. I still remember back in 2018, when I was giving a talk about property-prediction models, right, one of the first questions people asked is, instead of going from material structure to properties, can you, kind of, inversely generate the materials directly from their property conditions? So in a way, this is, kind of, like a dream for material scientists<strong> </strong>because, like, the end goal is really about finding materials property, right, [that] will satisfy your application. </p>



<p><strong>ZIHENG LU: </strong>Previously, a lot of people are using this atomistic simulator and this generative models <em>alone</em>. But if you think about it, now that we have these two foundation models together, it really can make things different, right. You have a very good idea generator. And you have a very good goalkeeper. And you put them together. They form a loop. And now you can use this loop to design materials really quickly. </p>



<p>[TEASER ENDS]&nbsp;</p>



<p><strong>LINDSAY KALTER: </strong>You&#8217;re listening to <em>Ideas</em>, a Microsoft Research Podcast that dives deep into the world of technology research and the profound questions behind the code. In this series, we&#8217;ll explore the technologies that are shaping our future and the big ideas that propel them forward.</p>



				</span>
				<span id="show-more-show-less-toggle-12" class="show-more-show-less-toggleable-content">
					



<p>[MUSIC FADES]&nbsp;</p>



<p>I&#8217;m your guest host, Lindsay Kalter. Today I&#8217;m talking to Microsoft Principal Research Manager Tian Xie and Microsoft Principal Researcher Ziheng Lu. Tian is doing fascinating work with MatterGen, an AI tool for generating new materials guided by specific design requirements. Ziheng is one of the visionaries behind MatterSim, which puts those new materials to the test through advanced simulations. Together, they&#8217;re redefining what&#8217;s possible in materials science. Tian and Ziheng, welcome to the podcast.&nbsp;</p>



<p><strong>TIAN XIE:</strong> Very excited to be here.&nbsp;</p>



<p><strong>ZIHENG LU: </strong>Thanks, Lindsay, very excited. </p>



<p><strong>KALTER: </strong>Before we dig into the specifics of MatterGen and MatterSim, let&#8217;s give our audience a sense of how you, as researchers, arrived at this moment. Materials science, especially at the intersection of computer science, is such a cutting-edge and transformative field. What first drew each of you to this space? And what, if any, moment or experience made you realize <em>this</em> was where you wanted to innovate? Tian, do you want to start?&nbsp;</p>



<p><strong>XIE: </strong>So I started working on AI for materials back in 2015, when I started my PhD. So I come as a chemist and materials scientist, but I was, kind of, figuring out what I want to do during my PhD. So there is actually one moment really drove me into the field. That was AlphaGo. AlphaGo was, kind of, coming out in 2016, where it was able to beat the world champion in go in 2016. I was extremely impressed by that because I, kind of, learned how to do go, like, in my childhood. I know how hard it is and how much effort those professional go players have spent, right, in learning about go. So I, kind of, have the feeling that if AI can surpass the world-leading go players, one day, it will too surpass material scientists, right, in their ability to design novel materials. So that&#8217;s why I ended up deciding to<strong> </strong>focus my entire PhD on working on AI for materials. And I have been working on that since then. So it was actually very interesting because it was a very small field back then. And it&#8217;s great to see how much progress has been made, right, in the past 10 years and how much bigger a field it is now compared with 10 years ago.&nbsp;</p>



<p><strong>LU: </strong>That&#8217;s very interesting, Tian. So, actually, I think I started, like, two years before you as a PhD student. So I, actually, I was trained as a computational materials scientist solely, not really an AI expert. But at that time, the computational materials science did not really work that well. It works but not working that well. So after, like, two or three years, I went back to experiments for, like, another two or three years because, I mean, the experiment is always the gold standard, right. And I worked on this experiments for a few years, and then about three years ago, I went back to this field of computation, <em>especially</em> because of AI. At that time, I think GPT and these large AI models that currently we&#8217;re using is not there, but we already have their prior forms like BERT, so we see the very large potential of AI. We know that these large AIs might work. So one idea is really to use AI to learn the entire space of materials and really grasp the physics there, and that really drove me to this field and that&#8217;s why I&#8217;m here working on this field, yeah.&nbsp;</p>



<p><strong>KALTER: </strong>We&#8217;re going to get into what MatterGen and MatterSim mean for materials science—the potential, the challenges, <em>and</em> open questions. But first, give us an overview of what each of these tools are, how they do what they do, and—as this show is about big ideas—the idea driving the work. Ziheng, let&#8217;s have you go first. </p>



<p><strong>LU:</strong> So MatterSim is a tool to do in silico characterizations of materials. If you think about working on materials, you have several steps. You first need to synthesize it, and then you need to characterize this. Basically, you need to know what property, what structures, whatever stuff about these materials. So for MatterSim, what we want to do is to really move the characterization process, a lot of these processes, into using computations. So the idea behind MatterSim is to really learn the fundamentals of physics. So we learn the energies and forces and stresses from these atomic structures and the charge densities, all of these things, and then with these, we can really simulate any sort of materials using our computational machines. And then with these, we can really characterize a lot of these materials’ properties using our computer, that is very fast. It&#8217;s much faster than we do experiments so that we can accelerate the materials design. So just in a word, basically, you input your material into your computer, a structure into your computer, and MatterSim will try to simulate these materials like what you do in a furnace or with an XRD<strong> </strong>(x-ray diffraction) and then you get your properties out of that, and a lot of times it&#8217;s much faster than you do experiments.&nbsp;</p>



<p><strong>KALTER: </strong>All right, thank you very much. Tian, why don&#8217;t you tell us about MatterGen?&nbsp;</p>



<p><strong>XIE: </strong>Yeah, thank you. So, actually, Ziheng, once you start with explaining MatterSim, it makes it much easier for me to explain MatterGen. So MatterGen actually represents a new way to design materials with generative AI. Material discovery is like finding needles in a haystack. You&#8217;re looking for a material with a very specific property for a material application. For example, like finding a room-temperature superconductor or finding a solid that can conduct a lithium ion very well inside a battery. So it&#8217;s like finding one very specific material from a <em>million</em>, kind of, candidates. So the conventional way of doing material discovery is via screening, where you, kind of, go over millions of candidates to find the one that you&#8217;re looking for, where MatterSim is able to significantly accelerate that process by making the simulation much faster. But it&#8217;s still very inefficient because you need to go through this million candidates, right. So with MatterGen, you can, kind of, directly generate materials given the prompts of the design requirements for the application. So this means that you can discover materials—discover <em>useful</em> materials— much more efficiently. And it also allows us to explore a much larger space beyond the set of known materials.&nbsp;</p>



<p><strong>KALTER: </strong>Thank you, Tian. Can you tell us a little bit about how MatterGen and MatterSim work together?&nbsp;</p>



<p><strong>XIE: </strong>So you can really think about MatterSim and MatterGen accelerating different parts of materials discovery process. MatterSim is trying to accelerate the simulation of material properties, while MatterGen is trying to accelerate the <em>search</em> of novel material candidates. It means that they can really work together as a flywheel and you can compound the acceleration from both models. They are also both foundation AI models, meaning they can both be used for a broad range of materials design problems. So we&#8217;re really looking forward to see how they can, kind of, working together iteratively as a tool to design novel materials for a broad range of applications.&nbsp;</p>



<p><strong>LU: </strong>I think that&#8217;s a very good, like, general introduction of how they work together. I think I can provide an example of how they really fit together. If you want a material with a specific, like, bulk modulus or lithium-ion conductivity or thermal conductivity for your CPU chips, so basically what you want to do is start with a pool of material structures, like some structures from the database, and then you compute or you characterize your wanted property from that stack of materials. And then what you do, you’ve got these properties and structure pairs, and you input these pairs into MatterGen. And MatterGen will be able to give you a lot more of these structures that are highly possible to be real. But the number will be very large. For example, for the bulk modulus, I don&#8217;t remember the number we generated in our work … was that like thousands, tens of thousands? </p>



<p><strong>XIE:</strong> Thousands, tens of thousands.&nbsp;</p>



<p><strong>LU:</strong> Yeah, that would be a very large number pool even with MatterGen, so then the next step will be, how would you like to screen that? You cannot really just send all of those structures to a lab to synthesize. It&#8217;s too much, right. That&#8217;s when MatterSim again comes in. So MatterSim comes in and screen all those structures again and see which ones are the most likely to be synthesized and which ones have the closest property you wanted. And then after screening, you probably get five, 10 top candidates and then you send to a lab. Boom, everything goes down. That&#8217;s it.&nbsp;</p>



<p><strong>KALTER: </strong>I&#8217;m wondering if there&#8217;s any prior research or advancements that you drew from in creating MatterGen and MatterSim. Were there any specific breakthroughs that influenced your approaches at all?&nbsp;</p>



<p><strong>LU: </strong>Thanks, Lindsay. I think I&#8217;ll take that question first. So interestingly for MatterSim, a very fundamental idea was drew from Chi Chen, who was a previous lab mate of mine and now also works for Microsoft at Microsoft Quantum. He made this fantastic model named M3GNet, which is a prior form of a lot of these large-scale models for atomistic simulations. That model, M3GNet, actually resolves the near ground state prediction problem. I mean, the near ground state problem sounds like a fancy but not realistic word, but what that actually means is that it can simulate materials at near-zero covalent states. So basically at very low temperatures. So at that time, we were thinking since the models are now able to simulate materials at their near ground states, it&#8217;s not a very large space. But if you also look at other larger models, like GPT whatever, those models are large enough to simulate entire human language. So it&#8217;s possible to really <em>extend</em> the capability from these such prior models to very large space. Because we believe in the capability of AI, then it really drove us to use MatterSim to learn the entire space of materials. I mean, the entire space really means the entire periodic table, all the temperatures and the pressures people can actually grasp.&nbsp;</p>



<p><strong>XIE: </strong>Yeah, I still remember a lot of the amazing works from Chi Chen whenever we&#8217;re, kind of, back working on property-prediction models. So, yeah, so the problem of generating materials from properties is actually a pretty old one. I still remember back in 2018, when I was, kind of, working on CGCNN (crystal graph convolutional neural networks) and giving a talk about property-prediction models, right, one of the first questions people asked is, OK, can you inverse this process? Instead of going from material structure to properties, can you, kind of, inversely generate the materials directly from their property conditions? So in a way, this is, kind of, like a dream for material scientists—some people even call it, like, holy grail—because, like, the end goal is really about finding materials property, right, [that] will satisfy your application. So I&#8217;ve been, kind of, thinking about this problem for a while and also there has been a lot of work, right, over the past few years in the community to build a generative model for materials. A lot of people have tried before, like 2020, using ideas like VAEs or GANs. But it&#8217;s hard to represent materials in this type of generative model architecture, and many of those models generated relatively poor candidates. So I thought it was a hard problem. I, kind of, know it for a while. But there is no good solutions back then. So I started to focus more on this problem during my postdoc, when I studied that in 2020 and I keep working on that in 2021. At the beginning, I wasn&#8217;t really sure exactly what approach to take because it&#8217;s, kind of, like open question and really tried a lot of random ideas. So one day actually in my group back then with Tommi Jaakkola and Regina Barzilay at MIT&#8217;s CSAIL (Computer Science & Artificial Intelligence Laboratory), we, kind of, get to know this method called diffusion model. It was a very early stage of a diffusion model back then, but it already began to show very promising signs, kind of, achieving state of art in many problems like 3D point cloud generation and the 3D molecular conformer generation. So the work that really inspired me a lot is two works that was for molecular conformer generation. One is ConfGF, and one is GeoDiff. So they, kind of, inspired me to, kind of, focus more on diffusion models. That actually lead to CDVAE (crystal diffusion variational autoencoder). So it&#8217;s interesting that we, kind of, spend like a couple of weeks in trying all this diffusion idea, and without that much work, it actually worked quite out of box. And at that time, CDVAE achieves much better performance than any previous models in materials generation, and we&#8217;re, kind of, super happy with that. So after CDVAE, I, kind of, joined Microsoft, now working with more people together on this problem of generative model for materials. So we, kind of, know what the limitations of CDVAE are, is that it can do unconditional material generation well means it can generate novel material structures, but it is very hard to use CDVAE to do property-guided generations. So basically, it uses an architecture called a variational autoencoder, where you have a latent space. So the way that you do property-guided generation there was to do a, kind of, a gradient update inside the latent space. But because the latent space wasn&#8217;t learned very well, so it actually … you cannot do, kind of, good property-guided generation. We only managed to do energy-guided generation, but it wasn&#8217;t successful in going beyond energy. So that comes us to really thinking, right, how can we make the property-guided generation much better? So I remember like one day, actually, my colleague, Daniel Zügner, who actually really showed me this blog which basically explains this idea of classifier-free guidance, which is the powerhouse behind the text-image generative models. And so, yeah, then we began to think about, can we actually make the diffusion model work for classifier-free guidance? That lead us to remove the, kind of, the variational autoencoder component from CDVAE and begin to work on a pure diffusion architecture. But then there was, kind of, a lot of development around that. But it turns out that classifier-free guidance is the key really to make property-guided generation work, and then combined with a lot more effort in, kind of, improving architecture and also generating more data and also trying out all these different downstream tasks that end up leading into MatterGen as we see today.&nbsp;</p>



<p><strong>KALTER: </strong>Yeah, I think you&#8217;ve both done a really great job of explaining how MatterGen and MatterSim work together and how MatterGen can offer a lot in terms of reducing the amount of time and work that goes into finding new materials. Tian, how does the process of using MatterGen to generate materials translate into real-world applications?&nbsp;</p>



<p><strong>XIE: </strong>Yeah, that&#8217;s a fantastic question. So one way that I think about MatterGen, right, is that you can think about it as like a copilot for materials scientists, right. So they can help you to come up with, kind of, potential good hypothesis for the materials design problems that you&#8217;re looking for. So say you&#8217;re trying to design a battery, right. So you may have some ideas over, OK, what candidates you want to make, but this is, kind of, based on your own experience, right. Depths of experience as a researcher. But MatterGen is able to, kind of, learn from a very broad set of data, so therefore, it may be able to come up with some good suggestions, even <em>surprising</em> suggestions, for you so that you can, kind of, try this out, right, both with computation or even one day in wet lab and experimentally synthesize it. But I also want to note that this, in a way, this is still an early stage in generative AI for materials means that I don&#8217;t expect all the candidates MatterGen generates will be, kind of, suits your needs, right. So you still need to, kind of, look into them with expertise or with some kind of computational screening. But<strong> </strong>I think in the future, as this model keep improving themselves, they will become a key component, right, in the design process of many of the materials we&#8217;re seeing today, like designing new batteries, new solar cells, or even computer chips, right, so that like Ziheng mentioned earlier.&nbsp;</p>



<p><strong>KALTER: </strong>I want to pivot a little bit to the MatterSim side of things. I know identifying new combinations of compounds is key to meeting changing needs for things like sustainable materials. But testing them is equally important to developing materials that can be put to use. Ziheng, how does MatterSim handle the uncertainty of how materials behave under various conditions, and how do you ensure that the predictions remain robust despite the inherent complexity of molecular systems?&nbsp;</p>



<p><strong>LU: </strong>Thanks. That&#8217;s a very, very good question. So uncertainty quantification is a key to make sure all these predictions and simulations are trustworthy. And that&#8217;s actually one of the questions we got almost every time after a presentation. So people will ask, well—especially those experimentalists—would ask, well, I&#8217;ve been using your model; how do I know those predictions are true under the very complex conditions I&#8217;m using in my experiments? So to understand how we deal with uncertainty, we need to know how MatterSim really functions in predicting an arbitrary property, especially under the condition you want, like the temperature and pressure. That would be quite complex, right? So in the ideal case, we would hope that by using MatterSim, you can directly simulate the properties you want using molecular dynamics combined with statistical mechanics. So if so, it would be easy to really quantify the uncertainty because there are just two parts: the error from the model and the error from the simulations, the statistical mechanics. So the error from the model will be able to be measured by, what we call, an <em>ensemble</em>. So basically you start with different random seeds when you train the model, and then when you predict your property, you use several models from the ensemble and then you get different numbers. If the variance from the numbers are very large, you&#8217;ll say the prediction is not that trustworthy. But a lot of times, we will see the variance is very small. So basically, an ensemble of several different models will give you almost exactly the same number; you&#8217;re quite sure that the number is somehow very, like, useful. So that&#8217;s one level of the way we want to get our property. But sometimes, it&#8217;s very hard to really directly simulate the property you want. For example, for catalytic processes, it&#8217;s very hard to imagine how you really get those coefficients. It&#8217;s very hard. The process is just too complicated. So for that process, what we do is to really use the, what we call, embeddings learned from the entire material space. So basically that vector we learned for any arbitrary material. And then start from that, we build a very shallow layer of a neural network to predict the property, but that also means you need to bring in some of your experimental or simulation data from your side. And for that way of predicting a property to measure the uncertainty, it&#8217;s still like the two levels, right. So we don&#8217;t really have the statistical error anymore, but what we have is, like, only the model error. So you can still stick to the ensemble, and then it will work, right. So to be short, so MatterSim can provide you an uncertainty to make sure the prediction tells you whether it&#8217;s true or not.</p>



<p><strong>KALTER: </strong>So in many ways, MatterSim is the <em>realist</em> in the equation, and it&#8217;s there to sort of be a gatekeeper for MatterGen, which is the idea generator.&nbsp;</p>



<p><strong>XIE: </strong>I really like the analogy.&nbsp;</p>



<p><strong>LU: </strong>Yeah.&nbsp;</p>



<p><strong>KALTER: </strong>As is the case with many AI models, the development of MatterGen and MatterSim relies on massive amounts of data. And here you use a simulation to create the needed training data. Can you talk about that process and why you&#8217;ve chosen that approach, Tian?</p>



<p><strong>XIE: </strong>So one advantage here is that we can really use large-scale simulation to generate data. So we have a lot of compute here at Microsoft on our Azure platform, right. So how we generate the data is that we use a method called density functional theory, DFT, which is a quantum mechanical method. And we use a simulation workflow built on top with DFT to simulate the stability of materials. So what we do is that we curate a huge amount of material structures from multiple different sources of open data, mostly including Materials Project and Alexandria database, and in total, there are around 3 million materials candidates coming from these two databases. But not all of these structures, they are stable. So therefore, we try to use DFT to compute their stability and try to filter down the candidates such that we are making sure that our training data only have the most stable ones. This leads into around 600,000 training data, which was used to train the base model of MatterGen. So I want to note that actually we also use MatterSim as part of the workflow because MatterSim can be used to prescreen unstable candidates so that we don&#8217;t need to use DFT to compute all of them. I think at the end, we computed around 1 million DFT calculations where two-thirds of them, they are already filtered out by MatterSim, which saves us a lot of compute in generating our training data.</p>



<p><strong>LU: </strong>Tian, you have a very good description of how we really get those ground state structures for the MatterGen model. Actually, we&#8217;ve been also using MatterGen for MatterSim to really get the training data. So if you think about the simulation space of materials, it&#8217;s extremely large. So we would think it in a way that it has three axis, so basically the elements, the temperature, and the pressure. So if you think about existing databases, they have pretty good coverage of the elements space. Basically, we think about Materials Project, NOMAD, they really have this very good coverage of lithium oxide, lithium sulfide, hydrogen sulfide, whatever, those different ground-state structures. But they don&#8217;t really tell you how these materials behave under certain temperature and pressure, especially under those extreme conditions like 1,600 Kelvin, which you really use to synthesize your materials. That&#8217;s where we really focused on to generate the data for MatterSim. So it&#8217;s really easy to think about how we generate the data, right. You put your wanted material into a pressure cooker, basically, molecular dynamics; it can simulate the materials behavior on the temperature and pressure. So that&#8217;s it. Sounds easy, right? But that&#8217;s not true because what we want is not one single material. What we want is the entire material space. So that will be making the effort almost impossible because the space is just so large. So that&#8217;s where we really develop this active learning pipeline. So basically, what we do is, like, we generate a lot of these structures for different elements and temperatures, pressures. Really, really a lot. And then what we do is, like, we ask the active learning or the uncertainty measurements to really say whether the model knows about this structure already. So if the model thinks, well, I think I know the structure already. So then, we don&#8217;t really calculate this structure using density function theory, as Tian just said. So this will really save us like 99% of the effort in generating the data. So in the end, by combining this molecular dynamics, basically pressure cooker, together with active learning, we gathered around 17 million data for MatterSim. So that was used to train the model. And now it can cover the entire periodic table and a lot of temperature and pressures.&nbsp;</p>



<p><strong>KALTER: </strong>Thank you, Ziheng. Now, I&#8217;m sure this is not news to either one of you, given that you&#8217;re both at the forefront of these efforts, but there are a growing number of tools aimed at advancing materials science. So what is it about MatterGen and MatterSim in their approach or capabilities that distinguish them?&nbsp;</p>



<p><strong>XIE: </strong>Yeah, I think I can start. So I think there is, in the past one year, there is a huge interest in building up generative AI tools for materials. So we have seen lots and lots of innovations from the community published in top conferences like NeurIPS, ICLR, ICML, etc. So I think what distinguishes MatterGen, in my point of view, are two things. First is that we are trained with a very big dataset that we curated very, very carefully, and we also spent quite a lot of time to refining our diffusion architecture, which means that our model is capable of generating very, kind of, high-quality, highly stable and novel materials. We have some kind of bar plot in our paper showcasing the advantage of our performance. I think that&#8217;s one key aspect. And I think the second aspect, which in my point of view is even more important, is that it has the ability to do property-guided generation. Many of the works that we saw in the community, they are more focused on the problem of crystal structure prediction, which MatterGen can also do, but we focus more on really property-guided generation because we think this is one of the key problems that really materials scientists care about. So the ability to do a very broad range of property-guided generation—and we have, kind of, both computational and now experimental result to validate those—I think that&#8217;s the second strong point for MatterGen.&nbsp;</p>



<p><strong>KALTER: </strong>Ziheng, do you want to add to that?&nbsp;</p>



<p><strong>LU: </strong>Yeah, thanks, Lindsay. So on the MatterSim side, I think it&#8217;s really the diverse condition it can handle that makes a difference. We&#8217;ve been talking about, like, the training data we collected really covers the entire periodic table and also, more importantly, the temperatures from 0 Kelvin to 5,000 Kelvin and the pressures from 0 gigapascal to 1,000 gigapascal. That really covers what humans can control nowadays. I mean, it&#8217;s very hard to go beyond that. If you know anyone [who] can go beyond that, let me know. So that really makes MatterSim different. Like, it can handle the realistic conditions. I think beyond that, I would say the combo between MatterSim and MatterGen really makes these set of tools really different. So previously, a lot of people are using this atomistic simulator and this generative models <em>alone</em>. But if you think about it, now that we have these two foundation models together, they really can make things different, right. So we have predictor; we have the generator; you have a very good idea generator. And you have a very good goalkeeper. And you put them together. They form a loop. And now you can use this loop to design materials really quickly. So I would say to me, now, when I think about it, it&#8217;s really the combo that makes these set of tools different.&nbsp;</p>



<p><strong>KALTER: </strong>I know that I&#8217;ve spoken with both of you recently about how there&#8217;s so much excitement around this, and it&#8217;s clear that we&#8217;re on the precipice of this—as both of you have called it—a paradigm shift. And Microsoft places a very strong emphasis on ensuring that its innovations are grounded in reality and capable of addressing real-world problems. So with that in mind, how do you balance the excitement of scientific exploration with the practical challenges of implementation? Tian, do you want to take this?</p>



<p><strong>XIE: </strong>Yeah, I think this is a very, very important point, because &#8230; as there are so many hypes around AI that is happening right now, right. We must be very, very careful about the claims that we are making so that people will not have unrealistic expectations, right, over how these models can do. So for MatterGen, we&#8217;re pretty careful about that. We&#8217;re trying to, basically, we&#8217;re trying to say that this is an early stage of generative AI in materials where this model will be improved over time quite significantly, but you should not say, oh, all the materials generated by MatterGen is going to be amazing. That&#8217;s not what is happening today. So we try to be very careful to understand how far MatterGen is already capable of designing materials with real-world impact. So therefore, we went all the way to synthesize one material that was generated by MatterGen. So this material we generated is called tantalum chromium oxide<a id="_ftnref1" href="#_ftn1">[1]</a>. So this is a new material. It has not been discovered before. And it was generated by MatterGen by conditioning a bulk modulus equal to 200 gigapascal. Bulk modulus is, like, the compressiveness of the material. So we end up measuring the experimental synthesized material experimentally, and the measured bulk modulus is 169 gigapascal, which is within 20% of error. So this is a very good proof concept, in our point of view, to show that, oh, you can actually give it a prompt, right, and then MatterGen can generate a material, and the material actually have the property that is very close to your target. But it&#8217;s still a proof of concept. And we&#8217;re still working to see how MatterGen can design materials that are much more useful with a much broader range of applications. And I&#8217;m sure that there will be more challenges we are seeing along the way. But we&#8217;re looking forward to further working with our experimental partners to, kind of, push this further. And also working with MatterSim, right, to see how these two tools can be used to design really useful materials and bringing this into real-world impact.</p>



<p><strong>LU: </strong>Yeah, Tian, I think that&#8217;s very well said. It&#8217;s not really only for MatterGen. For MatterSim, we&#8217;re also very careful, right. So we really want to make sure that people understand how these models really behave under their instructions and understand, like, what they can do and they cannot do. So I think one thing that we really care about is that in the next few, maybe one or two years, we want to really work with our experimental partners to make this realistic materials, like, in different areas so that we can, even <em>us</em>, can really better understand the limitations and at the same time explore the forefront of materials science to make this excitement become true.&nbsp;</p>



<p><strong>KALTER: </strong>Ziheng, could you give us a concrete example of what exactly MatterSim is capable of doing?&nbsp;</p>



<p><strong>LU: </strong>Now MatterSim can really do, like, whatever you have on a potential energy surface. So what that means is, like, anything that can be simulated with the energy and forces, stresses alone. So to give you an example, we can compute … the first example would be the stability of a material. So basically, you input a structure, and from the energies of the relaxed structures, you can really tell whether the material is likely to be stable, like, the composition, right. So another example would be the thermal conductivity. Thermal conductivity is like a fundamental property of materials that tells you how fast heat can transfer in the material, right. So for MatterSim, it can really simulate how fast this heat can go through your diamond, your graphene, your copper, right. So basically, those are two examples. So these examples are based on energies and forces alone. But there are things MatterSim cannot do—at least for now. For example, you cannot really do anything related to electronic structures. So you cannot really compute the light absorption of a semitransparent material. That would be a no-no for now.&nbsp;</p>



<p><strong>KALTER: </strong>It&#8217;s clear from speaking with researchers, both from MatterSim and MatterGen, that despite these very rapid advancements in technology, you take very seriously the responsibility to consider the broader implications of the challenges that are still ahead. How do you think about the ethical considerations of creating entirely new materials and simulating their properties, particularly in terms of things like safety, sustainability, and societal impact?&nbsp;</p>



<p><strong>XIE: </strong>Yeah, that&#8217;s a fantastic question. So it&#8217;s extremely important that we are making sure that these AI tools, they are not misused. A potential misuse, right, as you just mentioned, is that people begin to use these AI tools—MatterGen, MatterSim—to, kind of, design harmful materials. There was actually extensive discussion over how generative AI tools that was originally purposed for drug design can be then misused to create bioweapons. So at Microsoft, we take this very seriously because we believe that when we create new technologies, you must also ensure that the technology is used responsibly. So we have an extensive process to ensure that all of our models respect those ethical considerations. In the meantime, as you mentioned, maybe sustainability and the societal impact, right, so there&#8217;s a huge amount these AI tools—MatterGen, MatterSim—can do for sustainability because a lot of the sustainability challenges, they are really, at the end, materials design challenges, right. So therefore, I think that MatterGen and MatterSim can really help with that in solving, in helping us to alleviate climate change and having positive societal impact for the broader society.&nbsp;</p>



<p><strong>KALTER: </strong>And, Ziheng, how about from a simulation standpoint?&nbsp;</p>



<p><strong>LU: </strong>Yeah, I think Tian gave a very good, like, description. At Microsoft, we are really careful about these ethical, like, considerations. So I would add a little bit on the more, like, the bright side of things. Like, so for MatterSim, like, it really carries out these simulations at atomic scales. So one thing you can think about is really the educational purpose. So back in my bachelor and PhD period, so I would sit, like, at the table and really grab a pen to really deal with those very complex equations and get into those statistics using my pen. It&#8217;s really painful. But now with MatterSim, these simulation tools at atomic level, what you can do is to really simulate the reactions, the movement of atoms, at atomic scale in real time. You can really see the chemical reactions and see the statistics. So you can get really the feeling, like very direct feeling, of how the system works instead of just working on those toy systems with your pen. I think it&#8217;s going to be a very good educational tool using MatterSim, yeah. Also MatterGen. MatterGen as, like, a generative tool and generating those i.i.d. (independent and identically distributed) distributions, it will be a perfect example to show the students how the Boltzmann distribution works. I think, Tian, you will agree with that, right?</p>



<p><strong>XIE: </strong>100%. Yeah, I really, really like the example that Ziheng mentioned about the educational purposes. I still remember, like, when I was, kind of, learning material simulation class, right. So everything is DFT. You, kind of, need to wait for an hour, right, for getting some simulation. Maybe then you&#8217;ll make some animation. Now you can do this in real time. This is, like, a huge step forward, right, for our young researchers to, kind of, gaining a sense, right, about how atoms interact at an atomic level.&nbsp;</p>



<p><strong>LU: </strong>Yeah, and the results are really, I mean, true; not really those toy models. I think it&#8217;s going to be very exciting stuff.&nbsp;</p>



<p><strong>KALTER: </strong>And, Tian, I&#8217;m directing this question to you, even though, Ziheng, I&#8217;m sure you can chime in, as well. But, Tian, I know that you and I have previously discussed this specifically. I know that you said back in, you know, 2017, 2018, that you knew an AI-based approach to materials science was possible but that even you were surprised by how far the technology has come so fast in aiding this area. What is the status of these tools right now? Are they in use? And if so, who are they available to? And, you know, what&#8217;s next for them?&nbsp;</p>



<p><strong>XIE: </strong>Yes, this is a fantastic question, right. So I think for AI generative tools like MatterGen, as I said many times earlier, it&#8217;s still in its early stages. MatterGen is the first tool that we managed to show that generative AI can enable very broad property-guided generation, and we have managed to have experimental validation to show it&#8217;s possible. But it will take more work to show, OK, it can actually design batteries, can design solar cells, right. It can design really useful materials in these broader domains. So this is, kind of, exactly why we are now taking a pretty open approach with MatterGen. We make our code, our training data, and model weights available to the general public. We&#8217;re really hoping the community can really use our tools to the problem that they care about and even build on top of that. So in terms of <em>what next</em>, I always like to use what happened with generative AI for drugs, right, to kind of predict how generative AI will impact materials. Three years ago, there is a lot of research around generative model for drugs, first coming from the machine learning community, right. So then all the big drug companies begin to take notice, and then there are, kind of, researchers in these drug companies begin to use these tools in actual drug design processes. From my colleague, Marwin Segler, because he, kind of, works together with Novartis in Microsoft and Novartis collaboration, he has been basically telling me that at the beginning, all the chemists in the drug companies, they&#8217;re all very suspicious, right. The molecules generated by these generative models, they all look a bit weird, so they don&#8217;t believe this will work. But once these chemists see one or two examples that actually turns out to be performing pretty well from the experimental result, then they begin to build more trust, right, into these generative AI models. And today, these generative AI tools, they are part of the standard drug discovery pipeline that is widely used in all the drug companies. That is today. So I think generative AI for materials is going through a very similar period. People will have doubts; people will have suspicions at the beginning. But I think in three years, right, so it will become a standard tool over how people are going to design new solar cells, design new batteries, and many other different applications.</p>



<p><strong>KALTER: </strong>Great. Ziheng, do you have anything to add to that?&nbsp;</p>



<p><strong>LU:</strong> So actually for MatterSim, we released the model, I think, back in last year, December. I mean, both the weights and the models, right. So we&#8217;re really grateful how much the community has contributed to the repo. And now, I mean, we really welcome the community to contribute more to both MatterSim and MatterGen via our open-source code bases. So, I mean, the community effort is really important, yeah.&nbsp;</p>



<p><strong>KALTER: </strong>Well, it has been fascinating to pick your brains, and as we close, you know, I know that you&#8217;re both capable of quite a bit, which you have demonstrated. I know that asking you to predict the future is a big ask, so I won&#8217;t explicitly ask that. But just as a fun thought exercise, let&#8217;s fast-forward 20 years and look back. How have MatterGen and MatterSim and the big ideas behind them impacted the world, and how are people better off because of how you and your teams have worked to make them a reality? Tian, you want to start?&nbsp;</p>



<p><strong>XIE: </strong>Yeah, I think one of the biggest challenges our human society is going to face, right, in the next 20 years is going to be climate change, right, and there are so many materials design problems people need to solve in order to properly handle climate change, like finding new materials that can absorb CO<sub>2</sub> from atmosphere to create a carbon capture industry or have a battery materials that is able to do large-scale energy grid storage so that we can fully utilizing all the wind powers and the solar power, etc., right. So if you want me to make <em>one</em> prediction, I really believe that these AI tools, like MatterGen and MatterSim, is going to play a central role in our human&#8217;s ability to design these new materials for climate problems. So therefore in 20 years, I would like to see we have already solved climate change, right. We have large-scale energy storage systems that was designed by AI that is … basically that we have removed all the fossil fuels, right, from our energy production, and for the rest of the carbon emissions that is very hard to remove, we will have a carbon capture industry with materials designed by AI that absorbs the CO<sub>2</sub> from the atmosphere. It&#8217;s hard to predict exactly what will happen, but I think AI will play a key role, right, into defining how our society will look like in 20 years.&nbsp;</p>



<p><strong>LU: </strong>Tian, very well said. So I think instead of really describing the future, I would really quote a science fiction scene in <em>Iron Man</em>. So basically in 20 years, I will say when we want to really get a new material, we will just sit in an office and say, “Well, J.A.R.V.I.S., can you design us a new material that really fits my newest MK 7 suit?” That will be the end. And it will run automatically, and we get this auto lab running, and all those MatterGen and MatterSim, these AI models, running, and then probably in a few hours, in a few days, we get the material.&nbsp;</p>



<p><strong>KALTER: </strong>Well, I think I speak for many people from several industries when I say that I cannot wait to see what is on the horizon for these projects. Tian and Ziheng, thank you so much for joining us on <em>Ideas</em>. It&#8217;s been a pleasure.&nbsp;</p>



<p>[MUSIC]&nbsp;</p>



<p><strong>XIE: </strong>Thank you so much.&nbsp;</p>



<p><strong>LU: </strong>Thank you.&nbsp;</p>



<p>[MUSIC FADES]</p>

				</span>
			</div>
			<button
				class="action-trigger glyph-prepend mt-2 mb-0 show-more-show-less-toggle"
				aria-expanded="false"
				data-show-less-text="Show less"
				type="button"
				aria-controls="show-more-show-less-toggle-12"
				aria-label="Show more content"
				data-alternate-aria-label="Show less content">
				Show more			</button>
		</div>
	</div>
</div>



<hr class="wp-block-separator has-alpha-channel-opacity"/>



<p id="footnote1"><a id="_ftn1" href="#_ftnref1">[1]<span class="sr-only"> (opens in new tab)</span></a> Learn more about MatterGen and the new material tantalum chromium oxide in the <em>Nature</em> paper “<a class="msr-external-link glyph-append glyph-append-open-in-new-tab glyph-append-xsmall" href="https://www.nature.com/articles/s41586-025-08628-5" target="_blank" rel="noreferrer noopener">A generative model for inorganic materials design<span class="sr-only"> (opens in new tab)</span></a>.”</p>
<span id="label-external-link" class="sr-only" aria-hidden="true">Opens in a new tab</span><p>The post <a href="https://www.microsoft.com/en-us/research/podcast/ideas-ai-for-materials-discovery-with-tian-xie-and-ziheng-lu/">Ideas: AI for materials discovery with Tian Xie and Ziheng Lu</a> appeared first on <a href="https://www.microsoft.com/en-us/research">Microsoft Research</a>.</p>
]]></content:encoded>
					
		
		
			</item>
		<item>
		<title>MatterGen: A new paradigm of materials design with generative AI </title>
		<link>https://www.microsoft.com/en-us/research/blog/mattergen-a-new-paradigm-of-materials-design-with-generative-ai/</link>
		
		<dc:creator><![CDATA[Alyssa Hughes (2ADAPTIVE LLC dba 2A Consulting)]]></dc:creator>
		<pubDate>Thu, 16 Jan 2025 10:05:45 +0000</pubDate>
				<category><![CDATA[Research Blog]]></category>
		<guid isPermaLink="false">https://www.microsoft.com/en-us/research/?p=1117392</guid>

					<description><![CDATA[<p>Microsoft researchers introduce MatterGen, a model that can discover new materials tailored to specific needs—like efficient solar cells or CO2 recycling—advancing progress beyond trial-and-error experiments.</p>
<p>The post <a href="https://www.microsoft.com/en-us/research/blog/mattergen-a-new-paradigm-of-materials-design-with-generative-ai/">MatterGen: A new paradigm of materials design with generative AI </a> appeared first on <a href="https://www.microsoft.com/en-us/research">Microsoft Research</a>.</p>
]]></description>
										<content:encoded><![CDATA[
<figure class="wp-block-image size-full"><img loading="lazy" decoding="async" width="1400" height="788" src="https://www.microsoft.com/en-us/research/uploads/prod/2025/01/MatterGen-Technical-MSR-BLG-BlogHeroFeature-1400x788-1.jpg" alt="A grid of colorful, abstract shapes on a black background. Each cell in the grid features a unique three-dimensional geometric pattern, showcasing a variety of colors including green, red, blue, and purple." class="wp-image-1120326" srcset="https://www.microsoft.com/en-us/research/uploads/prod/2025/01/MatterGen-Technical-MSR-BLG-BlogHeroFeature-1400x788-1.jpg 1400w, https://www.microsoft.com/en-us/research/uploads/prod/2025/01/MatterGen-Technical-MSR-BLG-BlogHeroFeature-1400x788-1-300x169.jpg 300w, https://www.microsoft.com/en-us/research/uploads/prod/2025/01/MatterGen-Technical-MSR-BLG-BlogHeroFeature-1400x788-1-1024x576.jpg 1024w, https://www.microsoft.com/en-us/research/uploads/prod/2025/01/MatterGen-Technical-MSR-BLG-BlogHeroFeature-1400x788-1-768x432.jpg 768w, https://www.microsoft.com/en-us/research/uploads/prod/2025/01/MatterGen-Technical-MSR-BLG-BlogHeroFeature-1400x788-1-1066x600.jpg 1066w, https://www.microsoft.com/en-us/research/uploads/prod/2025/01/MatterGen-Technical-MSR-BLG-BlogHeroFeature-1400x788-1-655x368.jpg 655w, https://www.microsoft.com/en-us/research/uploads/prod/2025/01/MatterGen-Technical-MSR-BLG-BlogHeroFeature-1400x788-1-240x135.jpg 240w, https://www.microsoft.com/en-us/research/uploads/prod/2025/01/MatterGen-Technical-MSR-BLG-BlogHeroFeature-1400x788-1-640x360.jpg 640w, https://www.microsoft.com/en-us/research/uploads/prod/2025/01/MatterGen-Technical-MSR-BLG-BlogHeroFeature-1400x788-1-960x540.jpg 960w, https://www.microsoft.com/en-us/research/uploads/prod/2025/01/MatterGen-Technical-MSR-BLG-BlogHeroFeature-1400x788-1-1280x720.jpg 1280w" sizes="auto, (max-width: 1400px) 100vw, 1400px" /></figure>



<p>Materials innovation is one of the key drivers of major technological breakthroughs. The discovery of lithium cobalt oxide in the 1980s laid the groundwork for today’s lithium-ion battery technology. It now powers modern mobile phones and electric cars, impacting the daily lives of billions of people. Materials innovation is also required for designing more efficient solar cells, cheaper batteries for grid-level energy storage, and adsorbents to recycle CO2 from atmosphere.&nbsp;&nbsp;</p>



<p>Finding a new material for a target application is like finding a needle in a haystack. Historically, this task has been done via expensive and time-consuming experimental trial-and-error. More recently, computational screening of large materials databases has allowed researchers to speed up this process. Nonetheless, finding the few materials with the desired properties still requires the screening of millions of candidates.&nbsp;</p>



<p>Today, in a <a class="msr-external-link glyph-append glyph-append-open-in-new-tab glyph-append-xsmall" href="https://www.nature.com/articles/s41586-025-08628-5" target="_blank" rel="noreferrer noopener">paper published in <em>Nature</em><span class="sr-only"> (opens in new tab)</span></a>, we share MatterGen, a generative AI tool that tackles materials discovery from a different angle. Instead of screening the candidates, it directly generates novel materials given prompts of the design requirements for an application. It can generate materials with desired chemistry, mechanical, electronic, or magnetic properties, as well as combinations of different constraints. MatterGen enables a new paradigm of generative AI-assisted&nbsp;materials design that allows for efficient exploration of materials, going beyond the limited set of known ones.&nbsp;&nbsp;&nbsp;</p>



<figure class="wp-block-image aligncenter size-full is-resized"><img loading="lazy" decoding="async" width="1600" height="1053" src="https://www.microsoft.com/en-us/research/uploads/prod/2025/01/Screening-vs-Generation-Cartoon_1600px.jpg" alt="An illustration comparing screening and generation at the task of finding shapes that have a given number of edges and color. A blue pentagon is shown with a question mark at the top of the illustration, denoting this as the target for the task. To the left, a collection of colored shapes that does not include a blue pentagon is poured into a screening funnel. Two green pentagons pass through the funnel. To the right of the illustration, a laptop representing MatterGen inputs a target of 5 edges and the color blue.  Three green and one blue pentagon are produced in addition to a single blue hexagon." class="wp-image-1122780" style="width:615px;height:auto" srcset="https://www.microsoft.com/en-us/research/uploads/prod/2025/01/Screening-vs-Generation-Cartoon_1600px.jpg 1600w, https://www.microsoft.com/en-us/research/uploads/prod/2025/01/Screening-vs-Generation-Cartoon_1600px-300x197.jpg 300w, https://www.microsoft.com/en-us/research/uploads/prod/2025/01/Screening-vs-Generation-Cartoon_1600px-1024x674.jpg 1024w, https://www.microsoft.com/en-us/research/uploads/prod/2025/01/Screening-vs-Generation-Cartoon_1600px-768x505.jpg 768w, https://www.microsoft.com/en-us/research/uploads/prod/2025/01/Screening-vs-Generation-Cartoon_1600px-1536x1011.jpg 1536w, https://www.microsoft.com/en-us/research/uploads/prod/2025/01/Screening-vs-Generation-Cartoon_1600px-240x158.jpg 240w" sizes="auto, (max-width: 1600px) 100vw, 1600px" /><figcaption class="wp-element-caption"><em><em><em>Figure <em>1</em>: Schematic representation of screening and generative approaches to materials design&nbsp;</em></em></em></figcaption></figure>



<h2 class="wp-block-heading" id="a-novel-diffusion-architecture">A novel diffusion architecture&nbsp;</h2>



<p>MatterGen is a diffusion model that operates on the 3D geometry of materials. Much like an image diffusion model generates pictures from a text prompt by modifying the color of pixels from a noisy image, MatterGen generates proposed structures by adjusting the positions, elements, and periodic lattice from a random structure. The diffusion architecture is specifically designed for materials to handle specialties like periodicity and 3D geometry.&nbsp;&nbsp;</p>



<figure class="wp-block-image aligncenter size-full is-resized"><img loading="lazy" decoding="async" width="7754" height="6996" src="https://www.microsoft.com/en-us/research/uploads/prod/2025/01/illustrative_blog.png" alt="An illustration showing a two-dimensional crystal structure at various states in the reverse diffusion process from a random to a stable material (left to right). Three additional illustrations are shown for denoising processes that are conditioned on the chemistry, symmetry and magnetic density of the material. " class="wp-image-1117482" style="width:706px;height:auto" srcset="https://www.microsoft.com/en-us/research/uploads/prod/2025/01/illustrative_blog.png 7754w, https://www.microsoft.com/en-us/research/uploads/prod/2025/01/illustrative_blog-300x271.png 300w, https://www.microsoft.com/en-us/research/uploads/prod/2025/01/illustrative_blog-1024x924.png 1024w, https://www.microsoft.com/en-us/research/uploads/prod/2025/01/illustrative_blog-768x693.png 768w, https://www.microsoft.com/en-us/research/uploads/prod/2025/01/illustrative_blog-1536x1386.png 1536w, https://www.microsoft.com/en-us/research/uploads/prod/2025/01/illustrative_blog-2048x1848.png 2048w, https://www.microsoft.com/en-us/research/uploads/prod/2025/01/illustrative_blog-200x180.png 200w" sizes="auto, (max-width: 7754px) 100vw, 7754px" /><figcaption class="wp-element-caption"><em><em>Figure <em>2</em>: Schematic representation of MatterGen: a diffusion model to generate novel and stable materials. MatterGen can be fine-tuned <em>to</em> generate materials under different design requirements such as specific chemistry, crystal symmetry, or materials’ properties.&nbsp;&nbsp;</em></em></figcaption></figure>



<p>The base model of MatterGen achieves state-of-the-art performance in generating novel, stable, diverse materials (Figure 3). It is trained on 608,000 stable materials from the <a class="msr-external-link glyph-append glyph-append-open-in-new-tab glyph-append-xsmall" href="https://materialsproject.org/" target="_blank" rel="noreferrer noopener">Materials Project<span class="sr-only"> (opens in new tab)</span></a> (MP) and <a class="msr-external-link glyph-append glyph-append-open-in-new-tab glyph-append-xsmall" href="https://alexandria.icams.rub.de/" target="_blank" rel="noreferrer noopener">Alexandria<span class="sr-only"> (opens in new tab)</span></a> (Alex) databases. The performance improvement can be attributed to both the architecture advancements, as well as&nbsp;the quality and size of our training data.&nbsp;&nbsp;</p>



<figure class="wp-block-image aligncenter size-full is-resized"><img loading="lazy" decoding="async" width="3669" height="1447" src="https://www.microsoft.com/en-us/research/uploads/prod/2025/01/blog_performance_1.png" alt="A figure comparing the percentage of samples generated that are stable, novel and unique for several methods. From most performant to least performant, the figure ranks methods in order of MatterGen (alex-mp), MatterGen (mp), DiffCSP (mp), CDVAE (mp), P-G-SchNet (mp), G-SchNet (mp), FTCP (mp). " class="wp-image-1117491" style="width:646px;height:auto" srcset="https://www.microsoft.com/en-us/research/uploads/prod/2025/01/blog_performance_1.png 3669w, https://www.microsoft.com/en-us/research/uploads/prod/2025/01/blog_performance_1-300x118.png 300w, https://www.microsoft.com/en-us/research/uploads/prod/2025/01/blog_performance_1-1024x404.png 1024w, https://www.microsoft.com/en-us/research/uploads/prod/2025/01/blog_performance_1-768x303.png 768w, https://www.microsoft.com/en-us/research/uploads/prod/2025/01/blog_performance_1-1536x606.png 1536w, https://www.microsoft.com/en-us/research/uploads/prod/2025/01/blog_performance_1-2048x808.png 2048w, https://www.microsoft.com/en-us/research/uploads/prod/2025/01/blog_performance_1-240x95.png 240w" sizes="auto, (max-width: 3669px) 100vw, 3669px" /><figcaption class="wp-element-caption"><em><em>Figure <em>3</em>: Performance of MatterGen and other methods in the generation of stable, unique, and novel structures. The training dataset for each method is indicated in parentheses. The purple bar highlights performance improvements due to MatterGen’s architecture alone, while the teal bar highlights performance improvements that come also from the larger training dataset.&nbsp;</em></em></figcaption></figure>



<p>MatterGen can be fine-tuned with a labelled dataset to generate novel materials given any desired conditions. We demonstrate examples of generating novel materials given a target’s chemistry and symmetry, as well as electronic, magnetic, and mechanical property constraints (Figure 2). &nbsp;</p>



<h2 class="wp-block-heading" id="outperforming-screening">Outperforming screening&nbsp;</h2>



<figure class="wp-block-image aligncenter size-full is-resized"><img loading="lazy" decoding="async" width="3699" height="1658" src="https://www.microsoft.com/en-us/research/uploads/prod/2025/01/blog_performance_2.png" alt="A figure comparing MatterGen and traditional screening in the task of generating stable, unique and novel structures with a bulk modulus greater than 400 giga pascal. The figure shows that the number of such structures discovered with screening plateaus at approximately 40, while for MatterGen this number continues to increase to above 100 for 175 density functional theory calculations. " class="wp-image-1117500" style="width:637px;height:auto" srcset="https://www.microsoft.com/en-us/research/uploads/prod/2025/01/blog_performance_2.png 3699w, https://www.microsoft.com/en-us/research/uploads/prod/2025/01/blog_performance_2-300x134.png 300w, https://www.microsoft.com/en-us/research/uploads/prod/2025/01/blog_performance_2-1024x459.png 1024w, https://www.microsoft.com/en-us/research/uploads/prod/2025/01/blog_performance_2-768x344.png 768w, https://www.microsoft.com/en-us/research/uploads/prod/2025/01/blog_performance_2-1536x688.png 1536w, https://www.microsoft.com/en-us/research/uploads/prod/2025/01/blog_performance_2-2048x918.png 2048w, https://www.microsoft.com/en-us/research/uploads/prod/2025/01/blog_performance_2-240x108.png 240w" sizes="auto, (max-width: 3699px) 100vw, 3699px" /><figcaption class="wp-element-caption"><em><em><em>Figure <em>4</em>: Performance of MatterGen (teal) and traditional screening (yellow) in finding novel, stable, and unique structures that satisfy the design requirement of having bulk modulus greater than 400 GPa.&nbsp;</em></em></em></figcaption></figure>



<p>The key advantage of MatterGen over screening is its ability to access the full space of unknown materials. In Figure 4, we show that MatterGen continues to generate more novel candidate materials with high bulk modulus above 400 GPa, for example, which are hard to compress. In contrast, screening baseline saturates due to exhausting known candidates.&nbsp;&nbsp;</p>



	<div class="border-bottom border-top border-gray-300 mt-5 mb-5 msr-promo text-center text-md-left alignwide" data-bi-aN="promo" data-bi-id="1085520">
		

		<p class="msr-promo__label text-gray-800 text-center text-uppercase">
		<span class="px-4 bg-white display-inline-block font-weight-semibold small">Microsoft research podcast</span>
	</p>
	
	<div class="row pt-3 pb-4 align-items-center">
						<div class="msr-promo__media col-12 col-md-5">
				<a class="bg-gray-300" href="https://www.microsoft.com/en-us/research/podcast/collaborators-silica-in-space-with-richard-black-and-dexter-greene/" aria-label="Collaborators: Silica in space with Richard Black and Dexter Greene" data-bi-cN="Collaborators: Silica in space with Richard Black and Dexter Greene" target="_blank">
					<img decoding="async" class="w-100 display-block" src="https://www.microsoft.com/en-us/research/uploads/prod/2024/09/Richard-and-Dexter_Collaborators_Hero_Feature_No_Text_1400x788-1.jpg" alt="Headshots of Richard Black and Dexter Greene for the Microsoft Research Podcast" />
				</a>
			</div>
			
			<div class="msr-promo__content p-3 px-5 col-12 col-md">

									<h2 class="h4">Collaborators: Silica in space with Richard Black and Dexter Greene</h2>
				
								<p class="large">College freshman Dexter Greene and Microsoft research manager Richard Black discuss how technology that stores data in glass is supporting students as they expand earlier efforts to communicate what it means to be human to extraterrestrials.</p>
				
								<div class="wp-block-buttons justify-content-center justify-content-md-start">
					<div class="wp-block-button">
						<a href="https://www.microsoft.com/en-us/research/podcast/collaborators-silica-in-space-with-richard-black-and-dexter-greene/" class="btn btn-brand glyph-append glyph-append-chevron-right" aria-label="Listen now" data-bi-cN="Collaborators: Silica in space with Richard Black and Dexter Greene" target="_blank">
							Listen now						</a>
					</div>
				</div>
							</div><!--/.msr-promo__content-->
	</div><!--/.msr-promo__inner-wrap-->
<span id="label-external-link" class="sr-only" aria-hidden="true">Opens in a new tab</span>	</div><!--/.msr-promo-->
	


<h2 class="wp-block-heading" id="handling-compositional-disorder">Handling compositional disorder&nbsp;</h2>



<figure class="wp-block-image aligncenter size-full is-resized"><img loading="lazy" decoding="async" width="9935" height="3904" src="https://www.microsoft.com/en-us/research/uploads/prod/2025/01/blog_disorder.png" alt="An illustration of a two-dimensional cubic crystal lattice containing two distinct atom types. The primitive cell is ordered and each atomic site is occupied by a single atom type. Another crystal lattice is shown to the right and is compositionally disordered such that each atom site contains either atom type with a probability of one half. " class="wp-image-1117506" style="width:610px;height:auto" srcset="https://www.microsoft.com/en-us/research/uploads/prod/2025/01/blog_disorder.png 9935w, https://www.microsoft.com/en-us/research/uploads/prod/2025/01/blog_disorder-300x118.png 300w, https://www.microsoft.com/en-us/research/uploads/prod/2025/01/blog_disorder-1024x402.png 1024w, https://www.microsoft.com/en-us/research/uploads/prod/2025/01/blog_disorder-768x302.png 768w, https://www.microsoft.com/en-us/research/uploads/prod/2025/01/blog_disorder-1536x604.png 1536w, https://www.microsoft.com/en-us/research/uploads/prod/2025/01/blog_disorder-2048x805.png 2048w, https://www.microsoft.com/en-us/research/uploads/prod/2025/01/blog_disorder-240x94.png 240w" sizes="auto, (max-width: 9935px) 100vw, 9935px" /><figcaption class="wp-element-caption"><em><em>Figure <em>5</em>: Illustration of compositional disorder. Left: a perfect crystal without compositional disorder and with a repeating unit cell (black dashed). Right: crystal with compositional disorder, where each site has 50% probability of yellow and teal atoms.&nbsp;</em></em></figcaption></figure>



<p>Compositional disorder (Figure 5) is a commonly observed phenomenon where different atoms can randomly swap their crystallographic sites in a synthesized material. <a class="msr-external-link glyph-append glyph-append-open-in-new-tab glyph-append-xsmall" href="https://journals.aps.org/prxenergy/abstract/10.1103/PRXEnergy.3.011002" target="_blank" rel="noreferrer noopener">Recently<span class="sr-only"> (opens in new tab)</span></a>, the community has been exploring what it means for a material to be novel in the context of computationally designed materials, as widely employed algorithms will not distinguish between pairs of structures where the only difference is a permutation of similar elements in their respective sites.</p>



<p>We provide an initial solution to this issue by introducing a new structure matching algorithm that considers compositional disorder. The algorithm assesses whether a pair of structures can be identified as ordered approximations of the same underlying compositionally disordered structure. This provides a new definition of novelty and uniqueness, which we adopt in our computational evaluation metrics. We also make our <a class="msr-external-link glyph-append glyph-append-open-in-new-tab glyph-append-xsmall" href="https://github.com/microsoft/mattergen?tab=readme-ov-file#evaluation" target="_blank" rel="noreferrer noopener">algorithm publicly available<span class="sr-only"> (opens in new tab)</span></a> as part of our evaluation package.&nbsp;</p>



<h2 class="wp-block-heading" id="experimental-lab-verification">Experimental lab verification&nbsp;</h2>



<figure class="wp-block-image aligncenter size-full is-resized"><img loading="lazy" decoding="async" width="1796" height="1202" src="https://www.microsoft.com/en-us/research/uploads/prod/2025/01/Experimental-validation-modified.png" alt="A photo that shows a scientist in a laboratory working at a bench and holding a small sample with tweezers. " class="wp-image-1117515" style="width:706px;height:auto" srcset="https://www.microsoft.com/en-us/research/uploads/prod/2025/01/Experimental-validation-modified.png 1796w, https://www.microsoft.com/en-us/research/uploads/prod/2025/01/Experimental-validation-modified-300x201.png 300w, https://www.microsoft.com/en-us/research/uploads/prod/2025/01/Experimental-validation-modified-1024x685.png 1024w, https://www.microsoft.com/en-us/research/uploads/prod/2025/01/Experimental-validation-modified-768x514.png 768w, https://www.microsoft.com/en-us/research/uploads/prod/2025/01/Experimental-validation-modified-1536x1028.png 1536w, https://www.microsoft.com/en-us/research/uploads/prod/2025/01/Experimental-validation-modified-240x161.png 240w" sizes="auto, (max-width: 1796px) 100vw, 1796px" /><figcaption class="wp-element-caption"><em><em><em><em><em>Figure 6: Experimental validation of the proposed compound, TaCr2O6&nbsp;</em>&nbsp;</em></em></em></em></figcaption></figure>



<p>In addition to our extensive computational evaluation, we have validated MatterGen’s capabilities through experimental synthesis. In collaboration with the team led by Prof Li Wenjie from the <a class="msr-external-link glyph-append glyph-append-open-in-new-tab glyph-append-xsmall" href="https://suat-sz.edu.cn/en/" target="_blank" rel="noreferrer noopener">Shenzhen Institutes of Advanced Technology<span class="sr-only"> (opens in new tab)</span></a> (SIAT) of the Chinese Academy of Sciences, we have synthesized a novel material, TaCr2O6, whose structure was generated by MatterGen after conditioning the model on a bulk modulus value of 200 GPa. The synthesized material’s structure aligns with the one proposed by MatterGen, with the caveat of compositional disorder between Ta and Cr. Additionally, we experimentally measure a bulk modulus of 169 GPa against the 200 GPa given as design specification, with a relative error below 20%, very close from an experimental perspective. If similar results can be translated to other domains, it will have a profound impact on the design of batteries, fuel cells, and more. &nbsp;</p>



<h2 class="wp-block-heading" id="ai-emulator-and-generator-flywheel">AI emulator and generator flywheel&nbsp;</h2>



<p>MatterGen presents a new opportunity for AI accelerated materials design, complementing our AI emulator <a href="https://www.microsoft.com/en-us/research/blog/mattersim-a-deep-learning-model-for-materials-under-real-world-conditions/" target="_blank" rel="noreferrer noopener">MatterSim</a>. MatterSim follows the <a href="https://www.microsoft.com/en-us/research/blog/ai4science-to-empower-the-fifth-paradigm-of-scientific-discovery/" target="_blank" rel="noreferrer noopener">fifth paradigm</a> of scientific discovery, significantly accelerating the speed of material properties’ simulations. MatterGen in turn accelerates the speed of exploring new material candidates with property guided generation. <a href="https://www.microsoft.com/en-us/research/story/ai-meets-materials-discovery/">MatterGen and MatterSim can work together</a> as a flywheel to speed up both the simulation and exploration of novel materials.</p>



<h2 class="wp-block-heading" id="making-mattergen-available">Making MatterGen available&nbsp;</h2>



<p>We believe the best way to make an impact in materials design is to make our model available to the public. We release the <a class="msr-external-link glyph-append glyph-append-open-in-new-tab glyph-append-xsmall" href="https://github.com/microsoft/mattergen" target="_blank" rel="noreferrer noopener">source code of MatterGen<span class="sr-only"> (opens in new tab)</span></a> under the MIT license, together with the training and fine-tuning data. We welcome the community to use and build on top of our model.&nbsp;&nbsp;</p>



<h2 class="wp-block-heading" id="looking-ahead">Looking ahead&nbsp;</h2>



<p>MatterGen represents a new paradigm of materials design enabled by generative AI technology. It explores a significantly larger space of materials than screening-based methods. It is also more efficient by guiding materials exploration with prompts. Similar to <a class="msr-external-link glyph-append glyph-append-open-in-new-tab glyph-append-xsmall" href="https://news.microsoft.com/source/features/digital-transformation/novartis-empowers-scientists-ai-speed-discovery-development-breakthrough-medicines/" target="_blank" rel="noreferrer noopener">how generative AI has impacted drug discovery<span class="sr-only"> (opens in new tab)</span></a>, it will have profound impact on how we design materials in broad domains including batteries, magnets, and fuel cells.&nbsp;</p>



<p>We plan to continue our work with external collaborators to further develop and validate the technology. “At the Johns Hopkins University Applied Physics Laboratory (APL), we’re dedicated to the exploration of tools with the potential to advance discovery of novel, mission-enabling materials. That&#8217;s why we are interested in understanding the impact that MatterGen could have on materials discovery,” said Christopher Stiles, a computational materials scientists leading multiple materials discovery efforts at APL.</p>



<h2 class="wp-block-heading" id="acknowledgement">Acknowledgement&nbsp;</h2>



<p>This work is the result of highly collaborative team efforts at <a href="https://www.microsoft.com/en-us/research/lab/microsoft-research-ai-for-science/">Microsoft Research AI for Science</a>. The full authors include: <a href="https://www.microsoft.com/en-us/research/people/claudiozeni/" target="_blank" rel="noreferrer noopener">Claudio Zeni</a>, <a href="https://www.microsoft.com/en-us/research/people/rpinsler/" target="_blank" rel="noreferrer noopener">Robert Pinsler</a>, <a href="https://www.microsoft.com/en-us/research/people/dzuegner/" target="_blank" rel="noreferrer noopener">Daniel Zügner</a>, <a href="https://www.microsoft.com/en-us/research/people/fowlerandrew/" target="_blank" rel="noreferrer noopener">Andrew Fowler</a>, <a href="https://www.microsoft.com/en-us/research/people/mahorton/" target="_blank" rel="noreferrer noopener">Matthew Horton</a>, Xiang Fu, <a href="https://www.microsoft.com/en-us/research/people/wangzilong/">Zilong Wang</a>, Aliaksandra Shysheya, Jonathan Crabbé, <a href="https://www.microsoft.com/en-us/research/people/shokoueda/">Shoko Ueda</a>, Roberto Sordillo, <a href="https://www.microsoft.com/en-us/research/people/lixinsun/">Lixin Sun</a>, <a href="https://www.microsoft.com/en-us/research/people/jakesmith/">Jake Smith</a>, <a href="https://www.microsoft.com/en-us/research/people/bnguy/">Bichlien Nguyen</a>, <a href="https://www.microsoft.com/en-us/research/people/haschulz/">Hannes Schulz</a>, <a href="https://www.microsoft.com/en-us/research/people/sarahlewis/">Sarah Lewis</a>, <a href="https://www.microsoft.com/en-us/research/people/chinweihuang/">Chin-Wei Huang</a>, <a href="https://www.microsoft.com/en-us/research/people/zihenglu/">Ziheng Lu</a>, Yichi Zhou, <a href="https://www.microsoft.com/en-us/research/people/hanyang/">Han Yang</a>, <a href="https://www.microsoft.com/en-us/research/people/hongxiahao/">Hongxia Hao</a>, <a href="https://www.microsoft.com/en-us/research/people/jielanli/">Jielan Li</a>, Chunlei Yang, Wenjie Li, <a href="https://www.microsoft.com/en-us/research/people/ryoto/">Ryota Tomioka</a>, <a href="https://www.microsoft.com/en-us/research/people/tianxie/">Tian Xie</a>.&nbsp;&nbsp;</p>
<span id="label-external-link" class="sr-only" aria-hidden="true">Opens in a new tab</span><p>The post <a href="https://www.microsoft.com/en-us/research/blog/mattergen-a-new-paradigm-of-materials-design-with-generative-ai/">MatterGen: A new paradigm of materials design with generative AI </a> appeared first on <a href="https://www.microsoft.com/en-us/research">Microsoft Research</a>.</p>
]]></content:encoded>
					
		
		
			</item>
		<item>
		<title>AutoGen v0.4: Reimagining the foundation of agentic AI for scale, extensibility, and robustness</title>
		<link>https://www.microsoft.com/en-us/research/blog/autogen-v0-4-reimagining-the-foundation-of-agentic-ai-for-scale-extensibility-and-robustness/</link>
		
		<dc:creator><![CDATA[Alyssa Hughes (2ADAPTIVE LLC dba 2A Consulting)]]></dc:creator>
		<pubDate>Tue, 14 Jan 2025 14:33:09 +0000</pubDate>
				<category><![CDATA[Research Blog]]></category>
		<guid isPermaLink="false">https://www.microsoft.com/en-us/research/?p=1116288</guid>

					<description><![CDATA[<p>Announcing AutoGen 0.4, fully reimagined library for building advanced agentic AI systems, developed to improve code quality and robustness. Its asynchronous, event-driven architecture is designed to support dynamic, scalable workflows.</p>
<p>The post <a href="https://www.microsoft.com/en-us/research/blog/autogen-v0-4-reimagining-the-foundation-of-agentic-ai-for-scale-extensibility-and-robustness/">AutoGen v0.4: Reimagining the foundation of agentic AI for scale, extensibility, and robustness</a> appeared first on <a href="https://www.microsoft.com/en-us/research">Microsoft Research</a>.</p>
]]></description>
										<content:encoded><![CDATA[
<figure class="wp-block-image size-large"><img loading="lazy" decoding="async" width="1024" height="576" src="https://www.microsoft.com/en-us/research/uploads/prod/2025/01/AutoGen-0.4-BlogHeroFeature-1400x788-1-1024x576.jpg" alt="The v0.4 update introduces a cohesive AutoGen ecosystem that includes the framework, developer tools, and applications. The framework’s layered architecture clearly defines each layer’s functionality. It supports both first-party and third-party applications and extensions." class="wp-image-1120017" srcset="https://www.microsoft.com/en-us/research/uploads/prod/2025/01/AutoGen-0.4-BlogHeroFeature-1400x788-1-1024x576.jpg 1024w, https://www.microsoft.com/en-us/research/uploads/prod/2025/01/AutoGen-0.4-BlogHeroFeature-1400x788-1-300x169.jpg 300w, https://www.microsoft.com/en-us/research/uploads/prod/2025/01/AutoGen-0.4-BlogHeroFeature-1400x788-1-768x432.jpg 768w, https://www.microsoft.com/en-us/research/uploads/prod/2025/01/AutoGen-0.4-BlogHeroFeature-1400x788-1-1066x600.jpg 1066w, https://www.microsoft.com/en-us/research/uploads/prod/2025/01/AutoGen-0.4-BlogHeroFeature-1400x788-1-655x368.jpg 655w, https://www.microsoft.com/en-us/research/uploads/prod/2025/01/AutoGen-0.4-BlogHeroFeature-1400x788-1-240x135.jpg 240w, https://www.microsoft.com/en-us/research/uploads/prod/2025/01/AutoGen-0.4-BlogHeroFeature-1400x788-1-640x360.jpg 640w, https://www.microsoft.com/en-us/research/uploads/prod/2025/01/AutoGen-0.4-BlogHeroFeature-1400x788-1-960x540.jpg 960w, https://www.microsoft.com/en-us/research/uploads/prod/2025/01/AutoGen-0.4-BlogHeroFeature-1400x788-1-1280x720.jpg 1280w, https://www.microsoft.com/en-us/research/uploads/prod/2025/01/AutoGen-0.4-BlogHeroFeature-1400x788-1.jpg 1400w" sizes="auto, (max-width: 1024px) 100vw, 1024px" /></figure>



<p>Over the past year, our work on <a href="https://www.microsoft.com/en-us/research/project/autogen/" target="_blank" rel="noreferrer noopener">AutoGen</a> has highlighted the transformative potential of agentic AI and multi-agent applications. Today, we are excited to announce AutoGen v0.4, a significant milestone informed by insights from our community of users and developers. This update represents a complete redesign of the AutoGen library, developed to improve code quality, robustness, generality, and scalability in agentic workflows.&nbsp;</p>



<p>The initial release of <a href="https://www.microsoft.com/en-us/research/publication/autogen-enabling-next-gen-llm-applications-via-multi-agent-conversation-framework/" target="_blank" rel="noreferrer noopener">AutoGen</a> generated widespread interest in agentic technologies. At the same time, users struggled with architectural constraints, an inefficient API compounded by rapid growth, and limited debugging and intervention functionality. Feedback highlighted the need for stronger observability and control, more flexible multi-agent collaboration patterns, and reusable components. AutoGen v0.4 addresses these issues with its <strong>asynchronous, event-driven architecture</strong>.&nbsp;</p>



<p>This update makes AutoGen more robust and extensible, enabling a broader range of agentic scenarios. The new framework includes the following features, inspired by feedback from both within and outside Microsoft.&nbsp;&nbsp;</p>



<ul class="wp-block-list">
<li><strong>Asynchronous messaging</strong>: Agents communicate through asynchronous messages, supporting both event-driven and request/response interaction patterns.&nbsp;</li>



<li><strong>Modular and extensible</strong>: Users can easily customize systems with pluggable components, including custom agents, tools, memory, and models. They can also build proactive and long-running agents using event-driven patterns.&nbsp;</li>



<li><strong>Observability and debugging</strong>: Built-in metric tracking, message tracing, and debugging tools provide monitoring and control over agent interactions and workflows, with support for OpenTelemetry for industry-standard observability.&nbsp;</li>



<li><strong>Scalable and distributed</strong>: Users can design complex, distributed agent networks that operate seamlessly across organizational boundaries.&nbsp;</li>



<li><strong>Built-in and community extensions</strong>: The extensions module enhances the framework’s functionality with advanced model clients, agents, multi-agent teams, and tools for agentic workflows. Community support allows open-source developers to manage their own extensions.&nbsp;</li>



<li><strong>Cross-language support</strong>: This update enables interoperability between agents built in different programming languages, with current support for Python and .NET and additional languages in development.&nbsp;</li>



<li><strong>Full type support</strong>: Interfaces enforce type checks at build time, improving robustness and maintaining code quality.</li>
</ul>



	<div class="border-bottom border-top border-gray-300 mt-5 mb-5 msr-promo text-center text-md-left alignwide" data-bi-aN="promo" data-bi-id="1115757">
		

		<p class="msr-promo__label text-gray-800 text-center text-uppercase">
		<span class="px-4 bg-white display-inline-block font-weight-semibold small">Microsoft research podcast</span>
	</p>
	
	<div class="row pt-3 pb-4 align-items-center">
						<div class="msr-promo__media col-12 col-md-5">
				<a class="bg-gray-300" href="https://www.microsoft.com/en-us/research/podcast/ideas-ai-and-democracy-with-madeleine-daepp-and-robert-osazuwa-ness/" aria-label="Ideas: AI and democracy with Madeleine Daepp and Robert Osazuwa Ness" data-bi-cN="Ideas: AI and democracy with Madeleine Daepp and Robert Osazuwa Ness" target="_blank">
					<img decoding="async" class="w-100 display-block" src="https://www.microsoft.com/en-us/research/uploads/prod/2024/12/NEWGinny-Madeleine-and-Robert_Ideas_Hero_Feature_No_Text_1400x788.jpg" alt="Illustrated headshots of Ginny Badanes, Madeleine Daepp and Robert Ness" />
				</a>
			</div>
			
			<div class="msr-promo__content p-3 px-5 col-12 col-md">

									<h2 class="h4">Ideas: AI and democracy with Madeleine Daepp and Robert Osazuwa Ness</h2>
				
								<p class="large">As the “biggest election year in history” comes to an end, researchers Madeleine Daepp and Robert Osazuwa Ness and Democracy Forward GM Ginny Badanes discuss AI’s impact on democracy, including the tech’s use in Taiwan and India.</p>
				
								<div class="wp-block-buttons justify-content-center justify-content-md-start">
					<div class="wp-block-button">
						<a href="https://www.microsoft.com/en-us/research/podcast/ideas-ai-and-democracy-with-madeleine-daepp-and-robert-osazuwa-ness/" class="btn btn-brand glyph-append glyph-append-chevron-right" aria-label="Listen now" data-bi-cN="Ideas: AI and democracy with Madeleine Daepp and Robert Osazuwa Ness" target="_blank">
							Listen now						</a>
					</div>
				</div>
							</div><!--/.msr-promo__content-->
	</div><!--/.msr-promo__inner-wrap-->
<span id="label-external-link" class="sr-only" aria-hidden="true">Opens in a new tab</span>	</div><!--/.msr-promo-->
	


<h2 class="wp-block-heading" id="new-autogen-framework">New AutoGen framework</h2>



<p>As shown in Figure 1, the AutoGen framework features a layered architecture with clearly defined responsibilities across the framework, developer tools, and applications. The framework comprises three layers: core, agent chat, and first-party extensions.&nbsp;&nbsp;</p>



<ul class="wp-block-list">
<li><strong>Core: </strong>The foundational building blocks for an event-driven agentic system.</li>



<li><strong>AgentChat:</strong> A task-driven, high-level API built on the core layer, featuring group chat, code execution, pre-built agents, and more. This layer is most similar to <a class="msr-external-link glyph-append glyph-append-open-in-new-tab glyph-append-xsmall" href="http://aka.ms/autogen" target="_blank" rel="noreferrer noopener">AutoGen v0.2<span class="sr-only"> (opens in new tab)</span></a>, making it the easiest API to migrate to.</li>



<li><strong>Extensions:</strong> Implementations of core interfaces and third-party integrations, such as the Azure code executor and OpenAI model client.</li>
</ul>



<figure class="wp-block-image aligncenter size-full is-resized"><img loading="lazy" decoding="async" width="865" height="530" src="https://www.microsoft.com/en-us/research/uploads/prod/2025/01/Fig1-v0.4.png" alt="Figure 1. The v0.4 update introduces a cohesive AutoGen ecosystem that includes the framework, developer tools, and applications. The framework’s layered architecture clearly defines each layer’s functionality. It supports both first-party and third-party applications and extensions." class="wp-image-1116330" style="width:649px;height:auto" srcset="https://www.microsoft.com/en-us/research/uploads/prod/2025/01/Fig1-v0.4.png 865w, https://www.microsoft.com/en-us/research/uploads/prod/2025/01/Fig1-v0.4-300x184.png 300w, https://www.microsoft.com/en-us/research/uploads/prod/2025/01/Fig1-v0.4-768x471.png 768w, https://www.microsoft.com/en-us/research/uploads/prod/2025/01/Fig1-v0.4-240x147.png 240w" sizes="auto, (max-width: 865px) 100vw, 865px" /><figcaption class="wp-element-caption">Figure 1. The v0.4 update introduces a cohesive AutoGen ecosystem that includes the framework, developer tools, and applications. The framework’s layered architecture clearly defines each layer’s functionality. It supports both first-party and third-party applications and extensions.&nbsp;</figcaption></figure>



<h2 class="wp-block-heading" id="developer-tools">Developer tools</h2>



<p>In addition to the framework, AutoGen 0.4 includes upgraded programming tools and applications, designed to support developers in building and experimenting with AutoGen.&nbsp;</p>



<p><strong><a class="msr-external-link glyph-append glyph-append-open-in-new-tab glyph-append-xsmall" href="http://aka.ms/autogen-bench" target="_blank" rel="noreferrer noopener">AutoGen Bench<span class="sr-only"> (opens in new tab)</span></a>: </strong>Enables developers to benchmark their agents by measuring and comparing performance across tasks and environments. </p>



<p><strong><a class="msr-external-link glyph-append glyph-append-open-in-new-tab glyph-append-xsmall" href="http://aka.ms/autogen-studio" target="_blank" rel="noreferrer noopener">AutoGen Studio<span class="sr-only"> (opens in new tab)</span></a>: </strong>Rebuilt on the v0.4 AgentChat API, this low-code interface enables rapid prototyping of AI agents. It introduces several new capabilities: </p>



<ul class="wp-block-list">
<li><strong>Real-time agent updates: </strong>View agent action streams in real time with asynchronous, event-driven messages.&nbsp;&nbsp;</li>



<li><strong>Mid-execution control:</strong> Pause conversations, redirect agent actions, and adjust team composition. Then seamlessly resume tasks.&nbsp;</li>



<li><strong>Interactive feedback through the UI: </strong>Add a UserProxyAgent to enable user input and guidance during team runs in real time.&nbsp;</li>



<li><strong>Message flow visualization:</strong> Understand agent communication through an intuitive visual interface that maps message paths and dependencies.&nbsp;</li>



<li><strong>Drag-and-drop team builder:</strong> Design agent teams visually using an interface for dragging components into place and configuring their relationships and properties.&nbsp;</li>



<li><strong>Third-party component galleries:</strong> Import and use custom agents, tools, and workflows from external galleries to extend functionality.&nbsp;</li>
</ul>



<p><strong><a href="https://www.microsoft.com/en-us/research/articles/magentic-one-a-generalist-multi-agent-system-for-solving-complex-tasks/">Magentic-One</a>:</strong> A new generalist multi-agent application to solve open-ended web and file-based tasks across various domains. This tool marks a significant step toward creating agents capable of completing tasks commonly encountered in both work and personal contexts.</p>



<h2 class="wp-block-heading" id="migrating-to-autogen-v0-4">Migrating to AutoGen v0.4</h2>



<p>We implemented several measures to facilitate a smooth upgrade from the previous v0.2 API, addressing core differences in the underlying architecture.&nbsp;</p>



<p>First, the AgentChat API maintains the same level of abstraction as v0.2, making it easy to migrate existing code to v0.4. For example, AgentChat offers an AssistantAgent and UserProxy agent with similar behaviors to those in v0.2. It also provides a team interface with implementations like RoundRobinGroupChat and SelectorGroupChat, which cover all the capabilities of the GroupChat class in v0.2. Additionally, v0.4 introduces many new functionalities, such as streaming messages, improved observability, saving and restoring task progress, and resuming paused actions where they left off. &nbsp;</p>



<p>For detailed guidance, refer to the <a class="msr-external-link glyph-append glyph-append-open-in-new-tab glyph-append-xsmall" href="https://aka.ms/autogen-migrate" target="_blank" rel="noreferrer noopener">migration guide<span class="sr-only"> (opens in new tab)</span></a>.</p>



<h2 class="wp-block-heading" id="looking-forward">Looking forward</h2>



<p>This new release sets the stage for a robust ecosystem and strong foundation to drive advances in agentic AI application and research. Our roadmap includes releasing .NET support, introducing built-in, well-designed applications and extensions for challenging domains, and fostering a community-driven ecosystem. We remain committed to the responsible development of AutoGen and its evolving capabilities.&nbsp;</p>



<p>We encourage you to engage with us on <a class="msr-external-link glyph-append glyph-append-open-in-new-tab glyph-append-xsmall" href="https://aka.ms/autogen-discord" target="_blank" rel="noreferrer noopener">AutoGen’s Discord server<span class="sr-only"> (opens in new tab)</span></a> and share feedback on the official <a class="msr-external-link glyph-append glyph-append-open-in-new-tab glyph-append-xsmall" href="https://github.com/microsoft/autogen" target="_blank" rel="noreferrer noopener">AutoGen repository<span class="sr-only"> (opens in new tab)</span></a> via GitHub Issues. &nbsp;Stay up to date with frequent AutoGen updates via <a class="msr-external-link glyph-append glyph-append-open-in-new-tab glyph-append-xsmall" href="https://x.com/pyautogen?t=1Zp7y4T18NCrGP9TuLZoJg&s=09" target="_blank" rel="noreferrer noopener">X<span class="sr-only"> (opens in new tab)</span></a>.&nbsp;</p>



<h2 class="wp-block-heading" id="acknowledgments">Acknowledgments</h2>



<p>We would like to thank the many individuals whose ideas and insights helped formalize the concepts introduced in this release, including <a href="https://www.microsoft.com/en-us/research/people/ranaras/" target="_blank" rel="noreferrer noopener">Rajan Chari</a>, <a href="https://www.microsoft.com/en-us/research/people/eckamar/" target="_blank" rel="noreferrer noopener">Ece Kamar</a>, <a href="https://www.microsoft.com/en-us/research/people/jcl/" target="_blank" rel="noreferrer noopener">John Langford</a>, <a href="https://www.microsoft.com/en-us/research/people/chinganc/" target="_blank" rel="noreferrer noopener">Ching-An Chen</a>, Bob West, Paul Minero, Safoora Yousefi, Will Epperson, Grace Proebsting, Enhao Zhang, and Andrew Ng.&nbsp;</p>
<span id="label-external-link" class="sr-only" aria-hidden="true">Opens in a new tab</span><p>The post <a href="https://www.microsoft.com/en-us/research/blog/autogen-v0-4-reimagining-the-foundation-of-agentic-ai-for-scale-extensibility-and-robustness/">AutoGen v0.4: Reimagining the foundation of agentic AI for scale, extensibility, and robustness</a> appeared first on <a href="https://www.microsoft.com/en-us/research">Microsoft Research</a>.</p>
]]></content:encoded>
					
		
		
			</item>
	</channel>
</rss>
