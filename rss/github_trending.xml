<?xml version='1.0' encoding='UTF-8'?>
<rss xmlns:atom="http://www.w3.org/2005/Atom" xmlns:content="http://purl.org/rss/1.0/modules/content/" version="2.0">
  <channel>
    <title>github_trending</title>
    <link>https://github.com/trending</link>
    <description>Latest posts from https://github.com/trending. follow.is: None</description>
    <docs>http://www.rssboard.org/rss-specification</docs>
    <generator>python-feedgen</generator>
    <lastBuildDate>Fri, 31 Jan 2025 01:25:12 +0000</lastBuildDate>
    <item>
      <title>QwenLM /Qwen2.5-VL</title>
      <link>https://github.com/QwenLM/Qwen2.5-VL</link>
      <description>Qwen2.5-VL is the multimodal large language model series developed by Qwen team, Alibaba Cloud.</description>
    </item>
    <item>
      <title>aws-samples /amazon-bedrock-samples</title>
      <link>https://github.com/aws-samples/amazon-bedrock-samples</link>
      <description>This repository contains examples for customers to get started using the Amazon Bedrock Service. This contains examples for all available foundational models</description>
    </item>
    <item>
      <title>github /docs</title>
      <link>https://github.com/github/docs</link>
      <description>The open-source repo for docs.github.com</description>
    </item>
    <item>
      <title>polarsource /polar</title>
      <link>https://github.com/polarsource/polar</link>
      <description>An open source Merchant of Record. Sell SaaS and digital products in minutes.</description>
    </item>
    <item>
      <title>unslothai /unsloth</title>
      <link>https://github.com/unslothai/unsloth</link>
      <description>Finetune Llama 3.3, Mistral, Phi-4, Qwen 2.5 &amp; Gemma LLMs 2-5x faster with 70% less memory</description>
    </item>
    <item>
      <title>deepseek-ai /DreamCraft3D</title>
      <link>https://github.com/deepseek-ai/DreamCraft3D</link>
      <description>[ICLR 2024] Official implementation of DreamCraft3D: Hierarchical 3D Generation with Bootstrapped Diffusion Prior</description>
    </item>
    <item>
      <title>deepseek-ai /DeepSeek-Math</title>
      <link>https://github.com/deepseek-ai/DeepSeek-Math</link>
      <description>DeepSeekMath: Pushing the Limits of Mathematical Reasoning in Open Language Models</description>
    </item>
    <item>
      <title>deepseek-ai /Janus</title>
      <link>https://github.com/deepseek-ai/Janus</link>
      <description>Janus-Series: Unified Multimodal Understanding and Generation Models</description>
    </item>
    <item>
      <title>ollama /ollama</title>
      <link>https://github.com/ollama/ollama</link>
      <description>Get up and running with Llama 3.3, DeepSeek-R1, Phi-4, Gemma 2, and other large language models.</description>
    </item>
    <item>
      <title>deepseek-ai /DeepSeek-Coder</title>
      <link>https://github.com/deepseek-ai/DeepSeek-Coder</link>
      <description>DeepSeek Coder: Let the Code Write Itself</description>
    </item>
    <item>
      <title>n4ze3m /page-assist</title>
      <link>https://github.com/n4ze3m/page-assist</link>
      <description>Use your locally running AI models to assist you in your web browsing</description>
    </item>
    <item>
      <title>deepseek-ai /DeepSeek-Coder-V2</title>
      <link>https://github.com/deepseek-ai/DeepSeek-Coder-V2</link>
      <description>DeepSeek-Coder-V2: Breaking the Barrier of Closed-Source Models in Code Intelligence</description>
    </item>
    <item>
      <title>deepseek-ai /DeepSeek-LLM</title>
      <link>https://github.com/deepseek-ai/DeepSeek-LLM</link>
      <description>DeepSeek LLM: Let there be answers</description>
    </item>
    <item>
      <title>QwenLM /Qwen2.5</title>
      <link>https://github.com/QwenLM/Qwen2.5</link>
      <description>Qwen2.5 is the large language model series developed by Qwen team, Alibaba Cloud.</description>
    </item>
    <item>
      <title>block /goose</title>
      <link>https://github.com/block/goose</link>
      <description>an open-source, extensible AI agent that goes beyond code suggestions - install, execute, edit, and test with any LLM</description>
    </item>
  </channel>
</rss>
