<?xml version='1.0' encoding='UTF-8'?>
<rss xmlns:atom="http://www.w3.org/2005/Atom" xmlns:content="http://purl.org/rss/1.0/modules/content/" version="2.0">
  <channel>
    <title>DeveloperNvidiaBlog</title>
    <link>https://developer.nvidia.com/zh-cn/blog/recent-posts/</link>
    <description>Latest posts from https://developer.nvidia.com/zh-cn/blog/recent-posts/. follow.is: None</description>
    <docs>http://www.rssboard.org/rss-specification</docs>
    <generator>python-feedgen</generator>
    <lastBuildDate>Mon, 14 Jul 2025 02:02:06 +0000</lastBuildDate>
    <item>
      <title>在魔搭社区使用 NVIDIA TensorRT-LLM PyTorch 新架构优化 Qwen3 系列模型推理</title>
      <link>https://developer.nvidia.com/zh-cn/blog/modelscope-nvidia-tensorrt-llm-pytorch-qwen3/</link>
      <description>2025年 6月 26日在魔搭社区使用 NVIDIA TensorRT-LLM PyTorch 新架构优化 Qwen3 系列模型推理摘要： TensorRT-LLM 采用 PyTorch 全新架构进一步优化模型部署流程，提升开发者使用体验。2 MIN READ</description>
    </item>
    <item>
      <title>如何在 Polars GPU 引擎中处理超过 VRAM 的数据</title>
      <link>https://developer.nvidia.com/zh-cn/blog/how-to-work-with-data-exceeding-vram-in-the-polars-gpu-engine/</link>
      <description>2025年 6月 27日如何在 Polars GPU 引擎中处理超过 VRAM 的数据在量化金融、算法交易和欺诈检测等高风险领域，数据从业者经常需要处理数百 GB 的数据，才能快速做出明智的决策。1 MIN READ</description>
    </item>
    <item>
      <title>AI 分析护士观察记录以降低患者危险</title>
      <link>https://developer.nvidia.com/zh-cn/blog/ai-analyzes-nurses-observations-to-reduce-patient-danger/</link>
      <description>2025年 6月 27日AI 分析护士观察记录以降低患者危险研究人员开发了一款 AI 赋能的工具，可以分析护士的轮班笔记，从而比传统方法更早地识别入院患者的健康状况可能恶化或处于“崩溃”的边缘…1 MIN READ</description>
    </item>
    <item>
      <title>出色的多模态 RAG：Llama 3.2 NeMo 检索器嵌入模型如何提高工作流准确性</title>
      <link>https://developer.nvidia.com/zh-cn/blog/best-in-class-multimodal-rag-how-the-llama-3-2-nemo-retriever-embedding-model-boosts-pipeline-accuracy/</link>
      <description>2025年 6月 30日出色的多模态 RAG：Llama 3.2 NeMo 检索器嵌入模型如何提高工作流准确性数据远不止于文本，它本质上是多模态的，包括图像、视频、音频等，通常采用复杂的非结构化格式。虽然常见的方法是将 PDF、扫描图像、2 MIN READ</description>
    </item>
    <item>
      <title>适用于有效 FP8 训练的按张量和按块扩展策略</title>
      <link>https://developer.nvidia.com/zh-cn/blog/per-tensor-and-per-block-scaling-strategies-for-effective-fp8-training/</link>
      <description>2025年 7月 1日适用于有效 FP8 训练的按张量和按块扩展策略在本博文中，我们将分解主要的 FP8 缩放策略 (按张量缩放、延迟和电流缩放以及按块缩放 (包括 Blackwell 支持的 MXFP8…2 MIN READ</description>
    </item>
    <item>
      <title>如何使用 NVIDIA NeMo Agent 工具套件开源库构建自定义 AI 智能体</title>
      <link>https://developer.nvidia.com/zh-cn/blog/how-to-build-custom-ai-agents-with-nvidia-nemo-agent-toolkit-open-source-library/</link>
      <description>2025年 7月 1日如何使用 NVIDIA NeMo Agent 工具套件开源库构建自定义 AI 智能体AI 智能体通过转变业务运营、自动执行复杂任务和解锁新的效率，正在彻底改变数字员工队伍。借助协作能力，这些智能体现在可以协同工作，1 MIN READ</description>
    </item>
    <item>
      <title>先进的 NVIDIA CUDA 内核优化技术：手写 PTX</title>
      <link>https://developer.nvidia.com/zh-cn/blog/advanced-nvidia-cuda-kernel-optimization-techniques-handwritten-ptx/</link>
      <description>2025年 7月 2日先进的 NVIDIA CUDA 内核优化技术：手写 PTX随着加速计算不断提升 AI 和科学计算各个领域的应用程序性能，人们对 GPU 优化技术的兴趣也越来越浓厚，以确保应用程序获得尽可能好的性能。3 MIN READ</description>
    </item>
    <item>
      <title>NVIDIA Omniverse：开发者需要了解的关于迁移远离启动程序的重点</title>
      <link>https://developer.nvidia.com/zh-cn/blog/nvidia-omniverse-what-developers-need-to-know-about-migration-away-from-launcher/</link>
      <description>2025年 7月 2日NVIDIA Omniverse：开发者需要了解的关于迁移远离启动程序的重点为了继续努力确保 NVIDIA Omniverse 成为开发者优先平台，NVIDIA 将于 10 月 1 日弃用 Omniverse…1 MIN READ</description>
    </item>
    <item>
      <title>通过低精度量化优化用于图像编辑的 FLUX.1 Kontext</title>
      <link>https://developer.nvidia.com/zh-cn/blog/optimizing-flux-1-kontext-for-image-editing-with-low-precision-quantization/</link>
      <description>2025年 7月 2日通过低精度量化优化用于图像编辑的 FLUX.1 KontextFLUX.1 Kontext 是 Black Forest Labs 最近发布的模型，是对社区图像生成模型的一项令人着迷的补充。3 MIN READ</description>
    </item>
    <item>
      <title>RAPIDS 新增 GPU Polars 串流、统一 GNN API 和零代码 ML 加速功能</title>
      <link>https://developer.nvidia.com/zh-cn/blog/rapids-adds-gpu-polars-streaming-a-unified-gnn-api-and-zero-code-ml-speedups/</link>
      <description>2025年 7月 3日RAPIDS 新增 GPU Polars 串流、统一 GNN API 和零代码 ML 加速功能RAPIDS 是一套用于 Python 数据科学的 NVIDIA CUDA-X 库，发布了 25.06 版本，引入了令人兴奋的新功能。2 MIN READ</description>
    </item>
    <item>
      <title>新视频：使用 NVIDIA Data Flywheel Blueprint 构建可自我提升的 AI 代理</title>
      <link>https://developer.nvidia.com/zh-cn/blog/new-video-build-self-improving-ai-agents-with-the-nvidia-data-flywheel-blueprint/</link>
      <description>2025年 7月 3日新视频：使用 NVIDIA Data Flywheel Blueprint 构建可自我提升的 AI 代理由大语言模型驱动的 AI 智能体正在改变企业工作流，但高昂的推理成本和延迟可能会限制其可扩展性和用户体验。为解决这一问题，1 MIN READ</description>
    </item>
    <item>
      <title>提出一个维基百科规模的问题：如何利用数百万 token 的实时推理使世界更加智能</title>
      <link>https://developer.nvidia.com/zh-cn/blog/asking-an-encyclopedia-sized-question-how-to-make-the-world-smarter-with-multi-million-token-real-time-inference/</link>
      <description>2025年 7月 7日提出一个维基百科规模的问题：如何利用数百万 token 的实时推理使世界更加智能现代 AI 应用越来越依赖于将庞大的参数数量与数百万个令牌的上下文窗口相结合的模型。无论是经过数月对话的 AI 智能体、3 MIN READ</description>
    </item>
    <item>
      <title>NVIDIA cuQuantum 增加了动态梯度、DMRG 和模拟加速</title>
      <link>https://developer.nvidia.com/zh-cn/blog/nvidia-cuquantum-adds-dynamic-gradients-dmrg-and-simulation-speedup/</link>
      <description>2025年 7月 7日NVIDIA cuQuantum 增加了动态梯度、DMRG 和模拟加速NVIDIA cuQuantum 是一个包含优化库和工具的 SDK，可将电路和设备级别的量子计算模拟加速几个数量级。1 MIN READ</description>
    </item>
    <item>
      <title>使用 DPU 加速的 Kubernetes 服务代理增强 AI 工厂</title>
      <link>https://developer.nvidia.com/zh-cn/blog/turbocharging-ai-factories-with-dpu-accelerated-service-proxy-for-kubernetes/</link>
      <description>2025年 7月 7日使用 DPU 加速的 Kubernetes 服务代理增强 AI 工厂随着 AI 借助代理式 AI 向规划、研究和推理发展，工作流变得越来越复杂。为了高效部署代理式 AI 应用，AI 云需要软件定义、2 MIN READ</description>
    </item>
    <item>
      <title>LLM 推理基准测试：使用 TensorRT-LLM 进行性能调优</title>
      <link>https://developer.nvidia.com/zh-cn/blog/llm-inference-benchmarking-performance-tuning-with-tensorrt-llm/</link>
      <description>2025年 7月 7日LLM 推理基准测试：使用 TensorRT-LLM 进行性能调优这是大语言模型延迟 – 吞吐量基准测试系列的第三篇博文，旨在指导开发者如何使用 TensorRT-LLM 对 LLM 推理进行基准测试。3 MIN READ</description>
    </item>
    <item>
      <title>突破延迟极限：在 NVIDIA Blackwell GPU 上优化 DeepSeek-R1 的性能</title>
      <link>https://developer.nvidia.com/zh-cn/blog/nvidia-blackwell-gpu-deepseek-r1-optimization/</link>
      <description>2025年 7月 11日突破延迟极限：在 NVIDIA Blackwell GPU 上优化 DeepSeek-R1 的性能近年来，大语言逻辑推理模型取得了显著进步，但也带来了新的部署挑战。其中，因复杂的“思考与逻辑推理”过程而引起的输出序列长度 (OSL)…3 MIN READ</description>
    </item>
  </channel>
</rss>
