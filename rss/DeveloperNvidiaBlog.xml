<?xml version='1.0' encoding='UTF-8'?>
<rss xmlns:atom="http://www.w3.org/2005/Atom" xmlns:content="http://purl.org/rss/1.0/modules/content/" version="2.0">
  <channel>
    <title>DeveloperNvidiaBlog</title>
    <link>https://developer.nvidia.com/zh-cn/blog/recent-posts/</link>
    <description>Latest posts from https://developer.nvidia.com/zh-cn/blog/recent-posts/. follow.is: None</description>
    <docs>http://www.rssboard.org/rss-specification</docs>
    <generator>python-feedgen</generator>
    <lastBuildDate>Sat, 12 Apr 2025 01:40:50 +0000</lastBuildDate>
    <item>
      <title>工业设施数字孪生中的机器人仿真</title>
      <link>https://developer.nvidia.com/zh-cn/blog/simulating-robots-in-industrial-facility-digital-twins/</link>
      <description>2025年 3月 31日工业设施数字孪生中的机器人仿真工业企业正在采用 物理 AI 和自主系统来实现运营转型。这涉及在工厂和仓库中部署异构机器人车队，包括移动机器人、 人形助手 、2 MIN READ</description>
    </item>
    <item>
      <title>人工智能如何推动气候创新和可持续增长</title>
      <link>https://developer.nvidia.com/zh-cn/blog/how-ai-is-shaping-climate-innovation-and-sustainable-growth/</link>
      <description>2025年 4月 1日人工智能如何推动气候创新和可持续增长在 GTC 2025 大会上，来自整个技术生态系统的行业领导者小组分享了他们如何使用 AI 来减轻气候变化带来的破坏性越来越大的影响，1 MIN READ</description>
    </item>
    <item>
      <title>NVIDIA 开源 Run:ai 调度程序以推动社区协作</title>
      <link>https://developer.nvidia.com/zh-cn/blog/nvidia-open-sources-runai-scheduler-to-foster-community-collaboration/</link>
      <description>2025年 4月 1日NVIDIA 开源 Run:ai 调度程序以推动社区协作今天，NVIDIA 宣布推出 KAI Scheduler 的开源版本，这是一种 Kubernetes-native GPU 调度解决方案，3 MIN READ</description>
    </item>
    <item>
      <title>NVIDIA Blackwell 在 MLPerf Inference v5.0 中实现巨大的性能飞跃</title>
      <link>https://developer.nvidia.com/zh-cn/blog/nvidia-blackwell-delivers-massive-performance-leaps-in-mlperf-inference-v5-0/</link>
      <description>2025年 4月 2日NVIDIA Blackwell 在 MLPerf Inference v5.0 中实现巨大的性能飞跃在不断增长的模型大小、实时延迟要求以及最近的 AI 推理的推动下， 大语言模型 (LLM) 推理的计算需求正在快速增长。与此同时，3 MIN READ</description>
    </item>
    <item>
      <title>LLM 基准测试：基本概念</title>
      <link>https://developer.nvidia.com/zh-cn/blog/llm-benchmarking-fundamental-concepts/</link>
      <description>2025年 4月 2日LLM 基准测试：基本概念在过去几年中，作为广泛的 AI 革命的一部分， 生成式 AI 和 大语言模型 (LLMs) 越来越受欢迎。4 MIN READ</description>
    </item>
    <item>
      <title>使用 GPU 加速 Apache Spark 上的 Apache Parquet 扫描</title>
      <link>https://developer.nvidia.com/zh-cn/blog/accelerating-apache-parquet-scans-on-apache-spark-with-gpus/</link>
      <description>2025年 4月 3日使用 GPU 加速 Apache Spark 上的 Apache Parquet 扫描随着各行各业企业的数据规模不断增长， Apache Parquet 已成为一种重要的数据存储格式。3 MIN READ</description>
    </item>
    <item>
      <title>NVIDIA 加速推理 Meta Llama 4 Scout 与 Maverick 模型</title>
      <link>https://developer.nvidia.com/zh-cn/blog/nvidia-accelerates-inference-on-meta-llama-4-scout-and-maverick/</link>
      <description>2025年 4月 5日NVIDIA 加速推理 Meta Llama 4 Scout 与 Maverick 模型最新一代热门 Llama AI 模型现已支持 Llama 4 Scout 和 Llama 4 Maverick。2 MIN READ</description>
    </item>
    <item>
      <title>使用合成数据评估和增强 RAG 工作流性能</title>
      <link>https://developer.nvidia.com/zh-cn/blog/evaluating-and-enhancing-rag-pipeline-performance-using-synthetic-data/</link>
      <description>2025年 4月 7日使用合成数据评估和增强 RAG 工作流性能随着 大语言模型 (LLM) 在各种问答系统中的普及， 检索增强生成 (RAG) 流程也成为焦点。1 MIN READ</description>
    </item>
    <item>
      <title>初创公司利用人工智能改善孕产期和新生儿护理服务</title>
      <link>https://developer.nvidia.com/zh-cn/blog/startups-use-ai-to-deliver-better-maternal-and-newborn-care/</link>
      <description>2025年 4月 7日初创公司利用人工智能改善孕产期和新生儿护理服务每年，全球有近 30 万名女性死于因孕期或生产引起的并发症。在出生后的第一个月内死亡的死产儿和婴儿的数量每年超过近 400 万。1 MIN READ</description>
    </item>
    <item>
      <title>使用先进的开放式 NVIDIA Llama Nemotron 推理模型构建企业 AI 智能体</title>
      <link>https://developer.nvidia.com/zh-cn/blog/build-enterprise-ai-agents-with-advanced-open-nvidia-llama-nemotron-reasoning-models-2/</link>
      <description>2025年 4月 8日使用先进的开放式 NVIDIA Llama Nemotron 推理模型构建企业 AI 智能体此更新文章最初发布于 2025 年 3 月 18 日 。 企业组织正在采用 AI 智能体 来提高生产力并简化运营。为了更大限度地发挥影响，3 MIN READ</description>
    </item>
    <item>
      <title>利用 AI 更好地了解海洋</title>
      <link>https://developer.nvidia.com/zh-cn/blog/using-ai-to-better-understand-the-ocean/</link>
      <description>2025年 4月 8日利用 AI 更好地了解海洋人类对深空的了解比我们对地球最深的海洋的了解更多。但科学家计划在 AI 的帮助下改变这种状况。1 MIN READ</description>
    </item>
    <item>
      <title>借助 Rafay 为企业 AI 工作负载提供 NVIDIA 加速计算</title>
      <link>https://developer.nvidia.com/zh-cn/blog/delivering-nvidia-accelerated-computing-for-enterprise-ai-workloads-with-rafay/</link>
      <description>2025年 4月 9日借助 Rafay 为企业 AI 工作负载提供 NVIDIA 加速计算生成式 AI 在全球的应用推动了全球对加速计算硬件的巨大需求。在企业中，这加快了加速私有云基础设施的部署。在地区层面，2 MIN READ</description>
    </item>
    <item>
      <title>在 NVIDIA NeMo Guardrails 中使用 Cleanlab 可信语言模型防止 LLM 幻觉</title>
      <link>https://developer.nvidia.com/zh-cn/blog/prevent-llm-hallucinations-with-the-cleanlab-trustworthy-language-model-in-nvidia-nemo-guardrails/</link>
      <description>2025年 4月 9日在 NVIDIA NeMo Guardrails 中使用 Cleanlab 可信语言模型防止 LLM 幻觉随着越来越多的企业将 Large Language Models (LLM) 集成到其应用中，他们面临着一个严峻的挑战：3 MIN READ</description>
    </item>
    <item>
      <title>斯坦福大学实验室借助 NVIDIA DGX 云加速 RNA 折叠研究</title>
      <link>https://developer.nvidia.com/zh-cn/blog/stanford-das-lab-accelerates-rna-folding-research-with-nvidia-dgx-cloud/</link>
      <description>2025年 4月 9日斯坦福大学实验室借助 NVIDIA DGX 云加速 RNA 折叠研究斯坦福大学的 Das Lab 正在通过一种利用社区参与和加速计算的独特方法，彻底改变 RNA 折叠研究。在 NVIDIA DGX 云 通过…1 MIN READ</description>
    </item>
    <item>
      <title>高效扩展 Polars 的 GPU Parquet 读取器</title>
      <link>https://developer.nvidia.com/zh-cn/blog/efficiently-scaling-polars-gpu-parquet-reader/</link>
      <description>2025年 4月 10日高效扩展 Polars 的 GPU Parquet 读取器在处理大型数据集时，数据处理工具的性能变得至关重要。 Polars 是一个以速度和效率闻名的开源数据操作库，提供由 cuDF 驱动的 GPU…2 MIN READ</description>
    </item>
    <item>
      <title>使用 NVIDIA NIM 管理科学文献中的生物研究成果</title>
      <link>https://developer.nvidia.com/zh-cn/blog/curating-biological-findings-from-scientific-literature-with-nvidia-nim/</link>
      <description>2025年 4月 11日使用 NVIDIA NIM 管理科学文献中的生物研究成果科学论文多种多样，通常为同一实体使用不同的术语，使用不同的方法来研究生物现象，并在不同的上下文中展示研究结果。2 MIN READ</description>
    </item>
  </channel>
</rss>
