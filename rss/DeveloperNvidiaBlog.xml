<?xml version='1.0' encoding='UTF-8'?>
<rss xmlns:atom="http://www.w3.org/2005/Atom" xmlns:content="http://purl.org/rss/1.0/modules/content/" version="2.0">
  <channel>
    <title>DeveloperNvidiaBlog</title>
    <link>https://developer.nvidia.com/zh-cn/blog/recent-posts/</link>
    <description>Latest posts from https://developer.nvidia.com/zh-cn/blog/recent-posts/. follow.is: None</description>
    <docs>http://www.rssboard.org/rss-specification</docs>
    <generator>python-feedgen</generator>
    <lastBuildDate>Tue, 22 Apr 2025 01:45:05 +0000</lastBuildDate>
    <item>
      <title>使用先进的开放式 NVIDIA Llama Nemotron 推理模型构建企业 AI 智能体</title>
      <link>https://developer.nvidia.com/zh-cn/blog/build-enterprise-ai-agents-with-advanced-open-nvidia-llama-nemotron-reasoning-models-2/</link>
      <description>2025年 4月 8日使用先进的开放式 NVIDIA Llama Nemotron 推理模型构建企业 AI 智能体此更新文章最初发布于 2025 年 3 月 18 日 。 企业组织正在采用 AI 智能体 来提高生产力并简化运营。为了更大限度地发挥影响，3 MIN READ</description>
    </item>
    <item>
      <title>利用 AI 更好地了解海洋</title>
      <link>https://developer.nvidia.com/zh-cn/blog/using-ai-to-better-understand-the-ocean/</link>
      <description>2025年 4月 8日利用 AI 更好地了解海洋人类对深空的了解比我们对地球最深的海洋的了解更多。但科学家计划在 AI 的帮助下改变这种状况。1 MIN READ</description>
    </item>
    <item>
      <title>借助 Rafay 为企业 AI 工作负载提供 NVIDIA 加速计算</title>
      <link>https://developer.nvidia.com/zh-cn/blog/delivering-nvidia-accelerated-computing-for-enterprise-ai-workloads-with-rafay/</link>
      <description>2025年 4月 9日借助 Rafay 为企业 AI 工作负载提供 NVIDIA 加速计算生成式 AI 在全球的应用推动了全球对加速计算硬件的巨大需求。在企业中，这加快了加速私有云基础设施的部署。在地区层面，2 MIN READ</description>
    </item>
    <item>
      <title>在 NVIDIA NeMo Guardrails 中使用 Cleanlab 可信语言模型防止 LLM 幻觉</title>
      <link>https://developer.nvidia.com/zh-cn/blog/prevent-llm-hallucinations-with-the-cleanlab-trustworthy-language-model-in-nvidia-nemo-guardrails/</link>
      <description>2025年 4月 9日在 NVIDIA NeMo Guardrails 中使用 Cleanlab 可信语言模型防止 LLM 幻觉随着越来越多的企业将 Large Language Models (LLM) 集成到其应用中，他们面临着一个严峻的挑战：3 MIN READ</description>
    </item>
    <item>
      <title>斯坦福大学实验室借助 NVIDIA DGX 云加速 RNA 折叠研究</title>
      <link>https://developer.nvidia.com/zh-cn/blog/stanford-das-lab-accelerates-rna-folding-research-with-nvidia-dgx-cloud/</link>
      <description>2025年 4月 9日斯坦福大学实验室借助 NVIDIA DGX 云加速 RNA 折叠研究斯坦福大学的 Das Lab 正在通过一种利用社区参与和加速计算的独特方法，彻底改变 RNA 折叠研究。在 NVIDIA DGX 云 通过…1 MIN READ</description>
    </item>
    <item>
      <title>高效扩展 Polars 的 GPU Parquet 读取器</title>
      <link>https://developer.nvidia.com/zh-cn/blog/efficiently-scaling-polars-gpu-parquet-reader/</link>
      <description>2025年 4月 10日高效扩展 Polars 的 GPU Parquet 读取器在处理大型数据集时，数据处理工具的性能变得至关重要。 Polars 是一个以速度和效率闻名的开源数据操作库，提供由 cuDF 驱动的 GPU…2 MIN READ</description>
    </item>
    <item>
      <title>借助 NVIDIA FLARE 和 Meta ExecuTorch，在移动设备上轻松进行联邦学习</title>
      <link>https://developer.nvidia.com/zh-cn/blog/effortless-federated-learning-on-mobile-with-nvidia-flare-and-meta-executorch/</link>
      <description>2025年 4月 11日借助 NVIDIA FLARE 和 Meta ExecuTorch，在移动设备上轻松进行联邦学习NVIDIA 和 Meta 的 PyTorch 团队宣布开展突破性合作，通过集成 NVIDIA FLARE 和 ExecuTorch ，3 MIN READ</description>
    </item>
    <item>
      <title>NVIDIA 借助 NVIDIA DGX SuperPOD 加快 AI 工厂建设速度</title>
      <link>https://developer.nvidia.com/zh-cn/blog/nvidia-helps-build-ai-factories-faster-than-ever-with-nvidia-dgx-superpod/</link>
      <description>2025年 4月 11日NVIDIA 借助 NVIDIA DGX SuperPOD 加快 AI 工厂建设速度在日本一个秘密地点的洞穴状房间里，一场数字革命正在展开。服务器机架像巨人一样立着，它们的光滑框架由数千条电缆连接，充满了潜力。 直到去年，1 MIN READ</description>
    </item>
    <item>
      <title>AI Fabric 的弹性以及网络融合的重要性</title>
      <link>https://developer.nvidia.com/zh-cn/blog/ai-fabric-resiliency-and-why-network-convergence-matters/</link>
      <description>2025年 4月 11日AI Fabric 的弹性以及网络融合的重要性高性能计算和深度学习工作负载对延迟极为敏感。数据包丢失会导致通信管道中的重传或停顿，从而直接增加延迟并中断 GPU 之间的同步。1 MIN READ</description>
    </item>
    <item>
      <title>AI 利用标准 MRI 扫描提高帕金森病检测能力</title>
      <link>https://developer.nvidia.com/zh-cn/blog/ai-advances-parkinsons-detection-using-standard-mri-scans/</link>
      <description>2025年 4月 11日AI 利用标准 MRI 扫描提高帕金森病检测能力要想准确诊断帕金森症，只需简单的脑部扫描就可以了，这要归功于 AI 驱动的新工具。这一进步可以帮助医生加快检测和治疗速度，1 MIN READ</description>
    </item>
    <item>
      <title>使用 NVIDIA NIM 管理科学文献中的生物研究成果</title>
      <link>https://developer.nvidia.com/zh-cn/blog/curating-biological-findings-from-scientific-literature-with-nvidia-nim/</link>
      <description>2025年 4月 11日使用 NVIDIA NIM 管理科学文献中的生物研究成果科学论文多种多样，通常为同一实体使用不同的术语，使用不同的方法来研究生物现象，并在不同的上下文中展示研究结果。2 MIN READ</description>
    </item>
    <item>
      <title>NVIDIA Llama Nemotron 超开放模型实现突破性的推理准确性</title>
      <link>https://developer.nvidia.com/zh-cn/blog/nvidia-llama-nemotron-ultra-open-model-delivers-groundbreaking-reasoning-accuracy/</link>
      <description>2025年 4月 15日NVIDIA Llama Nemotron 超开放模型实现突破性的推理准确性AI 不再只是生成文本或图像，而是要针对商业、金融、客户和医疗健康服务中的现实应用进行深度推理、详细解决问题并实现强大的适应性。2 MIN READ</description>
    </item>
    <item>
      <title>AI 生成的热图可保护老年人及其隐私</title>
      <link>https://developer.nvidia.com/zh-cn/blog/ai-generated-heat-maps-keep-seniors-and-their-privacy-safe/</link>
      <description>2025年 4月 16日AI 生成的热图可保护老年人及其隐私到 2030 年，超过五分之一的美国人将年满 65 岁，成为美国有史以来最大的老年人群体。 位于硅谷的初创公司 Butlr 开发了一个 AI…1 MIN READ</description>
    </item>
    <item>
      <title>宣布推出基于 CUDA 评估 LLM 的开源框架 ComputeEval</title>
      <link>https://developer.nvidia.com/zh-cn/blog/announcing-computeeval-an-open-source-framework-for-evaluating-llms-on-cuda/</link>
      <description>2025年 4月 16日宣布推出基于 CUDA 评估 LLM 的开源框架 ComputeEval大语言模型 (LLMs) 正在彻底改变开发者的编码方式和编码学习方式。对于经验丰富的或初级的开发者来说，1 MIN READ</description>
    </item>
    <item>
      <title>使用 NVIDIA NIM 构建 AI 驱动的自动引用验证工具</title>
      <link>https://developer.nvidia.com/zh-cn/blog/developing-an-ai-powered-tool-for-automatic-citation-validation-using-nvidia-nim/</link>
      <description>2025年 4月 16日使用 NVIDIA NIM 构建 AI 驱动的自动引用验证工具引文的准确性对于保持学术和 AI 生成内容的完整性至关重要。当引用不准确或错误时，它们可能会误导读者并散布虚假信息。2 MIN READ</description>
    </item>
    <item>
      <title>在大型语言模型时代，通过消息量化和流式传输实现高效的联邦学习</title>
      <link>https://developer.nvidia.com/zh-cn/blog/efficient-federated-learning-in-the-era-of-llms-with-message-quantization-and-streaming/</link>
      <description>2025年 4月 16日在大型语言模型时代，通过消息量化和流式传输实现高效的联邦学习联邦学习 (Federated Learning, FL) 已成为一种在分布式数据源中训练机器学习模型的有前景的方法，同时还能保护数据隐私。2 MIN READ</description>
    </item>
  </channel>
</rss>
