<?xml version='1.0' encoding='UTF-8'?>
<rss xmlns:atom="http://www.w3.org/2005/Atom" xmlns:content="http://purl.org/rss/1.0/modules/content/" version="2.0">
  <channel>
    <title>DeveloperNvidiaBlog</title>
    <link>https://developer.nvidia.com/zh-cn/blog/recent-posts/</link>
    <description>Latest posts from https://developer.nvidia.com/zh-cn/blog/recent-posts/. follow.is: None</description>
    <docs>http://www.rssboard.org/rss-specification</docs>
    <generator>python-feedgen</generator>
    <lastBuildDate>Wed, 04 Feb 2026 02:26:45 +0000</lastBuildDate>
    <item>
      <title>如何在 NVIDIA CUDA Tile 中编写高性能矩阵乘法</title>
      <link>https://developer.nvidia.cn/blog/how-to-write-high-performance-matrix-multiply-in-nvidia-cuda-tile/</link>
      <description>2026年 1月 14日如何在 NVIDIA CUDA Tile 中编写高性能矩阵乘法本博文是系列课程的一部分，旨在帮助开发者学习 NVIDIA CUDA Tile 编程，掌握构建高性能 GPU 内核的方法，5 MIN READ</description>
    </item>
    <item>
      <title>NVIDIA DLSS 4.5 推出超分辨率增强与全新动态多帧生成技术</title>
      <link>https://developer.nvidia.cn/blog/nvidia-dlss-4-5-delivers-super-resolution-upgrades-and-new-dynamic-multi-frame-generation/</link>
      <description>2026年 1月 14日NVIDIA DLSS 4.5 推出超分辨率增强与全新动态多帧生成技术带有多帧生成功能的 NVIDIA DLSS 4 已成为迄今为止普及速度最快的 NVIDIA 游戏技术。2 MIN READ</description>
    </item>
    <item>
      <title>如何使用合成数据和强化学习训练 AI 智能体执行命令行任务</title>
      <link>https://developer.nvidia.cn/blog/how-to-train-an-ai-agent-for-command-line-tasks-with-synthetic-data-and-reinforcement-learning/</link>
      <description>2026年 1月 15日如何使用合成数据和强化学习训练 AI 智能体执行命令行任务如果您的计算机智能体能够学习新的命令行界面（CLI），并且在无需编写文件或自由输入 shell 命令的情况下也能安全操作，该怎么办？3 MIN READ</description>
    </item>
    <item>
      <title>使用 Single Call API 简化 CUB</title>
      <link>https://developer.nvidia.cn/blog/streamlining-cub-with-a-single-call-api/</link>
      <description>2026年 1月 21日使用 Single Call API 简化 CUBC++ 模板库 CUB 提供了高性能 GPU 基元算法，但其将内存估计与分配分离的传统“两阶段”API 可能带来使用上的不便。2 MIN READ</description>
    </item>
    <item>
      <title>在 NVIDIA Blackwell 数据中心 GPU 上实现 FLUX.2 的 NVFP4 推理扩展</title>
      <link>https://developer.nvidia.cn/blog/scaling-nvfp4-inference-for-flux-2-on-nvidia-blackwell-data-center-gpus/</link>
      <description>2026年 1月 22日在 NVIDIA Blackwell 数据中心 GPU 上实现 FLUX.2 的 NVFP4 推理扩展2025 年，NVIDIA 与 Black Forest Labs (BFL) 合作优化 FLUX.1 文本转图像模型系列，3 MIN READ</description>
    </item>
    <item>
      <title>NVIDIA TensorRT for RTX 中的自适应推理可实现自动优化</title>
      <link>https://developer.nvidia.cn/blog/adaptive-inference-in-nvidia-tensorrt-for-rtx-enables-automatic-optimization/</link>
      <description>2026年 1月 26日NVIDIA TensorRT for RTX 中的自适应推理可实现自动优化传统上，在各种消费级硬件中部署 AI 应用需要进行权衡。可以针对特定 GPU 配置进行优化，以牺牲便携性为代价来提升性能；3 MIN READ</description>
    </item>
    <item>
      <title>如何使用 NVIDIA Earth-2 解锁粗略气候投影的局部细节</title>
      <link>https://developer.nvidia.cn/blog/how-to-unlock-local-detail-in-coarse-climate-projections-with-nvidia-earth-2/</link>
      <description>2026年 1月 26日如何使用 NVIDIA Earth-2 解锁粗略气候投影的局部细节全球气候模型擅长大局把握，但飓风和台风等局部极端气候现象往往在细节中被忽略。这些现象依然存在，只需借助合适的工具，3 MIN READ</description>
    </item>
    <item>
      <title>使用 NVIDIA TensorRT LLM 部署 MiniMax M2/M2.1 稀疏 MoE 大模型</title>
      <link>https://developer.nvidia.cn/blog/deploying-minimax-sparse-moe-llm-using-tensorrt-llm/</link>
      <description>2026年 1月 27日使用 NVIDIA TensorRT LLM 部署 MiniMax M2/M2.1 稀疏 MoE 大模型MiniMax M2/M2.1 是一款面向 Agents 和 Coding 工作流的开源稀疏 MoE 模型，在工具调用、2 MIN READ</description>
    </item>
    <item>
      <title>通过开放式即插即用产品加速扩散模型</title>
      <link>https://developer.nvidia.cn/blog/accelerating-diffusion-models-with-an-open-plug-and-play-offering/</link>
      <description>2026年 1月 27日通过开放式即插即用产品加速扩散模型大规模扩散模型的近期进展深刻改变了生成式 AI 在多个领域的应用，涵盖图像合成、音频生成、3D 素材创建、分子设计等。2 MIN READ</description>
    </item>
    <item>
      <title>基于时间的公平共享实现 Kubernetes 集群 GPU 分配均衡</title>
      <link>https://developer.nvidia.cn/blog/ensuring-balanced-gpu-allocation-in-kubernetes-clusters-with-time-based-fairshare/</link>
      <description>2026年 1月 28日基于时间的公平共享实现 Kubernetes 集群 GPU 分配均衡NVIDIA Run:ai v2.24 引入了基于时间的公平分享，这是一种全新的调度模式，可为 Kubernetes 集群实现公平分享调度，2 MIN READ</description>
    </item>
    <item>
      <title>借助动态上下文并行和 NVIDIA Megatron Core 加速可变长度训练</title>
      <link>https://developer.nvidia.cn/blog/speeding-up-variable-length-training-with-dynamic-context-parallelism-and-nvidia-megatron-core/</link>
      <description>2026年 1月 28日借助动态上下文并行和 NVIDIA Megatron Core 加速可变长度训练本文将介绍动态上下文并行（Dynamic Context Parallelism，Dynamic-CP），4 MIN READ</description>
    </item>
    <item>
      <title>更新视觉语言模型的分类器规避</title>
      <link>https://developer.nvidia.cn/blog/updating-classifier-evasion-for-vision-language-models/</link>
      <description>2026年 1月 28日更新视觉语言模型的分类器规避AI 架构的进步解锁了多模态功能，使 Transformer 模型能够在统一的上下文中处理多种类型的数据。例如，3 MIN READ</description>
    </item>
    <item>
      <title>基于 CUDA Tile IR 后端的 OpenAI Triton 推动 GPU 编程发展</title>
      <link>https://developer.nvidia.cn/blog/advancing-gpu-programming-with-the-cuda-tile-ir-backend-for-openai-triton/</link>
      <description>2026年 1月 30日基于 CUDA Tile IR 后端的 OpenAI Triton 推动 GPU 编程发展NVIDIA CUDA Tile 是一种基于 GPU 的编程模型，旨在实现 NVIDIA Tensor Core 的可移植性，2 MIN READ</description>
    </item>
    <item>
      <title>使用通用稀疏张量建立可扩展的稀疏生态系统</title>
      <link>https://developer.nvidia.cn/blog/establishing-a-scalable-sparse-ecosystem-with-the-universal-sparse-tensor/</link>
      <description>2026年 1月 30日使用通用稀疏张量建立可扩展的稀疏生态系统稀疏张量是向量、矩阵以及高维数组在包含大量零元素情况下的推广形式。由于其在存储、计算和功耗方面的高效性，稀疏张量在科学计算、5 MIN READ</description>
    </item>
    <item>
      <title>沙箱代理工作流与执行风险管理的实用安全指南</title>
      <link>https://developer.nvidia.cn/blog/practical-security-guidance-for-sandboxing-agentic-workflows-and-managing-execution-risk/</link>
      <description>2026年 1月 30日沙箱代理工作流与执行风险管理的实用安全指南AI 编码智能体通过简化任务和推动测试驱动的自动化开发，使开发者能够更高效地工作。然而，它们也引入了一个常被忽视的重要攻击面：1 MIN READ</description>
    </item>
    <item>
      <title>使用混合专家并行优化混合专家训练的通信</title>
      <link>https://developer.nvidia.cn/blog/optimizing-communication-for-mixture-of-experts-training-with-hybrid-expert-parallel/</link>
      <description>2026年 2月 2日使用混合专家并行优化混合专家训练的通信在 LLM 训练中，超大规模多专家模型 (MoE) 的专家并行 (EP) 通信面临巨大挑战。EP 通信本质上属于多对多模式，4 MIN READ</description>
    </item>
  </channel>
</rss>
