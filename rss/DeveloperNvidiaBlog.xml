<?xml version='1.0' encoding='UTF-8'?>
<rss xmlns:atom="http://www.w3.org/2005/Atom" xmlns:content="http://purl.org/rss/1.0/modules/content/" version="2.0">
  <channel>
    <title>DeveloperNvidiaBlog</title>
    <link>https://developer.nvidia.com/zh-cn/blog/recent-posts/</link>
    <description>Latest posts from https://developer.nvidia.com/zh-cn/blog/recent-posts/. follow.is: None</description>
    <docs>http://www.rssboard.org/rss-specification</docs>
    <generator>python-feedgen</generator>
    <lastBuildDate>Wed, 10 Sep 2025 01:39:30 +0000</lastBuildDate>
    <item>
      <title>行业协作共推 NVIDIA CPO 技术</title>
      <link>https://developer.nvidia.com/zh-cn/blog/how-industry-collaboration-fosters-nvidia-co-packaged-optics/</link>
      <description>2025年 8月 26日行业协作共推 NVIDIA CPO 技术NVIDIA 通过光、电组件的无缝集成，重塑数据中心互连新格局。这一突破的关键在于与整个行业的合作伙伴的紧密合作。1 MIN READ</description>
    </item>
    <item>
      <title>TensorRT-LLM 中的分离式服务</title>
      <link>https://developer.nvidia.com/zh-cn/blog/tensorrt-llm-partioned-service/</link>
      <description>2025年 8月 26日TensorRT-LLM 中的分离式服务在之前的技术博客中，我们介绍了低延迟和高吞吐场景的优化方法。对于生产部署，用户还关心在满足特定延迟约束的情况下，每个 GPU 的吞吐表现。3 MIN READ</description>
    </item>
    <item>
      <title>在 NVIDIA Blackwell GPU 上优化 DeepSeek R1 吞吐量：开发者深度解析</title>
      <link>https://developer.nvidia.com/zh-cn/blog/nvidia-blackwell-gpu-deepseek-r1-optimization-2/</link>
      <description>2025年 8月 26日在 NVIDIA Blackwell GPU 上优化 DeepSeek R1 吞吐量：开发者深度解析开源 DeepSeek R1 模型的创新架构包含多头潜在注意力机制 (MLA) 和大型稀疏混合专家模型 (MoE)，1 MIN READ</description>
    </item>
    <item>
      <title>如何通过共享内存寄存器溢出来提高 CUDA 内核性能</title>
      <link>https://developer.nvidia.com/zh-cn/blog/how-to-improve-cuda-kernel-performance-with-shared-memory-register-spilling/</link>
      <description>2025年 8月 27日如何通过共享内存寄存器溢出来提高 CUDA 内核性能当 CUDA 内核所需的硬件寄存器数量超过可用数量时，编译器会将多余的变量溢出到本地内存中，这一过程称为寄存器溢出。3 MIN READ</description>
    </item>
    <item>
      <title>如何将生产环境中的 LangGraph 智能体从单个用户扩展到 1000 名同事</title>
      <link>https://developer.nvidia.com/zh-cn/blog/how-to-scale-your-langgraph-agents-in-production-from-a-single-user-to-1000-coworkers/</link>
      <description>2025年 8月 27日如何将生产环境中的 LangGraph 智能体从单个用户扩展到 1000 名同事您已经成功构建了一个功能强大的 AI 智能体，并准备与同事分享，但您有一个重要的顾虑：如果同时有 10 位、100…3 MIN READ</description>
    </item>
    <item>
      <title>使用远程手术工作流程入门 NVIDIA Isaac 进行医疗保健应用开发</title>
      <link>https://developer.nvidia.com/zh-cn/blog/getting-started-with-nvidia-isaac-for-healthcare-using-the-telesurgery-workflow/</link>
      <description>2025年 8月 28日使用远程手术工作流程入门 NVIDIA Isaac 进行医疗保健应用开发远程手术已不再是一种未来主义理念，正迅速成为提供医疗服务的关键手段。到2030年，全球外科医生预计短缺450万人，而农村医院尤其难以吸引专家，2 MIN READ</description>
    </item>
    <item>
      <title>小型语言模型如何成为可扩展代理人工智能的关键</title>
      <link>https://developer.nvidia.com/zh-cn/blog/how-small-language-models-are-key-to-scalable-agentic-ai/</link>
      <description>2025年 8月 29日小型语言模型如何成为可扩展代理人工智能的关键代理式 AI 的迅速崛起，正在重塑企业、开发者以及整个行业对自动化与数字生产力的认知。从软件开发流程到企业级任务编排，2 MIN READ</description>
    </item>
    <item>
      <title>使用量化感知训练微调 gpt-oss 提高准确性和性能</title>
      <link>https://developer.nvidia.com/zh-cn/blog/fine-tuning-gpt-oss-for-accuracy-and-performance-with-quantization-aware-training/</link>
      <description>2025年 8月 29日使用量化感知训练微调 gpt-oss 提高准确性和性能对于 AI 社界而言，主要的开源基础模型版本带来了独特的架构创新与功能突破，正掀起一股令人振奋的浪潮。作为 OpenAI 实验室自 GPT…3 MIN READ</description>
    </item>
    <item>
      <title>降低模型部署成本，同时通过 GPU 显存交换保持性能</title>
      <link>https://developer.nvidia.com/zh-cn/blog/cut-model-deployment-costs-while-keeping-performance-with-gpu-memory-swap/</link>
      <description>2025年 9月 2日降低模型部署成本，同时通过 GPU 显存交换保持性能大规模部署大语言模型（LLM）面临双重挑战：一方面需保障高需求时段的快速响应能力，另一方面又要有效控制 GPU 成本。组织通常面临两难选择：2 MIN READ</description>
    </item>
    <item>
      <title>借助启发式算法和 CUTLASS 4.2 提高 NVIDIA GPU 上的 GEMM 内核自动调整效率</title>
      <link>https://developer.nvidia.com/zh-cn/blog/improving-gemm-kernel-auto-tuning-efficiency-on-nvidia-gpus-with-heuristics-and-cutlass-4-2/</link>
      <description>2025年 9月 2日借助启发式算法和 CUTLASS 4.2 提高 NVIDIA GPU 上的 GEMM 内核自动调整效率为特定问题和硬件选择合适的通用矩阵乘法（GEMM）核函数是一项重大挑战。GEMM 核函数的性能由一系列编译时和运行时的元参数共同决定，2 MIN READ</description>
    </item>
    <item>
      <title>适用于 Jetson Thor 的 CUDA 工具包 13.0 的新功能：统一 Arm 生态系统等</title>
      <link>https://developer.nvidia.com/zh-cn/blog/whats-new-in-cuda-toolkit-13-0-for-jetson-thor-unified-arm-ecosystem-and-more/</link>
      <description>2025年 9月 2日适用于 Jetson Thor 的 CUDA 工具包 13.0 的新功能：统一 Arm 生态系统等随着由 NVIDIA Blackwell GPU 架构驱动的 Jetson Thor SoC 即将支持 CUDA 13.0 版本，4 MIN READ</description>
    </item>
    <item>
      <title>借助 NVIDIA DRIVE AGX Thor 开发者套件加速自动驾驶汽车开发</title>
      <link>https://developer.nvidia.com/zh-cn/blog/accelerate-autonomous-vehicle-development-with-the-nvidia-drive-agx-thor-developer-kit/</link>
      <description>2025年 9月 3日借助 NVIDIA DRIVE AGX Thor 开发者套件加速自动驾驶汽车开发自动驾驶汽车（AV）技术是快速发展的，由于更大型、更复杂的AI模型被部署于边缘端推动。如今，现代汽车不仅需要先进的感知能力和传感器融合技术，3 MIN READ</description>
    </item>
    <item>
      <title>如何运行 AI 驱动的 CAE 仿真</title>
      <link>https://developer.nvidia.com/zh-cn/blog/how-to-run-ai-powered-cae-simulations/</link>
      <description>2025年 9月 3日如何运行 AI 驱动的 CAE 仿真在现代工程领域，创新速度与执行模拟分析的效率密切相关。计算机辅助工程（CAE）在验证产品性能与安全性方面发挥着关键作用，3 MIN READ</description>
    </item>
    <item>
      <title>南北向网络：加速企业 AI 工作负载的关键</title>
      <link>https://developer.nvidia.com/zh-cn/blog/north-south-networks-the-key-to-faster-enterprise-ai-workloads/</link>
      <description>2025年 9月 3日南北向网络：加速企业 AI 工作负载的关键在 AI 基础架构中，数据为计算引擎提供关键燃料。随着代理式 AI 系统的持续演进，多个模型与服务相互协作，需要获取外部上下文并实时做出决策，2 MIN READ</description>
    </item>
    <item>
      <title>通过 CPU-GPU 显存共享加速大规模 LLM 推理和 KV 缓存卸载</title>
      <link>https://developer.nvidia.com/zh-cn/blog/accelerate-large-scale-llm-inference-and-kv-cache-offload-with-cpu-gpu-memory-sharing/</link>
      <description>2025年 9月 5日通过 CPU-GPU 显存共享加速大规模 LLM 推理和 KV 缓存卸载大语言模型（LLM）处于人工智能创新的前沿，但其庞大的规模往往会影响推理效率。例如，Llama 3 70B 和 Llama 4 Scout…2 MIN READ</description>
    </item>
    <item>
      <title>如何使用 Outerbound 和 DGX 云 Lepton 自行构建 AI 系统</title>
      <link>https://developer.nvidia.com/zh-cn/blog/how-to-build-ai-systems-in-house-with-outerbounds-and-dgx-cloud-lepton/</link>
      <description>2025年 9月 8日如何使用 Outerbound 和 DGX 云 Lepton 自行构建 AI 系统我们往往容易低估实际生产级 AI 系统所涉及的组件复杂性。无论是构建融合内部数据与外部大语言模型的智能体，还是提供按需生成动画的服务，3 MIN READ</description>
    </item>
  </channel>
</rss>
