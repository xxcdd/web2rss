<?xml version='1.0' encoding='UTF-8'?>
<rss xmlns:atom="http://www.w3.org/2005/Atom" xmlns:content="http://purl.org/rss/1.0/modules/content/" version="2.0">
  <channel>
    <title>DeveloperNvidiaBlog</title>
    <link>https://developer.nvidia.com/zh-cn/blog/recent-posts/</link>
    <description>Latest posts from https://developer.nvidia.com/zh-cn/blog/recent-posts/. follow.is: None</description>
    <docs>http://www.rssboard.org/rss-specification</docs>
    <generator>python-feedgen</generator>
    <lastBuildDate>Thu, 26 Jun 2025 01:52:38 +0000</lastBuildDate>
    <item>
      <title>使用 FlashInfer 运行 NVIDIA 的高性能 LLM 推理内核</title>
      <link>https://developer.nvidia.com/zh-cn/blog/run-high-performance-llm-inference-kernels-from-nvidia-using-flashinfer/</link>
      <description>2025年 6月 13日使用 FlashInfer 运行 NVIDIA 的高性能 LLM 推理内核出色的 LLM 推理需要两个关键要素：速度和开发者速度。速度是指通过使用高度优化的计算内核算法，最大限度地提高底层硬件的效率。2 MIN READ</description>
    </item>
    <item>
      <title>Isaac Sim 和 Isaac Lab 现已推出早期开发者预览版</title>
      <link>https://developer.nvidia.com/zh-cn/blog/isaac-sim-and-isaac-lab-are-now-available-for-early-developer-preview/</link>
      <description>2025年 6月 16日Isaac Sim 和 Isaac Lab 现已推出早期开发者预览版NVIDIA 今天发布了 NVIDIA Isaac Sim 和 NVIDIA Isaac Lab 的开发者预览版…2 MIN READ</description>
    </item>
    <item>
      <title>使用世界基础模型生成的合成轨迹数据提高机器人学习效果</title>
      <link>https://developer.nvidia.com/zh-cn/blog/enhance-robot-learning-with-synthetic-trajectory-data-generated-by-world-foundation-models/</link>
      <description>2025年 6月 16日使用世界基础模型生成的合成轨迹数据提高机器人学习效果在机电一体化和机器人 AI 基础模型的进步的推动下，通用型机器人技术已经问世。但关键的瓶颈依然存在：2 MIN READ</description>
    </item>
    <item>
      <title>人工智能致力于为法律领域带来秩序</title>
      <link>https://developer.nvidia.com/zh-cn/blog/ai-aims-to-bring-order-to-the-law/</link>
      <description>2025年 6月 16日人工智能致力于为法律领域带来秩序斯坦福大学的一个研究团队开发了一个 LLM 系统，以减少官样文章。 被称为“System for Statutory Research”…1 MIN READ</description>
    </item>
    <item>
      <title>微调 LLMOps 以实现快速模型评估和持续优化</title>
      <link>https://developer.nvidia.com/zh-cn/blog/fine-tuning-llmops-for-rapid-model-evaluation-and-ongoing-optimization/</link>
      <description>2025年 6月 17日微调 LLMOps 以实现快速模型评估和持续优化大语言模型 (LLM) 为各行各业带来了前所未有的机遇。然而，将 LLM 从研发转向可靠、可扩展和可维护的生产系统会带来独特的运营挑战。4 MIN READ</description>
    </item>
    <item>
      <title>R²D²：利用 NVIDIA Research 构建AI驱动的3D机器人感知与地图构建技术</title>
      <link>https://developer.nvidia.com/zh-cn/blog/r2d2-building-ai-based-3d-robot-perception-and-mapping-with-nvidia-research/</link>
      <description>2025年 6月 17日R²D²：利用 NVIDIA Research 构建AI驱动的3D机器人感知与地图构建技术机器人必须感知和解释其 3D 环境，才能安全有效地行动。这对于非结构化或陌生空间中的自主导航、对象操作和远程操作等任务尤为重要。3 MIN READ</description>
    </item>
    <item>
      <title>通过 NVIDIA Holoscan for Media 上的全新 AI 应用实例，实现实时 AI 媒体效果增强</title>
      <link>https://developer.nvidia.com/zh-cn/blog/power-real-time-ai-media-effects-with-new-ai-reference-apps-on-nvidia-holoscan-for-media/</link>
      <description>2025年 6月 17日通过 NVIDIA Holoscan for Media 上的全新 AI 应用实例，实现实时 AI 媒体效果增强直播媒体工作流越来越多地使用 AI 微服务来增强制作能力。然而，先进的 AI 模型大多托管在云端，由于网络延迟、带宽和实时可扩展性方面的限制，1 MIN READ</description>
    </item>
    <item>
      <title>使用一个 GPU 运行多模态提取以实现更高效的 AI 工作流</title>
      <link>https://developer.nvidia.com/zh-cn/blog/run-multimodal-extraction-for-more-efficient-ai-pipelines-using-one-gpu/</link>
      <description>2025年 6月 18日使用一个 GPU 运行多模态提取以实现更高效的 AI 工作流随着企业生成和使用越来越多的多样化数据，从 PDF 和演示文稿等多模态文档中提取见解已成为一项重大挑战。4 MIN READ</description>
    </item>
    <item>
      <title>借助 NVIDIA NIM 推理微服务和 ITMonitron 实现实时 IT 事故检测和情报</title>
      <link>https://developer.nvidia.com/zh-cn/blog/real-time-it-incident-detection-and-intelligence-with-nvidia-nim-inference-microservices-and-itmonitron/</link>
      <description>2025年 6月 18日借助 NVIDIA NIM 推理微服务和 ITMonitron 实现实时 IT 事故检测和情报在当今快节奏的 IT 环境中，并非所有事件都始于明显的警报。这些问题可能始于细微的分散信号、错过的警报、悄无声息的 SLO 漏洞，2 MIN READ</description>
    </item>
    <item>
      <title>寻找实现准确 AI 响应的最优文本分块策略</title>
      <link>https://developer.nvidia.com/zh-cn/blog/finding-the-best-chunking-strategy-for-accurate-ai-responses/</link>
      <description>2025年 6月 18日寻找实现准确 AI 响应的最优文本分块策略分块策略是一种将大型文档分解为较小、可管理的部分的方法，用于 AI 检索。糟糕的分块会导致结果不相关、效率低下并降低业务价值。3 MIN READ</description>
    </item>
    <item>
      <title>NVIDIA 集合通信库 2.26 实现性能和监控功能的提升</title>
      <link>https://developer.nvidia.com/zh-cn/blog/improved-performance-and-monitoring-capabilities-with-nvidia-collective-communications-library-2-26/</link>
      <description>2025年 6月 18日NVIDIA 集合通信库 2.26 实现性能和监控功能的提升NVIDIA 集合通信库 (NCCL) 可实现针对 NVIDIA GPU 和网络优化的多 GPU 和多节点通信基元。3 MIN READ</description>
    </item>
    <item>
      <title>编译器资源管理器：CUDA 开发者必备的内核实验室</title>
      <link>https://developer.nvidia.com/zh-cn/blog/compiler-explorer-the-kernel-playground-for-cuda-developers/</link>
      <description>2025年 6月 18日编译器资源管理器：CUDA 开发者必备的内核实验室您是否曾想过，当您编写 GPU 核函数时，CUDA 编译器究竟会生成什么？是否曾想与同事轻松分享精简的 CUDA 示例，2 MIN READ</description>
    </item>
    <item>
      <title>抢先体验 NVIDIA GB200 系统如何帮助 LMarena 构建评估 LLM 的模型</title>
      <link>https://developer.nvidia.com/zh-cn/blog/how-early-access-to-nvidia-gb200-systems-helped-lmarena-build-a-model-to-evaluate-llms/</link>
      <description>2025年 6月 18日抢先体验 NVIDIA GB200 系统如何帮助 LMarena 构建评估 LLM 的模型在 NVIDIA 和 Nebius 的帮助下，加州大学伯克利分校的 LMArena 可以更轻松地了解哪些大语言模型在特定任务中表现出色。2 MIN READ</description>
    </item>
    <item>
      <title>NVIDIA 在制造和运营领域的 AI 应用：借助 NVIDIA CUDA-X 数据科学加速 ML 模型</title>
      <link>https://developer.nvidia.com/zh-cn/blog/ai-in-manufacturing-and-operations-at-nvidia-accelerating-ml-models-with-nvidia-cuda-x-data-science/</link>
      <description>2025年 6月 18日NVIDIA 在制造和运营领域的 AI 应用：借助 NVIDIA CUDA-X 数据科学加速 ML 模型从晶圆制造和电路探测到封装芯片测试，NVIDIA 利用数据科学和机器学习来优化芯片制造和运营工作流程。这些阶段会产生 TB 级的数据，3 MIN READ</description>
    </item>
    <item>
      <title>基准测试大型语言模型推理成本以实现更智能的扩展和部署</title>
      <link>https://developer.nvidia.com/zh-cn/blog/benchmarking-llm-inference-costs-for-smarter-scaling-and-deployment/</link>
      <description>2025年 6月 18日基准测试大型语言模型推理成本以实现更智能的扩展和部署这是大语言模型延迟-吞吐量基准测试系列的第三篇博文，旨在指导开发者如何通过估算总体拥有成本 (TCO) 来确定 LLM 推理的成本。3 MIN READ</description>
    </item>
    <item>
      <title>NVIDIA recsys-examples: 生成式推荐系统大规模训练推理的高效实践(上篇)</title>
      <link>https://developer.nvidia.com/zh-cn/blog/nvidia-recsys-generative-recommenders-1/</link>
      <description>2025年 6月 19日NVIDIA recsys-examples: 生成式推荐系统大规模训练推理的高效实践(上篇)在生成式 AI 浪潮的推动下，推荐系统领域正经历深刻变革。传统的深度学习推荐模型（DLRMs）虽已展现出一定效果，2 MIN READ</description>
    </item>
  </channel>
</rss>
