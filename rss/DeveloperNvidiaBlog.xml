<?xml version='1.0' encoding='UTF-8'?>
<rss xmlns:atom="http://www.w3.org/2005/Atom" xmlns:content="http://purl.org/rss/1.0/modules/content/" version="2.0">
  <channel>
    <title>DeveloperNvidiaBlog</title>
    <link>https://developer.nvidia.com/zh-cn/blog/recent-posts/</link>
    <description>Latest posts from https://developer.nvidia.com/zh-cn/blog/recent-posts/. follow.is: None</description>
    <docs>http://www.rssboard.org/rss-specification</docs>
    <generator>python-feedgen</generator>
    <lastBuildDate>Mon, 02 Jun 2025 01:56:08 +0000</lastBuildDate>
    <item>
      <title>使用 NVIDIA Isaac Lab 为工业机器人装配应用弥合仿真与现实之间的差距</title>
      <link>https://developer.nvidia.com/zh-cn/blog/bridging-the-sim-to-real-gap-for-industrial-robotic-assembly-applications-using-nvidia-isaac-lab/</link>
      <description>2025年 5月 20日使用 NVIDIA Isaac Lab 为工业机器人装配应用弥合仿真与现实之间的差距多个部件的组装在几乎每个主要行业 (如制造、汽车、航空航天、电子和医疗设备) 中都发挥着关键作用。尽管机器人组装应用广泛，3 MIN READ</description>
    </item>
    <item>
      <title>NVIDIA Dynamo 新增 GPU 自动缩放、Kubernetes 自动化和网络优化功能</title>
      <link>https://developer.nvidia.com/zh-cn/blog/nvidia-dynamo-adds-gpu-autoscaling-kubernetes-automation-and-networking-optimizations/</link>
      <description>2025年 5月 20日NVIDIA Dynamo 新增 GPU 自动缩放、Kubernetes 自动化和网络优化功能在 NVIDIA GTC 2025 上，我们宣布推出 NVIDIA Dynamo ，这是一种高吞吐量、低延迟的开源推理服务框架，2 MIN READ</description>
    </item>
    <item>
      <title>NVIDIA 800V HVDC 架构赋能新一代 AI 工厂发展</title>
      <link>https://developer.nvidia.com/zh-cn/blog/nvidia-800-v-hvdc-architecture-will-power-the-next-generation-of-ai-factories/</link>
      <description>2025年 5月 20日NVIDIA 800V HVDC 架构赋能新一代 AI 工厂发展AI 工作负载的指数级增长正在增加数据中心的功率需求。传统的 54 V 机架内配电专为千瓦（KW）-scale 机架设计，2 MIN READ</description>
    </item>
    <item>
      <title>NVIDIA Dynamo 加速 llm-d 社区计划，推动大规模分布式推理</title>
      <link>https://developer.nvidia.com/zh-cn/blog/nvidia-dynamo-accelerates-llm-d-community-initiatives-for-advancing-large-scale-distributed-inference/</link>
      <description>2025年 5月 21日NVIDIA Dynamo 加速 llm-d 社区计划，推动大规模分布式推理在 Red Hat Summit 2025 上推出的 llm-d 社区标志着开源生态系统在加速生成式 AI 推理创新方面迈出了重要一步。1 MIN READ</description>
    </item>
    <item>
      <title>Blackwell 借助 Meta 的 Llama 4 Maverick 突破 1000 TPS/ 用户门槛</title>
      <link>https://developer.nvidia.com/zh-cn/blog/blackwell-breaks-the-1000-tps-user-barrier-with-metas-llama-4-maverick/</link>
      <description>2025年 5月 22日Blackwell 借助 Meta 的 Llama 4 Maverick 突破 1000 TPS/ 用户门槛NVIDIA 的大语言模型 (LLM) 推理速度创下了世界纪录。在包含 400 亿参数的 Llama 4 Maverick 模型 (…3 MIN READ</description>
    </item>
    <item>
      <title>聚焦：Infleqtion 利用 Q-CHOP 和 NVIDIA CUDA-Q Dynamics 进行投资组合优化</title>
      <link>https://developer.nvidia.com/zh-cn/blog/spotlight-infleqtion-optimizes-portfolios-using-q-chop-and-nvidia-cuda-q-dynamics/</link>
      <description>2025年 5月 22日聚焦：Infleqtion 利用 Q-CHOP 和 NVIDIA CUDA-Q Dynamics 进行投资组合优化计算是现代金融服务行业必不可少的工具。根据指导财务决策的算法的速度和准确性，利润是成败的。2 MIN READ</description>
    </item>
    <item>
      <title>特级大师专业提示：使用 cuML 通过堆叠夺得 Kaggle 竞赛冠军</title>
      <link>https://developer.nvidia.com/zh-cn/blog/grandmaster-pro-tip-winning-first-place-in-a-kaggle-competition-with-stacking-using-cuml/</link>
      <description>2025年 5月 22日特级大师专业提示：使用 cuML 通过堆叠夺得 Kaggle 竞赛冠军堆叠是一种先进的表格数据建模技术，通过结合多个不同模型的预测来实现高性能。利用 GPU 的计算速度，可以高效地训练大量模型。2 MIN READ</description>
    </item>
    <item>
      <title>利用 NVIDIA DALI 的最新技术实现高效数据处理</title>
      <link>https://developer.nvidia.com/zh-cn/blog/unlock-efficient-data-processing-with-the-latest-from-nvidia-dali/</link>
      <description>2025年 5月 23日利用 NVIDIA DALI 的最新技术实现高效数据处理NVIDIA DALI 是一个用于解码和增强图像、视频和语音的便携式开源软件库，最近推出了多项功能，可提高性能并支持 DALI 的新用例。2 MIN READ</description>
    </item>
    <item>
      <title>LLM 推理、AI 智能体和测试时间缩放的简单介绍</title>
      <link>https://developer.nvidia.com/zh-cn/blog/an-easy-introduction-to-llm-reasoning-ai-agents-and-test-time-scaling/</link>
      <description>2025年 5月 23日LLM 推理、AI 智能体和测试时间缩放的简单介绍智能体一直是应用大语言模型 (LLMs) 解决复杂问题的主要驱动力。自 2023 年 AutoGPT 以来，2 MIN READ</description>
    </item>
    <item>
      <title>更智能、更安全地串流：了解 NVIDIA NeMo Guardrails 如何增强 LLM 输出串流</title>
      <link>https://developer.nvidia.com/zh-cn/blog/stream-smarter-and-safer-learn-how-nvidia-nemo-guardrails-enhance-llm-output-streaming/</link>
      <description>2025年 5月 23日更智能、更安全地串流：了解 NVIDIA NeMo Guardrails 如何增强 LLM 输出串流LLM 流式传输会在生成模型响应时，逐个 token 实时递增发送该响应。2 MIN READ</description>
    </item>
    <item>
      <title>AI 将脑部 MRI 转化为潜在的中风预测因子</title>
      <link>https://developer.nvidia.com/zh-cn/blog/ai-transforms-brain-mris-into-potential-stroke-predictors/</link>
      <description>2025年 5月 23日AI 将脑部 MRI 转化为潜在的中风预测因子研究人员使用 AI 分析常规脑部扫描，发现了一种前景良好的新方法，可以可靠地识别常见但难以检测的多中风先兆。1 MIN READ</description>
    </item>
    <item>
      <title>在 NVIDIA Grace Hopper 上训练大型语言模型的高级优化策略</title>
      <link>https://developer.nvidia.com/zh-cn/blog/advanced-optimization-strategies-for-llm-training-on-nvidia-grace-hopper/</link>
      <description>2025年 5月 27日在 NVIDIA Grace Hopper 上训练大型语言模型的高级优化策略虽然分析有助于识别效率低下的情况，但高级优化策略对于解决硬件限制和有效扩展 AI 工作负载至关重要。在本文中，我们将探讨 CPU 卸载、3 MIN READ</description>
    </item>
    <item>
      <title>在 NVIDIA Grace Hopper 上分析大型语言模型训练工作流</title>
      <link>https://developer.nvidia.com/zh-cn/blog/profiling-llm-training-workflows-on-nvidia-grace-hopper/</link>
      <description>2025年 5月 27日在 NVIDIA Grace Hopper 上分析大型语言模型训练工作流AI 的快速发展催生了模型大小呈指数级增长的时代，特别是在大语言模型 (LLMs) 领域。这些模型凭借其变革能力，正在推动各行各业的创新。3 MIN READ</description>
    </item>
    <item>
      <title>聚焦：使用 Iguazio 的 MLRun 和 NVIDIA NIM 构建可扩展和可观察的 AI 以投入生产</title>
      <link>https://developer.nvidia.com/zh-cn/blog/spotlight-build-scalable-and-observable-ai-ready-for-production-with-iguazios-mlrun-and-nvidia-nim/</link>
      <description>2025年 5月 28日聚焦：使用 Iguazio 的 MLRun 和 NVIDIA NIM 构建可扩展和可观察的 AI 以投入生产Iguazio (被麦肯锡收购) 与 NVIDIA 的合作使企业组织能够构建生产级 AI 解决方案，这些解决方案不仅具有高性能和可扩展性，2 MIN READ</description>
    </item>
    <item>
      <title>RAPIDS 实现零代码更改加速、IO 性能提升和核外 XGBoost 加速</title>
      <link>https://developer.nvidia.com/zh-cn/blog/rapids-brings-zero-code-change-acceleration-io-performance-gains-and-out-of-core-xgboost/</link>
      <description>2025年 5月 29日RAPIDS 实现零代码更改加速、IO 性能提升和核外 XGBoost 加速在过去的两个版本中，RAPIDS 为 Python 机器学习引入了零代码更改加速、巨大的 IO 性能提升、大于内存的 XGBoost 训练、3 MIN READ</description>
    </item>
    <item>
      <title>在阿里云 PAI 上一键部署和使用 NVIDIA Cosmos Reason-1 模型</title>
      <link>https://developer.nvidia.com/zh-cn/blog/aliyun-pai-nvidia-cosmos-reason-1-model/</link>
      <description>2025年 5月 30日在阿里云 PAI 上一键部署和使用 NVIDIA Cosmos Reason-1 模型NVIDIA 近期发布了 Cosmos Reason-1 的 7B 和 56B 两款多模态大语言模型 (MLLM)，它们经过了“物理 AI…3 MIN READ</description>
    </item>
  </channel>
</rss>
