<?xml version='1.0' encoding='UTF-8'?>
<rss xmlns:atom="http://www.w3.org/2005/Atom" xmlns:content="http://purl.org/rss/1.0/modules/content/" version="2.0">
  <channel>
    <title>DeveloperNvidiaBlog</title>
    <link>https://developer.nvidia.com/zh-cn/blog/recent-posts/</link>
    <description>Latest posts from https://developer.nvidia.com/zh-cn/blog/recent-posts/. follow.is: None</description>
    <docs>http://www.rssboard.org/rss-specification</docs>
    <generator>python-feedgen</generator>
    <lastBuildDate>Thu, 28 Aug 2025 01:43:34 +0000</lastBuildDate>
    <item>
      <title>借助 CUDA-QX 0.4 简化量子错误纠正和应用程序开发</title>
      <link>https://developer.nvidia.com/zh-cn/blog/streamlining-quantum-error-correction-and-application-development-with-cuda-qx-0-4/</link>
      <description>2025年 8月 13日借助 CUDA-QX 0.4 简化量子错误纠正和应用程序开发随着量子处理器单元 (QPU) 制造商和算法开发者致力于打造大规模、商业上可行的量子超级计算机，他们越来越专注于量子纠错 (QEC) 。2 MIN READ</description>
    </item>
    <item>
      <title>Dynamo 0.4 最新版本提供高达 4 倍性能提升、基于 SLO 自动扩展和实时可观察性</title>
      <link>https://developer.nvidia.com/zh-cn/blog/dynamo-0-4-delivers-4x-faster-performance-slo-based-autoscaling-and-real-time-observability/</link>
      <description>2025年 8月 13日Dynamo 0.4 最新版本提供高达 4 倍性能提升、基于 SLO 自动扩展和实时可观察性近期，OpenAI 的 gpt-oss、月之暗面的 Kimi K2 等多个新的前沿开源模型相继问世，标志着大语言模型 (LLM)…2 MIN READ</description>
    </item>
    <item>
      <title>利用 CPO 技术扩展 AI 工厂，提高能效</title>
      <link>https://developer.nvidia.com/zh-cn/blog/scaling-ai-factories-with-co-packaged-optics-for-better-power-efficiency/</link>
      <description>2025年 8月 18日利用 CPO 技术扩展 AI 工厂，提高能效随着 AI 重新定义计算格局，网络已成为构建未来数据中心发展的关键支柱。大语言模型的训练性能不仅取决于计算资源，更受到底层网络敏捷性、2 MIN READ</description>
    </item>
    <item>
      <title>使用 NVIDIA Streaming Sortformer 实时识别会议、通话和语音应用中的演讲者</title>
      <link>https://developer.nvidia.com/zh-cn/blog/identify-speakers-in-meetings-calls-and-voice-apps-in-real-time-with-nvidia-streaming-sortformer/</link>
      <description>2025年 8月 18日使用 NVIDIA Streaming Sortformer 实时识别会议、通话和语音应用中的演讲者在每一次会议、电话交流、 多人场合或支持语音的应用中，技术始终面临一个核心难题：谁在何时发言？几十年来，若不依赖专用设备或离线批量处理，2 MIN READ</description>
    </item>
    <item>
      <title>宣布推出新的 NVIDIA 游戏 AI 和神经网络渲染技术</title>
      <link>https://developer.nvidia.com/zh-cn/blog/announcing-the-latest-nvidia-gaming-ai-and-neural-rendering-technologies/</link>
      <description>2025年 8月 18日宣布推出新的 NVIDIA 游戏 AI 和神经网络渲染技术在 Gamescom 2025上，NVIDIA发布了其NVIDIA RTX神经网络渲染技术以及NVIDIA ACE生成式AI技术的最新进展。3 MIN READ</description>
    </item>
    <item>
      <title>借助 NVIDIA NeMo-RL 进行强化学习：Megatron 核心支持优化训练吞吐量</title>
      <link>https://developer.nvidia.com/zh-cn/blog/reinforcement-learning-with-nvidia-nemo-rl-megatron-core-support-for-optimized-training-throughput/</link>
      <description>2025年 8月 20日借助 NVIDIA NeMo-RL 进行强化学习：Megatron 核心支持优化训练吞吐量NVIDIA NeMo-RL 的初始版本通过 PyTorch DTensor（也称为 FSDP2）提供训练支持。3 MIN READ</description>
    </item>
    <item>
      <title>大规模部署 Omniverse Kit 应用</title>
      <link>https://developer.nvidia.com/zh-cn/blog/deploying-your-omniverse-kit-apps-at-scale/</link>
      <description>2025年 8月 20日大规模部署 Omniverse Kit 应用运行采用先进渲染和仿真技术的 3D 应用程序，通常需要用户进行复杂的安装，并依赖高性能的基础设施。3 MIN READ</description>
    </item>
    <item>
      <title>更少的编码，更多的科学：借助 OpenACC 和统一内存简化 GPU 上的海洋建模</title>
      <link>https://developer.nvidia.com/zh-cn/blog/less-coding-more-science-simplify-ocean-modeling-on-gpus-with-openacc-and-unified-memory/</link>
      <description>2025年 8月 21日更少的编码，更多的科学：借助 OpenACC 和统一内存简化 GPU 上的海洋建模NVIDIA HPC SDK v25.7 为采用 GPU 加速的高性能计算（HPC）应用开发者带来了重大突破。3 MIN READ</description>
    </item>
    <item>
      <title>使用 cuPQC 0.4 中的加速哈希函数和 Merkle Trees 提高数据完整性和安全性</title>
      <link>https://developer.nvidia.com/zh-cn/blog/improve-data-integrity-and-security-with-accelerated-hash-functions-and-merkle-trees-in-cupqc-0-4/</link>
      <description>2025年 8月 21日使用 cuPQC 0.4 中的加速哈希函数和 Merkle Trees 提高数据完整性和安全性随着数据集的持续扩大，确保数据的安全性和完整性变得愈发重要。加密技术，如证明机制、数据完整性校验、一致性验证和数字签名，在应对这些挑战、2 MIN READ</description>
    </item>
    <item>
      <title>借助 NVIDIA NVLink 和 NVLink Fusion 扩展 AI 推理性能和灵活性</title>
      <link>https://developer.nvidia.com/zh-cn/blog/scaling-ai-inference-performance-and-flexibility-with-nvidia-nvlink-and-nvlink-fusion/</link>
      <description>2025年 8月 21日借助 NVIDIA NVLink 和 NVLink Fusion 扩展 AI 推理性能和灵活性AI 模型复杂性的指数级增长驱动参数规模从数百万迅速扩展到数万亿，对计算资源提出了前所未有的需求，必须依赖大规模 GPU 集群才能满足。2 MIN READ</description>
    </item>
    <item>
      <title>如何发现 (并修复) pandas 工作流中的 5 个常见性能瓶颈</title>
      <link>https://developer.nvidia.com/zh-cn/blog/how-to-spot-and-fix-5-common-performance-bottlenecks-in-pandas-workflows/</link>
      <description>2025年 8月 22日如何发现 (并修复) pandas 工作流中的 5 个常见性能瓶颈数据加载缓慢、内存消耗大的连接操作以及长时间运行的任务，是每位 Python 开发者都会面临的问题。它们不仅浪费了宝贵的时间，2 MIN READ</description>
    </item>
    <item>
      <title>NVIDIA 硬件创新和开源贡献正在塑造 AI</title>
      <link>https://developer.nvidia.com/zh-cn/blog/nvidia-hardware-innovations-and-open-source-contributions-are-shaping-ai/</link>
      <description>2025年 8月 22日NVIDIA 硬件创新和开源贡献正在塑造 AICosmos、DeepSeek、Gemma、GPT-OSS、Llama、Nemotron、Phi、2 MIN READ</description>
    </item>
    <item>
      <title>NVIDIA Jetson Thor，专为物理 AI 打造的卓越平台</title>
      <link>https://developer.nvidia.com/zh-cn/blog/introducing-nvidia-jetson-thor-the-ultimate-platform-for-physical-ai/</link>
      <description>2025年 8月 25日NVIDIA Jetson Thor，专为物理 AI 打造的卓越平台机器人技术正经历一场变革，逐步脱离专用机器时代，迈入通用机器人时代。这一转变意味着机器人不再局限于单一用途、功能固定的形态，4 MIN READ</description>
    </item>
    <item>
      <title>NVFP4 实现 16 位训练精度，4 位训练速度和效率</title>
      <link>https://developer.nvidia.com/zh-cn/blog/nvfp4-trains-with-precision-of-16-bit-and-speed-and-efficiency-of-4-bit/</link>
      <description>2025年 8月 25日NVFP4 实现 16 位训练精度，4 位训练速度和效率近年来，AI工作负载呈指数级增长，这不仅体现在大型语言模型（LLM）的广泛部署上，也反映在预训练和后训练阶段对处理更多token的迫切需求。2 MIN READ</description>
    </item>
    <item>
      <title>TensorRT-LLM 中的分离式服务</title>
      <link>https://developer.nvidia.com/zh-cn/blog/tensorrt-llm-partioned-service/</link>
      <description>2025年 8月 26日TensorRT-LLM 中的分离式服务在之前的技术博客中，我们介绍了低延迟和高吞吐场景的优化方法。对于生产部署，用户还关心在满足特定延迟约束的情况下，每个 GPU 的吞吐表现。3 MIN READ</description>
    </item>
    <item>
      <title>在 NVIDIA Blackwell GPU 上优化 DeepSeek R1 吞吐量：开发者深度解析</title>
      <link>https://developer.nvidia.com/zh-cn/blog/nvidia-blackwell-gpu-deepseek-r1-optimization-2/</link>
      <description>2025年 8月 26日在 NVIDIA Blackwell GPU 上优化 DeepSeek R1 吞吐量：开发者深度解析开源 DeepSeek R1 模型的创新架构包含多头潜在注意力机制 (MLA) 和大型稀疏混合专家模型 (MoE)，1 MIN READ</description>
    </item>
  </channel>
</rss>
