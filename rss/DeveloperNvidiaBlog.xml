<?xml version='1.0' encoding='UTF-8'?>
<rss xmlns:atom="http://www.w3.org/2005/Atom" xmlns:content="http://purl.org/rss/1.0/modules/content/" version="2.0">
  <channel>
    <title>DeveloperNvidiaBlog</title>
    <link>https://developer.nvidia.com/zh-cn/blog/recent-posts/</link>
    <description>Latest posts from https://developer.nvidia.com/zh-cn/blog/recent-posts/. follow.is: None</description>
    <docs>http://www.rssboard.org/rss-specification</docs>
    <generator>python-feedgen</generator>
    <lastBuildDate>Thu, 30 Oct 2025 01:51:57 +0000</lastBuildDate>
    <item>
      <title>GPU 原生 Velox 和 NVIDIA cuDF 加速大规模数据分析</title>
      <link>https://developer.nvidia.com/zh-cn/blog/accelerating-large-scale-data-analytics-with-gpu-native-velox-and-nvidia-cudf/</link>
      <description>2025年 10月 6日GPU 原生 Velox 和 NVIDIA cuDF 加速大规模数据分析随着工作负载规模的扩大以及对高效数据处理需求的提升，相比基于 CPU 的系统，采用 GPU 加速的数据库和查询引擎在性价比方面展现出显著优势。2 MIN READ</description>
    </item>
    <item>
      <title>使用 NVIDIA TensorRT Model Optimizer 剪枝和蒸 LLM</title>
      <link>https://developer.nvidia.com/zh-cn/blog/pruning-and-distilling-llms-using-nvidia-tensorrt-model-optimizer/</link>
      <description>2025年 10月 7日使用 NVIDIA TensorRT Model Optimizer 剪枝和蒸 LLM大语言模型（LLM）在自然语言处理（NLP）任务，如代码生成、推理和数学计算等方面，展现出卓越的性能，树立了新的标杆。然而，3 MIN READ</description>
    </item>
    <item>
      <title>训练联合 AI 模型以预测蛋白质属性</title>
      <link>https://developer.nvidia.com/zh-cn/blog/training-federated-ai-models-to-predict-protein-properties/</link>
      <description>2025年 10月 8日训练联合 AI 模型以预测蛋白质属性预测蛋白质在细胞内的定位对于生物学研究和药物开发具有重要意义，这一过程被称为亚细胞定位。蛋白质的功能与其所处位置密切相关，明确其存在于细胞核、2 MIN READ</description>
    </item>
    <item>
      <title>从助手到对手：利用代理式 AI 开发者工具</title>
      <link>https://developer.nvidia.com/zh-cn/blog/from-assistant-to-adversary-exploiting-agentic-ai-developer-tools/</link>
      <description>2025年 10月 9日从助手到对手：利用代理式 AI 开发者工具越来越多的开发者开始采用支持人工智能的编码工具，例如 Cursor、OpenAI Codex、Claude Code 和 GitHub…3 MIN READ</description>
    </item>
    <item>
      <title>使用 NVIDIA Nemotron 构建日志分析多智能体自校正 RAG 系统</title>
      <link>https://developer.nvidia.com/zh-cn/blog/build-a-log-analysis-multi-agent-self-corrective-rag-system-with-nvidia-nemotron/</link>
      <description>2025年 10月 10日使用 NVIDIA Nemotron 构建日志分析多智能体自校正 RAG 系统日志是现代系统的核心所在。然而，随着应用规模不断扩大，日志往往演变成一片冗长繁杂的文本海洋，充斥着重复与冗余信息，令人不堪重负。2 MIN READ</description>
    </item>
    <item>
      <title>探索在大模型训练中使用 Megatron-Core 训练框架提高显存使用效率</title>
      <link>https://developer.nvidia.com/zh-cn/blog/explore-using-the-megatron-core-training-framework-to-improve-gpu-memory-efficiency-in-large-model-training/</link>
      <description>2025年 10月 11日探索在大模型训练中使用 Megatron-Core 训练框架提高显存使用效率在大模型训练中，显存（GPU Memory）始终是最稀缺的资源之一。随着模型规模迈入百亿、千亿甚至万亿参数级别，如何在有限显存中“塞下”…3 MIN READ</description>
    </item>
    <item>
      <title>使用 NVIDIA Dynamo 部署 72B 模型提升 PD 分离性能</title>
      <link>https://developer.nvidia.com/zh-cn/blog/deploying-a-72b-model-using-nvidia-dynamo-to-improve-pd-separation-performance/</link>
      <description>2025年 10月 13日使用 NVIDIA Dynamo 部署 72B 模型提升 PD 分离性能在生产环境部署大模型推理服务时，技术团队往往会遇到诸多挑战，例如缺乏成熟的 PD 分离方案、自动扩缩容机制不够灵活、缺乏动态路由，2 MIN READ</description>
    </item>
    <item>
      <title>借助 QuTip 和 scQubits 中的 NVIDIA cuQuantum 集成加速量子位研究</title>
      <link>https://developer.nvidia.com/zh-cn/blog/accelerate-qubit-research-with-nvidia-cuquantum-integrations-in-qutip-and-scqubits/</link>
      <description>2025年 10月 14日借助 QuTip 和 scQubits 中的 NVIDIA cuQuantum 集成加速量子位研究NVIDIA cuQuantum 是一个软件开发工具包（SDK），可加速电路级（数字）和器件级（模拟）的量子模拟。2 MIN READ</description>
    </item>
    <item>
      <title>硬件一致性平台上的内存管理深入剖析</title>
      <link>https://developer.nvidia.com/zh-cn/blog/understanding-memory-management-on-hardware-coherent-platforms/</link>
      <description>2025年 10月 14日硬件一致性平台上的内存管理深入剖析如果您是应用程序开发者或集群管理员，可能已经意识到非统一内存访问（NUMA）会对系统性能产生显著影响。2 MIN READ</description>
    </item>
    <item>
      <title>借助 NVIDIA Parabricks 提高变体识别准确性</title>
      <link>https://developer.nvidia.com/zh-cn/blog/improve-variant-calling-accuracy-with-nvidia-parabricks/</link>
      <description>2025年 10月 14日借助 NVIDIA Parabricks 提高变体识别准确性NVIDIA Parabricks 是一款专为数据科学家和生物信息学家设计的可扩展基因组学软件套件，专注于基因数据的二级分析。3 MIN READ</description>
    </item>
    <item>
      <title>通过 NVIDIA Jetson AGX Thor 实现 7 倍生成式 AI 性能，解锁更快速、更智能的边缘模型</title>
      <link>https://developer.nvidia.com/zh-cn/blog/unlock-faster-smarter-edge-models-with-7x-gen-ai-performance-on-nvidia-jetson-agx-thor/</link>
      <description>2025年 10月 15日通过 NVIDIA Jetson AGX Thor 实现 7 倍生成式 AI 性能，解锁更快速、更智能的边缘模型NVIDIA 软件生态系统的一大显著优势在于其持续优化的承诺。今年 8 月，NVIDIA 发布了 Jetson AGX Thor，2 MIN READ</description>
    </item>
    <item>
      <title>面向代理式 AI 和 6G 时代的加速和分布式 UPF</title>
      <link>https://developer.nvidia.com/zh-cn/blog/accelerated-and-distributed-upf-for-the-era-of-agentic-ai-and-6g/</link>
      <description>2025年 10月 15日面向代理式 AI 和 6G 时代的加速和分布式 UPF电信行业正快速向AI原生无线接入网（AI-RAN）和以AI为核心的6G方向演进。分布式用户面功能（dUPF）通过去中心化的数据包处理与路由，4 MIN READ</description>
    </item>
    <item>
      <title>NVIDIA ACE 新增对开源 Qwen3 SLM 模型的支持，实现在PC游戏中的本地部署</title>
      <link>https://developer.nvidia.com/zh-cn/blog/nvidia-ace-adds-open-source-qwen3-slm-for-on-device-deployment-in-pc-games/</link>
      <description>2025年 10月 21日NVIDIA ACE 新增对开源 Qwen3 SLM 模型的支持，实现在PC游戏中的本地部署为助力打造实时、动态的NPC游戏角色，NVIDIA ACE现已支持开源Qwen3-8B小语言模型（SLM），可实现PC游戏中的本地部署。1 MIN READ</description>
    </item>
    <item>
      <title>面向 Physical AI 的全栈式解决方案：解析 NVIDIA 与阿里云 PAI 的完整技术链路</title>
      <link>https://developer.nvidia.com/zh-cn/blog/physical-ai-full-stack-solution-nvidia-alibaba-pai/</link>
      <description>2025年 10月 21日面向 Physical AI 的全栈式解决方案：解析 NVIDIA 与阿里云 PAI 的完整技术链路随着人工智能向物理世界深度融合，Physical AI 正在重塑智能体的研发范式。它对数据生成、仿真验证、模型训练与边缘部署提出了一些挑战。2 MIN READ</description>
    </item>
    <item>
      <title>NVIDIA 2025 Hackathon 年度总决赛圆满落幕：AI Agent 技术创新成果丰硕</title>
      <link>https://developer.nvidia.com/zh-cn/blog/nvidia-2025-annual-ai-agent-hackathon-showcase/</link>
      <description>2025年 10月 24日NVIDIA 2025 Hackathon 年度总决赛圆满落幕：AI Agent 技术创新成果丰硕NVIDIA 2025 Hackathon 年度总决赛近日圆满落幕。本届大赛以“智能体生态 – 从单点突破到系统协同”为主题，3 MIN READ</description>
    </item>
    <item>
      <title>释放算力潜能：TensorRT LLM ADP 平衡策略让推理吞吐量再提升 33%</title>
      <link>https://developer.nvidia.com/zh-cn/blog/tensorrt-llm-adp-ep-boost-inferencing/</link>
      <description>2025年 10月 28日释放算力潜能：TensorRT LLM ADP 平衡策略让推理吞吐量再提升 33%在 DeepSeek MLA + MoE 架构下，在最大吞吐量场景中，通常采用注意力数据并行 (Attention Data…3 MIN READ</description>
    </item>
  </channel>
</rss>
